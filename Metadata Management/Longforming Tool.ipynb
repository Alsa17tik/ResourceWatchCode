{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cartoframes\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = 200\n",
    "\n",
    "import requests as req\n",
    "import json\n",
    "import boto3\n",
    "import io\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "from dateutil import parser\n",
    "\n",
    "import sys\n",
    "import logging\n",
    "import os\n",
    "# logging.basicConfig(stream=sys.stderr, level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* id_columns and data columns are provided as ; separated lists w/ no spaces, i.e. rw_country_name;rw_country_code;commodity_name;category\n",
    "* All data columns have a prefix, followed by a 4-digit year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Authenticating to Carto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CARTO_USER = 'wri-rw'\n",
    "CARTO_KEY = '' #os.environ.get('CARTO_KEY', None)\n",
    "\n",
    "cc = cartoframes.CartoContext(base_url='https://{}.carto.com/'.format(CARTO_USER),\n",
    "                              api_key=CARTO_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Authenticating to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aws_access_key_id = #os.environ.get('aws_access_key_id')\n",
    "aws_secret_access_key = #os.environ.get('aws_secret_access_key')\n",
    "\n",
    "s3_bucket = \"wri-public-data\"\n",
    "s3_folder = \"resourcewatch/wide_to_long/\"\n",
    "\n",
    "s3_client = boto3.client(\n",
    "    's3',\n",
    "    aws_access_key_id=aws_access_key_id,\n",
    "    aws_secret_access_key=aws_secret_access_key\n",
    ")\n",
    "s3_resource = boto3.resource(\n",
    "    's3',\n",
    "    aws_access_key_id=aws_access_key_id,\n",
    "    aws_secret_access_key=aws_secret_access_key\n",
    ")\n",
    "\n",
    "# Functions for reading and uploading data to/from S3\n",
    "def read_from_S3(bucket, key, index_col=0):\n",
    "    obj = s3_client.get_object(Bucket=bucket, Key=key)\n",
    "    df = pd.read_csv(io.BytesIO(obj['Body'].read()), index_col=[index_col], encoding=\"utf8\")\n",
    "    return(df)\n",
    "\n",
    "def write_to_S3(df, bucket, key):\n",
    "    csv_buffer = io.StringIO()\n",
    "    # Need to set encoding in Python2... default of 'ascii' fails\n",
    "    df.to_csv(csv_buffer, encoding='utf-8')\n",
    "    s3_resource.Object(bucket, key).put(Body=csv_buffer.getvalue())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data from RW API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Base URL for getting dataset metadata from RW API\n",
    "url = \"https://api.resourcewatch.org/v1/dataset?sort=slug,-provider,userId&status=saved&includes=metadata,vocabulary,widget,layer\"\n",
    "\n",
    "# page[size] tells the API the maximum number of results to send back\n",
    "# There are currently between 200 and 300 datasets on the RW API\n",
    "payload = { \"application\":\"rw\", \"page[size]\": 1000}\n",
    "\n",
    "# Request all datasets, and extract the data from the response\n",
    "res = req.get(url, params=payload)\n",
    "data = res.json()[\"data\"]\n",
    "\n",
    "### Convert the json object returned by the API into a pandas DataFrame\n",
    "# Another option: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.io.json.json_normalize.html\n",
    "datasets_on_api = {}\n",
    "for ix, dset in enumerate(data):\n",
    "    atts = dset[\"attributes\"]\n",
    "    metadata = atts[\"metadata\"]\n",
    "    layers = atts[\"layer\"]\n",
    "    widgets = atts[\"widget\"]\n",
    "    tags = atts[\"vocabulary\"]\n",
    "    datasets_on_api[dset[\"id\"]] = {\n",
    "        \"name\":atts[\"name\"],\n",
    "        \"table_name\":atts[\"tableName\"],\n",
    "        \"provider\":atts[\"provider\"],\n",
    "        \"date_updated\":atts[\"updatedAt\"],\n",
    "        \"num_metadata\":len(metadata),\n",
    "        \"metadata\": metadata,\n",
    "        \"num_layers\":len(layers),\n",
    "        \"layers\": layers,\n",
    "        \"num_widgets\":len(widgets),\n",
    "        \"widgets\": widgets,\n",
    "        \"num_tags\":len(tags),\n",
    "        \"tags\":tags\n",
    "    }\n",
    "\n",
    "# Create the DataFrame, name the index, and sort by date_updated\n",
    "# More recently updated datasets at the top\n",
    "current_datasets_on_api = pd.DataFrame.from_dict(datasets_on_api, orient='index')\n",
    "current_datasets_on_api.index.rename(\"Dataset\", inplace=True)\n",
    "current_datasets_on_api.sort_values(by=[\"date_updated\"], inplace=True, ascending = False)\n",
    "\n",
    "# Select all Carto datasets on the API:\n",
    "provider = \"cartodb\"\n",
    "carto_ids = (current_datasets_on_api[\"provider\"]==provider)\n",
    "carto_data = current_datasets_on_api.loc[carto_ids]\n",
    "\n",
    "logging.info(\"Number of Carto datasets: \" + str(carto_data.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load longforming config & data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  1038    0  1038    0     0   2641      0 --:--:-- --:--:-- --:--:--  2647\n"
     ]
    }
   ],
   "source": [
    "# Read in data sets info from config file\n",
    "# longform_config = pd.read_csv('/Users/nathansuberi/Desktop/RW_Data/longforming_tasks/longform_these.csv')\n",
    "# longform_config = longform_config.set_index('wri_id')\n",
    "# longform_config\n",
    "\n",
    "#### Download Google Spreadsheets ####\n",
    "# Longform Config\n",
    "!curl \"https://docs.google.com/spreadsheets/d/1OjLN9yDbAyuh51uWezOIei5hWkTMU3yTJys_S7miUpU/export?format=tsv\" > longform_config.tsv\n",
    "longform_config = pd.read_csv(open(\"longform_these.tsv\", \"r\"), sep=\"\\t\", index_col=[0])\n",
    "os.remove(\"longform_config.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rw_id</th>\n",
       "      <th>id_cols</th>\n",
       "      <th>prefixes</th>\n",
       "      <th>parse_date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wri_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>com.009</th>\n",
       "      <td>c61c364b-1d68-4dd9-ae3d-76c2a0022280</td>\n",
       "      <td>NaN</td>\n",
       "      <td>isoalpha3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cit.013</th>\n",
       "      <td>5d269c36-6ccf-4620-838d-431f86c30f69</td>\n",
       "      <td>country</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cit.020</th>\n",
       "      <td>6d3163f5-4e08-4830-84f1-2c5d76570a82</td>\n",
       "      <td>country_name</td>\n",
       "      <td>country_code</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cli.022</th>\n",
       "      <td>995ec4fe-b3cc-4cf4-bd48-b89d4e3ea072</td>\n",
       "      <td>countryname</td>\n",
       "      <td>iso3v10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ene.012</th>\n",
       "      <td>d446a52e-c4c1-4e74-ae30-3204620a0365</td>\n",
       "      <td>country_name</td>\n",
       "      <td>country_code</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>for.020</th>\n",
       "      <td>03bfb30e-829f-4299-bab9-b2be1b66b5d4</td>\n",
       "      <td>country</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soc.001</th>\n",
       "      <td>0b9f0100-ce5b-430f-ad8f-3363efa05481</td>\n",
       "      <td>country</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soc.002</th>\n",
       "      <td>d4ca3cc4-c162-469c-b341-b52284a73eaa</td>\n",
       "      <td>country</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soc.012</th>\n",
       "      <td>f48541d3-a622-4908-9400-5ef26257ac96</td>\n",
       "      <td>country</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soc.021</th>\n",
       "      <td>e7582657-9c16-4eb1-89e8-0211d94015c6</td>\n",
       "      <td>country</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soc.022</th>\n",
       "      <td>773a16a7-3531-4b56-8253-babd15ad7f87</td>\n",
       "      <td>country</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soc.024</th>\n",
       "      <td>6c6e70e7-5a19-46f2-9d95-34789fd20adc</td>\n",
       "      <td>country</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soc.026</th>\n",
       "      <td>0be2ce12-79b3-434b-b557-d6ea92d787fe</td>\n",
       "      <td>country</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soc.045</th>\n",
       "      <td>2cc29514-b97a-4103-92b1-c8c8e9268cd8</td>\n",
       "      <td>country</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soc.055</th>\n",
       "      <td>795a7ceb-ebc1-4479-95ad-76ea4d045ad3</td>\n",
       "      <td>country</td>\n",
       "      <td>iso</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soc.067</th>\n",
       "      <td>1de2af1c-5e5e-4a33-b8f1-8c8f9d000e49</td>\n",
       "      <td>country</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>com.022</th>\n",
       "      <td>c2142922-84d9-4564-8216-a4867b9e48c5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>iso</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        rw_id       id_cols      prefixes  \\\n",
       "wri_id                                                                      \n",
       "com.009  c61c364b-1d68-4dd9-ae3d-76c2a0022280           NaN     isoalpha3   \n",
       "cit.013  5d269c36-6ccf-4620-838d-431f86c30f69       country           NaN   \n",
       "cit.020  6d3163f5-4e08-4830-84f1-2c5d76570a82  country_name  country_code   \n",
       "cli.022  995ec4fe-b3cc-4cf4-bd48-b89d4e3ea072   countryname       iso3v10   \n",
       "ene.012  d446a52e-c4c1-4e74-ae30-3204620a0365  country_name  country_code   \n",
       "for.020  03bfb30e-829f-4299-bab9-b2be1b66b5d4       country           NaN   \n",
       "soc.001  0b9f0100-ce5b-430f-ad8f-3363efa05481       country           NaN   \n",
       "soc.002  d4ca3cc4-c162-469c-b341-b52284a73eaa       country           NaN   \n",
       "soc.012  f48541d3-a622-4908-9400-5ef26257ac96       country           NaN   \n",
       "soc.021  e7582657-9c16-4eb1-89e8-0211d94015c6       country           NaN   \n",
       "soc.022  773a16a7-3531-4b56-8253-babd15ad7f87       country           NaN   \n",
       "soc.024  6c6e70e7-5a19-46f2-9d95-34789fd20adc       country           NaN   \n",
       "soc.026  0be2ce12-79b3-434b-b557-d6ea92d787fe       country           NaN   \n",
       "soc.045  2cc29514-b97a-4103-92b1-c8c8e9268cd8       country           NaN   \n",
       "soc.055  795a7ceb-ebc1-4479-95ad-76ea4d045ad3       country           iso   \n",
       "soc.067  1de2af1c-5e5e-4a33-b8f1-8c8f9d000e49       country           NaN   \n",
       "com.022  c2142922-84d9-4564-8216-a4867b9e48c5           NaN           iso   \n",
       "\n",
       "         parse_date  \n",
       "wri_id               \n",
       "com.009         NaN  \n",
       "cit.013         NaN  \n",
       "cit.020         NaN  \n",
       "cli.022         NaN  \n",
       "ene.012         NaN  \n",
       "for.020         NaN  \n",
       "soc.001         NaN  \n",
       "soc.002         NaN  \n",
       "soc.012         NaN  \n",
       "soc.021         NaN  \n",
       "soc.022         NaN  \n",
       "soc.024         NaN  \n",
       "soc.026         NaN  \n",
       "soc.045         NaN  \n",
       "soc.055         NaN  \n",
       "soc.067         NaN  \n",
       "com.022         NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longform_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load data sets into memory for processing\n",
    "def load_data(obj, elem):\n",
    "    print(elem)\n",
    "    wri_id = elem[0].strip()\n",
    "    rw_id = elem[1].strip()\n",
    "    try:\n",
    "        table_name = carto_data.loc[rw_id]['table_name']\n",
    "        obj[wri_id] = cc.read(table_name)\n",
    "        print('Table shape: {}'.format(obj[wri_id].shape))\n",
    "    except:\n",
    "        obj[wri_id] = 'Unavailable'\n",
    "        print('Unavailable')\n",
    "    return obj\n",
    "\n",
    "data_tables = reduce(load_data, zip(longform_config.index,longform_config['rw_id']), {})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use known prefixes to reformat tables\n",
    "def pick_value_col(col, pfx):\n",
    "    if pfx in col:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def prepare_date(date, pfx, use_, parse_date):\n",
    "    if parse_date:\n",
    "        dt = parser.parse(date[date.index(pfx) + len(pfx):])\n",
    "        dt = dt.replace(month=1)\n",
    "        return dt.replace(day=1)\n",
    "    else:\n",
    "        return date[date.index(pfx) + len(pfx):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Longforming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for wri_id, data in data_tables.items():\n",
    "    \n",
    "    prefixes = longform_config.loc[wri_id, 'prefixes'].split(';')\n",
    "    id_cols = longform_config.loc[wri_id, 'id_cols'].split(';')\n",
    "    parse_date = True if longform_config.loc[wri_id, 'parse_date'] == 'True' else False\n",
    "    \n",
    "    logging.info('initial shape: ' + str(data.shape))\n",
    "    \n",
    "    df = pd.DataFrame(columns = id_cols + ['variable'])\n",
    "    \n",
    "    for pfx in prefixes:\n",
    "        logging.debug('working on pfx ' + pfx)\n",
    "        \n",
    "        value_cols = [col for col in data.columns if pick_value_col(col, pfx)]\n",
    "        logging.debug('columns pulled: ' + str(value_cols))\n",
    "\n",
    "        _df = pd.melt(data, id_vars=id_cols, value_vars=value_cols)\n",
    "        _df['variable'] = [prepare_date(date, pfx, use_, parse_date) for date in _df['variable']]\n",
    "\n",
    "        col_names = [pfx+'_data' if col=='value' else col for col in _df.columns]\n",
    "        _df.columns = col_names\n",
    "\n",
    "        df = df.merge(_df, on=id_cols  + ['variable'], how='outer')\n",
    "        logging.debug('intermediate df shape: ' + str(df.shape))\n",
    "\n",
    "    logging.info('final shape of ' + name + ': ' + str(df.shape))\n",
    "\n",
    "    new_cols = ['datetime' if col=='variable' else col for col in df.columns]\n",
    "    df.columns = new_cols\n",
    "    logging.info('final columns: ' + str(df.columns))\n",
    "    \n",
    "    data_tables[wri_id] = df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
