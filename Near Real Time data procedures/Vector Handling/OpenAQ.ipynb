{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quality Control Considerations\n",
    "\n",
    "* Datetime format == UTC compliant: True\n",
    "* Long form: True\n",
    "* Duplicate records: Under development\n",
    "* Locations and History tables in sync: JUST USE RECENT DATA ENDPOINT Under development\n",
    "\n",
    "# Priority\n",
    "* Insert into Carto\n",
    "* Design a widget to show updating data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Access internet resources\n",
    "import requests as req\n",
    "# Parse json\n",
    "import json\n",
    "# Data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Using datetime objects to ensure UTC time in incoming data\n",
    "from datetime import datetime, timedelta\n",
    "# https://dateutil.readthedocs.io/en/stable/\n",
    "from dateutil.parser import parse\n",
    "# Retrieve credentials from a local .env file\n",
    "from configparser import ConfigParser\n",
    "config = ConfigParser()\n",
    "config.read(\"/Users/nathansuberi/Desktop/Code Portfolio/ResourceWatchCode/.env\")\n",
    "\n",
    "# S3 connection libraries\n",
    "# Need to have environmental variables set with \"aws configure\", \n",
    "# or update code to explicitly supplied AWS Access Id and AWS Secret Key\n",
    "import boto3\n",
    "import sys\n",
    "import threading\n",
    "\n",
    "s3_client = boto3.client(\"s3\")\n",
    "s3_resource = boto3.resource(\"s3\")\n",
    "\n",
    "class ProgressPercentage(object):\n",
    "        def __init__(self, filename):\n",
    "            self._filename = filename\n",
    "            self._size = float(os.path.getsize(filename))\n",
    "            self._seen_so_far = 0\n",
    "            self._lock = threading.Lock()\n",
    "\n",
    "        def __call__(self, bytes_amount):\n",
    "            # To simplify we'll assume this is hooked up\n",
    "            # to a single filename.\n",
    "            with self._lock:\n",
    "                self._seen_so_far += bytes_amount\n",
    "                percentage = (self._seen_so_far / self._size) * 100\n",
    "                sys.stdout.write(\"\\r%s  %s / %s  (%.2f%%)\"%(\n",
    "                        self._filename, self._seen_so_far, self._size,\n",
    "                        percentage))\n",
    "                sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONSTANTS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Base URL for all SQL calls\n",
    "CARTO_URL = \"https://wri-rw.carto.com/api/v2/sql\"\n",
    "\n",
    "# FROM: https://resourcewatch.carto.com/u/wri-rw/your_apps\n",
    "CARTO_API_TOKEN = config.get(\"auth\", \"carto_api_token\")\n",
    "\n",
    "OPENAQ_DATA_FOLDER = \"/Users/nathansuberi/Desktop/RW_Data/OpenAQ/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interacting with Carto Tables\n",
    "* Table creation (locations, history)\n",
    "* Table destruction (locations, history... in case need to start over due to dev mistakes)\n",
    "* Adding new rows to history (after querying an API to get new data)\n",
    "* Adding new locations (if newly observed data fall in previously unlisted sensor locations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###\n",
    "# Functions for updating tables after de-duplicating\n",
    "###\n",
    "\n",
    "\n",
    "### when passing around table, only pass the unique ids/datetime/the barebones necessary\n",
    "## Pass in 2 lists of ids... it sends back what are the duplicates, what are the new ones\n",
    "#### ^ this is instead of \n",
    "\n",
    "\n",
    "\n",
    "def update_table_without_duplicates(data_df, target_table_name,\n",
    "                                    cols_and_types, float_cols_to_round=[\"latitude\", \"longitude\"], precision=8, \n",
    "                                    cols_with_apostrophes=None, \n",
    "                                    datetime_column=None, datetime_cutoff=None, want_data_since_cutoff=True,\n",
    "                                    dedupe_with_target=True, update_batch_size=20):\n",
    "    \"\"\" \n",
    "    Determines whether there are new locations to add to the table.\n",
    "    Sends an SQL statement and returns the result of that operation to stdout.\n",
    "    \n",
    "    look_back_length parameter allows for de-duping with a table while only considering a limited\n",
    "    history of the recent record\n",
    "    \"\"\"\n",
    "    \n",
    "    # If target table doesn't exist, create it\n",
    "    if not check_table_exists(target_table_name):\n",
    "        create_table(target_table_name, cols_and_types)\n",
    "    \n",
    "    # column names to consider from both the observations and the target_table\n",
    "    column_names = list(cols_and_types.keys())\n",
    "    \n",
    "    # Select data from the target_table to use in de-duping procedure\n",
    "    res = select_from_table(target_table_name, datetime_column, datetime_cutoff, want_data_since_cutoff)  \n",
    "    target_table = pd.DataFrame(res[\"rows\"], columns=column_names)\n",
    "    \n",
    "    # Only attempt these if rows are returned\n",
    "    if target_table.shape[0] > 0:\n",
    "        # Fix precision on float columns in target_table\n",
    "        target_table = fix_precision_of_floats(target_table, float_cols_to_round, precision)\n",
    "\n",
    "        # Fix apostrophe change (back to a ' from &#8217) in target_table\n",
    "        target_table = toggle_apostrophes(target_table, cols_with_apostrophes, remove=False)\n",
    "    else:    \n",
    "        # Override dedupe_with_target, as there is no target to dedupe with at this time\n",
    "        dedupe_with_target = False\n",
    "\n",
    "    # Remove duplicates in the new observations\n",
    "    observations = data_df[column_names]\n",
    "    new_obs = deduplicate(observations, column_names, \n",
    "                          float_cols_to_round, precision, \n",
    "                          target_table, dedupe_with_target)\n",
    "    number_new_observations = new_obs.shape[0]\n",
    "    print(\"Number of new observations added to\", target_table_name + \":\", number_new_observations)\n",
    "    \n",
    "    if number_new_observations > 0:\n",
    "        # Add genuinely new observations to the existing table\n",
    "        update_in_batches(new_obs, update_batch_size, target_table_name, cols_and_types, cols_with_apostrophes)\n",
    "    \n",
    "    # Return number of new observations for logging\n",
    "    return(number_new_observations)\n",
    "\n",
    "\n",
    "\n",
    "### Use POST instead of GET, with a json payload\n",
    "# This will put the data into the body of the request, instead of into the URL\n",
    "# Might still have to chunk it, can try uploading the whole thing\n",
    "###\n",
    "\n",
    "def update_in_batches(data_df, batch_size, \n",
    "                      target_table_name, cols_and_types, \n",
    "                      cols_with_apostrophes=None):\n",
    "    \"\"\" \n",
    "    Send new rows for Carto in smaller batch sizes.\n",
    "    A batch_size of 20 seems to work for the location data. \n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate column names once\n",
    "    columns = str(tuple(data_df.columns)).replace(\"'\",\"\")\n",
    "    \n",
    "    # Determine number of batches in which to send data\n",
    "    num_batches = int(data_df.shape[0] / batch_size)\n",
    "\n",
    "    for batch in range(num_batches+1):\n",
    "        # Select sub-dataframe\n",
    "        sub_df = data_df.iloc[batch*batch_size:batch*batch_size+batch_size]\n",
    "        \n",
    "        # Replace apostrophes from varchar columns with &#8217\n",
    "        sub_df = toggle_apostrophes(sub_df, cols_with_apostrophes, remove=True)\n",
    "        \n",
    "        # Create Insert SQL statement\n",
    "        res = insert_into_table(sub_df, target_table_name, columns, cols_and_types)\n",
    "\n",
    "        # Help with trouble shooting\n",
    "        # Display response error, the data that created the error, and break the cycle\n",
    "        if \"error\" in res.text:\n",
    "            print(res.text)\n",
    "            print(sub_df)\n",
    "            break\n",
    "\n",
    "        print(\"Completed up until index:\", batch*batch_size+batch_size)    \n",
    "    \n",
    "def dump_row_contents(row, cols_and_types):\n",
    "    \"\"\" Format data from a dataframe for insert statements into a Carto table \"\"\"\n",
    "    \n",
    "    dump = \"(\"\n",
    "    for ix in row.index:\n",
    "        if cols_and_types[ix] == \"varchar\":\n",
    "            dump += \"'\" + str(row[ix]) + \"',\"\n",
    "        elif cols_and_types[ix] == \"timestamp\":\n",
    "            # This is particular to the OpenAQ application\n",
    "            dt_obj = parse(str(row[ix])[:-5])\n",
    "            dt_str = dt_obj.strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
    "            dump += \"'\" + dt_str + \"',\"\n",
    "        else:\n",
    "            dump += str(row[ix]) + \",\"\n",
    "    dump = dump[:-1]+\")\"\n",
    "    return(dump)    \n",
    " \n",
    "    \n",
    "### To dedupe:\n",
    "# Create a new column that is unique \n",
    "# Location name + timestamp + parameter\n",
    "    \n",
    "###### Edit this to slim down\n",
    "# Pass ids from observations and ids from target table\n",
    "# Use the results of this to select the right rows from your table\n",
    "\n",
    "def generate_unique_ids(data_df, columns):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "    * Data\n",
    "    * Columns in that data\n",
    "    Output:\n",
    "    * Single column that is the unique id's for every row in the DF\n",
    "    \"\"\"\n",
    "\n",
    "    # Can can do this first, and then dedupe\n",
    "    \n",
    "    return(None)\n",
    "    \n",
    "def deduplicate(observations, column_names, \n",
    "                float_cols_to_round, precision, \n",
    "                target_table, dedupe_with_target=True):\n",
    "    \"\"\"Determine unique observations in data_df (de-dupe in the new observations)\"\"\"\n",
    "    \n",
    "    print(\"Deduping with target in mind:\", dedupe_with_target)\n",
    "    print(\"Target table shape:\", target_table.shape)\n",
    "    \n",
    "    # http://pandas.pydata.org/pandas-docs/version/0.17/generated/pandas.DataFrame.drop_duplicates.html\n",
    "    obs = observations.drop_duplicates(keep=\"first\")\n",
    "    obs = keep_geolocated(obs)\n",
    "    obs = fix_precision_of_floats(obs, float_cols_to_round, precision)\n",
    "    \n",
    "    ##\n",
    "    #obs = fix_date\n",
    "    \n",
    "    if dedupe_with_target:\n",
    "        # De-dupe between existing table and new observations\n",
    "        # https://stackoverflow.com/questions/29464234/compare-python-pandas-dataframes-for-matching-rows\n",
    "        shared = pd.merge(target_table, obs, on=column_names, how=\"inner\")\n",
    "        \n",
    "        print(\"obs shape:\", obs.shape)\n",
    "        print(\"shared shape:\", shared.shape)\n",
    "        shared[\"key\"] = \"x\"\n",
    "        temp_df = pd.merge(obs, shared, on=column_names, how=\"left\")\n",
    "        print(\"temp_df shape:\", temp_df.shape)\n",
    "        new_obs = temp_df[temp_df[\"key\"].isnull()].drop(\"key\", axis=1)\n",
    "    else:\n",
    "        new_obs = obs\n",
    "        \n",
    "    return(new_obs)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "###\n",
    "# Procedure for looping over OpenAQ history - specific to OpenAQ\n",
    "### \n",
    "    \n",
    "def run_over_single_set_new_data(data, target_table_name, \n",
    "                                 cols_and_types, \n",
    "                                 datetime_cutoff):\n",
    "    \"\"\"\n",
    "    Update table for a single set of new data\n",
    "    Specific to the OpenAQ history because there is no option to change several columns\n",
    "    \"\"\"\n",
    "    \n",
    "    kwargs = {\n",
    "                \"data_df\":data,\n",
    "                \"target_table_name\":target_table_name,\n",
    "                \"cols_and_types\":cols_and_types,\n",
    "                \"cols_with_apostrophes\":[\"location\", \"city\",\"country\"],\n",
    "                \"float_cols_to_round\":[\"latitude\", \"longitude\"],\n",
    "                \"precision\":6,\n",
    "                \"datetime_column\":\"lastUpdated\",\n",
    "                \"datetime_cutoff\":datetime_cutoff,\n",
    "                \"want_data_since_cutoff\":True\n",
    "             }\n",
    "\n",
    "    number_new_observations = update_table_without_duplicates(**kwargs)\n",
    "    \n",
    "    return(number_new_observations)\n",
    "\n",
    "def run_over_history_of_files(list_of_files, target_table_name, \n",
    "                              cols_and_types, datetime_cutoff,\n",
    "                              start_ix=\"\", end_ix=\"\", \n",
    "                              output_json=None):    \n",
    "    \"\"\"Used to loop over history of openaq-data\n",
    "    \n",
    "    Inputs:\n",
    "    * List of files to feed in\n",
    "    * Target table\n",
    "    * Columns and types to add in\n",
    "    Outputs:\n",
    "    * A json file with the number of new observations \n",
    "    * Data added into the appropriate table\n",
    "    \"\"\"\n",
    "    \n",
    "    # If no output_json given, create a new dictionary to serve as this\n",
    "    if not output_json:\n",
    "        output_json = {}\n",
    "    \n",
    "    for file in list_of_files[start_ix:end_ix]:\n",
    "        print(\"Now handling date:\", file)\n",
    "        url = \"https://openaq-data.s3.amazonaws.com/\"+file\n",
    "        data = pd.read_csv(url)\n",
    "        \n",
    "        number_new_observations = run_over_single_set_new_data(data, target_table_name, \n",
    "                                                               cols_and_types,\n",
    "                                                              datetime_cutoff)\n",
    "        \n",
    "        # Keep a history of the number of new observations per day in OpenAQ history\n",
    "        output_json[file] = number_new_observations\n",
    "        #print(output_json)\n",
    "    \n",
    "    # Output \n",
    "    with open(OPENAQ_DATA_FOLDER + target_table_name + \"additions.json\", \"w\") as f:\n",
    "        json.dump(output_json, f)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "###\n",
    "# Carto SQL API interacting functions\n",
    "###\n",
    "\n",
    "# def sql_api(sql, get_or_post, url=CARTO_URL, key=CARTO_API_TOKEN):\n",
    "#     \"\"\" Execute sql request over Carto SQL API \"\"\"\n",
    "# #Consider adding in account as a parameter, would make this more extensible\n",
    "    \n",
    "#     if get_or_post == \"get\":\n",
    "#         params = {\n",
    "#             'api_key' : key,\n",
    "#             'q'       : sql\n",
    "#         }\n",
    "#         r = req.get(url, params=params)\n",
    "#         return(r)\n",
    "#     elif get_or_post == \"post\":\n",
    "#         data = {\n",
    "#             'query':sql.replace(\"\\n\", \"\").strip(),\n",
    "#             #'api_key' : key\n",
    "#         }\n",
    "#         print(data)\n",
    "#         r = req.post(url + \"?api_key=\"+key, data=json.dumps(data))\n",
    "#         return(r)\n",
    "    \n",
    "    \n",
    "def sql_api(sql, get_or_post='get', url=CARTO_URL, key=CARTO_API_TOKEN):\n",
    "    \"\"\" Execute sql request over Carto SQL API \"\"\"\n",
    "\n",
    "    payload = {\n",
    "            'api_key' : key,\n",
    "            'q'       : sql\n",
    "        }\n",
    "    \n",
    "    if get_or_post == \"get\":\n",
    "        \n",
    "        r = req.get(url, params=payload)\n",
    "        return(r.json())\n",
    "    elif get_or_post == \"post\":\n",
    "        \n",
    "        r = req.post(url, data=payload)\n",
    "        return(r) \n",
    "\n",
    "def check_table_exists(target_table_name):\n",
    "    \"\"\"Check to see if table already in our Carto account\"\"\"\n",
    "    \n",
    "    check_exists_sql = \"\"\"\n",
    "    SELECT cdb_usertables FROM CDB_UserTables()\n",
    "    \"\"\".format(table_name=target_table_name)\n",
    "    \n",
    "    res = sql_api(check_exists_sql, \"get\")\n",
    "    \n",
    "    if target_table_name in res.text:\n",
    "        return(True)\n",
    "    else:\n",
    "        return(False)\n",
    "\n",
    "def create_table(target_table_name, cols_and_types):\n",
    "    \"\"\"SQL statement to create a table\"\"\"\n",
    "    \n",
    "    cols_and_types = \", \".join([col + \" \" + cols_and_types[col] for col in cols_and_types])\n",
    "\n",
    "    create_table_sql = \"\"\"\n",
    "    CREATE TABLE {table_name}\n",
    "     (\n",
    "     {column_names_and_data_types}\n",
    "     );\n",
    "    \"\"\".format(table_name=target_table_name, column_names_and_data_types=cols_and_types)\n",
    "\n",
    "    res = sql_api(create_table_sql, \"post\")\n",
    "    print(res.text)\n",
    "    \n",
    "def delete_table(target_table_name):\n",
    "    \"\"\"SQL statement to drop a table\"\"\"\n",
    "    \n",
    "    delete_table_sql = \"\"\"\n",
    "    DROP TABLE {table_name}\n",
    "    \"\"\".format(table_name=target_table_name)\n",
    "\n",
    "    res = sql_api(delete_table_sql, \"post\")\n",
    "    print(res.text)\n",
    "    \n",
    "def select_from_table(target_table_name, datetime_column=None, datetime_cutoff=None, want_data_since_cutoff=True):\n",
    "    \"\"\"\n",
    "    Standard SQL statement to select from a table, \n",
    "    with support for a single WHERE clause \n",
    "    to select before or after a certain time cutoff\n",
    "    \"\"\"\n",
    "    \n",
    "    # If a datetime_cutoff are provided, a datetime_column must also be\n",
    "    # The datetime_column and datetime_cutoff should both be single strings\n",
    "    if(datetime_cutoff):\n",
    "        assert(datetime_column and datetime_cutoff)\n",
    "        assert(type(datetime_cutoff)==str)\n",
    "        if(datetime_column):\n",
    "            assert(type(datetime_column)==str) \n",
    "    \n",
    "    # If no datetime_cutoff, select all from the target_table\n",
    "    if not datetime_cutoff:\n",
    "        select_all_sql = \"\"\"\n",
    "        SELECT * FROM {table_name}\n",
    "        \"\"\".format(table_name=target_table_name)\n",
    "        res = sql_api(select_all_sql, \"get\")\n",
    "        return(res)\n",
    "    \n",
    "    # If there is a datetime_cutoff, \n",
    "    # either take the data since that date or previous to that date\n",
    "    else:\n",
    "        # want_data_since_cutoff should be a boolean\n",
    "        assert(type(want_data_since_cutoff)==bool)\n",
    "        if want_data_since_cutoff:\n",
    "            comparison_operator = \"<=\"\n",
    "        else:\n",
    "            comparison_operator = \">=\"\n",
    "            \n",
    "        ## TO DO    \n",
    "        ### SELECT JUST DATETIME COLUMN AND THE UNIQUE ID COLUMN    \n",
    "        ## \n",
    "        \n",
    "        select_all_sql = \"\"\"\n",
    "        SELECT * FROM {table_name} WHERE {datetime_column} {comparison_operator} {datetime_cutoff}\n",
    "        \"\"\".format(table_name=target_table_name, \n",
    "                   datetime_column=datetime_column,\n",
    "                   comparison_operator=comparison_operator,\n",
    "                   datetime_cutoff=datetime_cutoff)\n",
    "        \n",
    "        res = sql_api(select_all_sql, \"get\")\n",
    "        return(res)\n",
    "        \n",
    "def insert_into_table(data_df, target_table_name, column_names, cols_and_types):\n",
    "    \"\"\"Craft insert statement for Carto table\"\"\"\n",
    "    \n",
    "    values = \", \".join(list(data_df.apply(lambda row: dump_row_contents(row, cols_and_types), axis=1)))\n",
    "    \n",
    "    insert_value_sql = \"\"\"\n",
    "    INSERT INTO {table_name} {columns} VALUES {values}\n",
    "    \"\"\".format(table_name=target_table_name, columns=column_names, values=values)\n",
    "\n",
    "    res = sql_api(insert_value_sql, \"post\")\n",
    "    return(res)\n",
    "\n",
    "\n",
    "\n",
    "def get_table_count(target_table_name, id_col):\n",
    "    \"\"\"\n",
    "    Return a count of the number of entries in the target table\n",
    "    This will be used to assess whether old rows need to be deleted to accomodate new content\n",
    "    \"\"\"\n",
    "    \n",
    "    assess_count_sql = \"\"\"\n",
    "    SELECT count(id_col) FROM {table_name}\n",
    "    \"\"\".format(table_name=target_table_name, id_col=id_col)\n",
    "\n",
    "    res = sql_api(insert_value_sql, \"get\")\n",
    "    return(res)\n",
    "\n",
    "\n",
    "\n",
    "###\n",
    "# DataFrame cleaning functions\n",
    "###\n",
    "\n",
    "def clean_datetime(datetime):\n",
    "    \"\"\"Ensures that datetimes are all in the same format\"\"\"\n",
    "    clean_datetime = datetime\n",
    "    \n",
    "    return(clean_datetime)\n",
    "\n",
    "def keep_geolocated(df):\n",
    "    \"\"\"\n",
    "    Throw away points that do not have a latitude and longitude defined\n",
    "    COLUMNS MUST BE NAMED latitude and longitude\n",
    "    \"\"\"\n",
    "    \n",
    "    keep_geotagged = pd.notnull(df[\"latitude\"]) & pd.notnull(df[\"longitude\"]) \n",
    "    df = df.loc[keep_geotagged]\n",
    "    return(df)\n",
    "\n",
    "def fix_precision_of_floats(df, float_columns, precision):\n",
    "    \"\"\"Use this to address problem of comparing numpy floats with rounding errors\"\"\"\n",
    "    df = df.copy()\n",
    "    for col in float_columns:\n",
    "        df[col] = np.around(df[col],precision)\n",
    "    return(df)\n",
    "\n",
    "\n",
    "\n",
    "###\n",
    "### TO verify where it is breaking...\n",
    "# print out the payload before upload\n",
    "# when writing the payload to json... apostrophe not escaped breaks the json\n",
    "\n",
    "def toggle_apostrophes(df, cols_with_apostrophes, remove=True):\n",
    "    \"\"\"\n",
    "    Will switch between &#8217 and ' representation of an apostrophe\n",
    "    Provides a reversible function to accomplish this\n",
    "    \n",
    "    TO DO: Address how this affects our data storage... &#8217 will be in Carto table\n",
    "    \n",
    "    \"\"\"\n",
    "    # Copy df\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Initialize array to avoid \"NoneType not iterable\" error\n",
    "    if not cols_with_apostrophes:\n",
    "        cols_with_apostrophes = []\n",
    "    \n",
    "    # Loop over all columns and either remove or replace apostrophes\n",
    "    for col in cols_with_apostrophes:\n",
    "        if remove:\n",
    "            # 50% chance this works:\n",
    "            # df[col] = df[col].apply(lambda row: str(row).replace(\"'\", \"\\\\'\"))\n",
    "            df[col] = df[col].apply(lambda row: str(row).replace(\"'\", \"&#8217\"))\n",
    "        else:\n",
    "            df[col] = df[col].apply(lambda row: str(row).replace(\"&#8217\", \"'\"))\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete table with history of OpenAQ data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"rows\":[],\"time\":0.008,\"fields\":{},\"total_rows\":0}\n"
     ]
    }
   ],
   "source": [
    "# ### CAREFUL ###\n",
    "# # Leave commented out majority of time, unless sure you want to delete history\n",
    "\n",
    "delete_table(\"open_aq_history\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create table to store history of OpenAQ data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"rows\":[],\"time\":0.009,\"fields\":{},\"total_rows\":0}\n"
     ]
    }
   ],
   "source": [
    "# Define the column names and types\n",
    "cols_and_types_history = {\n",
    "    #col name: Carto col type\n",
    "    \"utc\":\"timestamp\",\n",
    "    \"value\":\"float\",\n",
    "    \"parameter\":\"varchar\",\n",
    "    #\"sourceName\":\"varchar\",\n",
    "    \"location\":\"varchar\",\n",
    "    \"city\":\"varchar\",\n",
    "    \"country\":\"varchar\",\n",
    "    \"unit\":\"varchar\",\n",
    "    \"latitude\":\"float\",\n",
    "    \"longitude\":\"float\"\n",
    "}\n",
    "\n",
    "# Create table sql\n",
    "create_table(\"open_aq_history\", cols_and_types_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Consider creating an index on the date column\n",
    "# https://carto.com/docs/carto-engine/sql-api/query-optimizations/#creating-indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete table with previously observed locations of OpenAQ data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"rows\":[],\"time\":0.011,\"fields\":{},\"total_rows\":0}\n"
     ]
    }
   ],
   "source": [
    "# ### CAREFUL ###\n",
    "# # Leave commented out majority of time, unless sure you want to delete table of observed locations\n",
    "\n",
    "# delete_table(\"open_aq_locations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create table for observed locations in OpenAQ data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"error\":[\"relation \\\"open_aq_locations\\\" already exists\"]}\n"
     ]
    }
   ],
   "source": [
    "# Define the column names and types\n",
    "cols_and_types_locations = {\n",
    "    #col name: Carto col type\n",
    "    \"location\":\"varchar\",\n",
    "    \"city\":\"varchar\",\n",
    "    \"country\":\"varchar\",\n",
    "    \"latitude\":\"float\",\n",
    "    \"longitude\":\"float\"\n",
    "}\n",
    "\n",
    "# Create table sql\n",
    "create_table(\"open_aq_locations\", cols_and_types_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Consider creating an index on the location, city, and country columns\n",
    "# For guidance on creating an index with multiple columsn:\n",
    "# https://www.postgresql.org/docs/9.1/static/sql-createindex.html\n",
    "\n",
    "# Keep in mind that we would need to re-run the index after every addition to the table\n",
    "# The CONCURRENT option can be used to create the index without blocking write operations while doing so"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Pandas to read a CSV from a public s3 account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate records between two days: 0\n",
      "Dec 8 times: ['2017-12-08T00:00:00.000Z' '2017-12-08T01:00:00.000Z'\n",
      " '2017-12-08T02:00:00.000Z' ..., '2017-12-08T22:24:09.000Z'\n",
      " '2017-12-08T22:22:26.000Z' '2017-12-08T22:24:26.000Z']\n",
      "Dec 9 times: ['2017-12-09T00:00:00.000Z' '2017-12-09T00:02:17.000Z'\n",
      " '2017-12-09T00:02:18.000Z' ..., '2017-12-09T23:44:24.000Z'\n",
      " '2017-12-09T23:45:00.000Z' '2017-12-09T23:55:00.000Z']\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/32400867/pandas-read-csv-from-url/41880513#41880513\n",
    "# http://www.ritchieng.com/pandas-removing-duplicate-rows/\n",
    "url = \"https://openaq-data.s3.amazonaws.com/2017-12-09.csv\"\n",
    "dec9 = pd.read_csv(url)\n",
    "url = \"https://openaq-data.s3.amazonaws.com/2017-12-08.csv\"\n",
    "dec8 = pd.read_csv(url)\n",
    "twodays = dec9.append(dec8)\n",
    "dupes = twodays.duplicated()\n",
    "print(\"Number of duplicate records between two days:\", dupes.sum())\n",
    "print(\"Dec 8 times:\", dec8.utc.unique())\n",
    "print(\"Dec 9 times:\", dec9.utc.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>utc</th>\n",
       "      <th>local</th>\n",
       "      <th>parameter</th>\n",
       "      <th>value</th>\n",
       "      <th>unit</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>attribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Escuela E-10</td>\n",
       "      <td>Tocopilla</td>\n",
       "      <td>CL</td>\n",
       "      <td>2017-12-08T00:00:00.000Z</td>\n",
       "      <td>2017-12-07T21:00:00-03:00</td>\n",
       "      <td>pm25</td>\n",
       "      <td>4.09000</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>-22.085519</td>\n",
       "      <td>-70.188683</td>\n",
       "      <td>[{\"name\":\"SINCA\",\"url\":\"http://sinca.mma.gob.c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Escuela E-10</td>\n",
       "      <td>Tocopilla</td>\n",
       "      <td>CL</td>\n",
       "      <td>2017-12-08T01:00:00.000Z</td>\n",
       "      <td>2017-12-07T22:00:00-03:00</td>\n",
       "      <td>pm25</td>\n",
       "      <td>5.31000</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>-22.085519</td>\n",
       "      <td>-70.188683</td>\n",
       "      <td>[{\"name\":\"SINCA\",\"url\":\"http://sinca.mma.gob.c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Escuela E-10</td>\n",
       "      <td>Tocopilla</td>\n",
       "      <td>CL</td>\n",
       "      <td>2017-12-08T00:00:00.000Z</td>\n",
       "      <td>2017-12-07T21:00:00-03:00</td>\n",
       "      <td>so2</td>\n",
       "      <td>1.30000</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>-22.085519</td>\n",
       "      <td>-70.188683</td>\n",
       "      <td>[{\"name\":\"SINCA\",\"url\":\"http://sinca.mma.gob.c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Escuela E-10</td>\n",
       "      <td>Tocopilla</td>\n",
       "      <td>CL</td>\n",
       "      <td>2017-12-08T00:00:00.000Z</td>\n",
       "      <td>2017-12-07T21:00:00-03:00</td>\n",
       "      <td>o3</td>\n",
       "      <td>40.16000</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>-22.085519</td>\n",
       "      <td>-70.188683</td>\n",
       "      <td>[{\"name\":\"SINCA\",\"url\":\"http://sinca.mma.gob.c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Escuela E-10</td>\n",
       "      <td>Tocopilla</td>\n",
       "      <td>CL</td>\n",
       "      <td>2017-12-08T00:00:00.000Z</td>\n",
       "      <td>2017-12-07T21:00:00-03:00</td>\n",
       "      <td>no2</td>\n",
       "      <td>1.53000</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>-22.085519</td>\n",
       "      <td>-70.188683</td>\n",
       "      <td>[{\"name\":\"SINCA\",\"url\":\"http://sinca.mma.gob.c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Escuela E-10</td>\n",
       "      <td>Tocopilla</td>\n",
       "      <td>CL</td>\n",
       "      <td>2017-12-08T00:00:00.000Z</td>\n",
       "      <td>2017-12-07T21:00:00-03:00</td>\n",
       "      <td>pm10</td>\n",
       "      <td>23.43000</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>-22.085519</td>\n",
       "      <td>-70.188683</td>\n",
       "      <td>[{\"name\":\"SINCA\",\"url\":\"http://sinca.mma.gob.c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Escuela E-10</td>\n",
       "      <td>Tocopilla</td>\n",
       "      <td>CL</td>\n",
       "      <td>2017-12-08T00:00:00.000Z</td>\n",
       "      <td>2017-12-07T21:00:00-03:00</td>\n",
       "      <td>co</td>\n",
       "      <td>556.86000</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>-22.085519</td>\n",
       "      <td>-70.188683</td>\n",
       "      <td>[{\"name\":\"SINCA\",\"url\":\"http://sinca.mma.gob.c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Chiu Chiu</td>\n",
       "      <td>Calama</td>\n",
       "      <td>CL</td>\n",
       "      <td>2017-12-08T00:00:00.000Z</td>\n",
       "      <td>2017-12-07T21:00:00-03:00</td>\n",
       "      <td>so2</td>\n",
       "      <td>2.08000</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>-22.342264</td>\n",
       "      <td>-68.650897</td>\n",
       "      <td>[{\"name\":\"SINCA\",\"url\":\"http://sinca.mma.gob.c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Santa Margarita</td>\n",
       "      <td>Catemu</td>\n",
       "      <td>CL</td>\n",
       "      <td>2017-12-08T00:00:00.000Z</td>\n",
       "      <td>2017-12-07T21:00:00-03:00</td>\n",
       "      <td>so2</td>\n",
       "      <td>57.00000</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>-32.776573</td>\n",
       "      <td>-70.938144</td>\n",
       "      <td>[{\"name\":\"SINCA\",\"url\":\"http://sinca.mma.gob.c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Nueva Libertad</td>\n",
       "      <td>Talcahuano</td>\n",
       "      <td>CL</td>\n",
       "      <td>2017-12-08T00:00:00.000Z</td>\n",
       "      <td>2017-12-07T21:00:00-03:00</td>\n",
       "      <td>pm25</td>\n",
       "      <td>38.65000</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>-36.735998</td>\n",
       "      <td>-73.118693</td>\n",
       "      <td>[{\"name\":\"SINCA\",\"url\":\"http://sinca.mma.gob.c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Lo Campo</td>\n",
       "      <td>Panquehue</td>\n",
       "      <td>CL</td>\n",
       "      <td>2017-12-08T00:00:00.000Z</td>\n",
       "      <td>2017-12-07T21:00:00-03:00</td>\n",
       "      <td>so2</td>\n",
       "      <td>12.00000</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>-32.797715</td>\n",
       "      <td>-70.898037</td>\n",
       "      <td>[{\"name\":\"SINCA\",\"url\":\"http://sinca.mma.gob.c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Coronel Sur</td>\n",
       "      <td>Coronel</td>\n",
       "      <td>CL</td>\n",
       "      <td>2017-12-08T00:00:00.000Z</td>\n",
       "      <td>2017-12-07T21:00:00-03:00</td>\n",
       "      <td>pm10</td>\n",
       "      <td>32.03000</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>-37.031702</td>\n",
       "      <td>-73.138689</td>\n",
       "      <td>[{\"name\":\"SINCA\",\"url\":\"http://sinca.mma.gob.c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Catemu</td>\n",
       "      <td>Catemu</td>\n",
       "      <td>CL</td>\n",
       "      <td>2017-12-08T00:00:00.000Z</td>\n",
       "      <td>2017-12-07T21:00:00-03:00</td>\n",
       "      <td>so2</td>\n",
       "      <td>13.00000</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>-32.779208</td>\n",
       "      <td>-70.959114</td>\n",
       "      <td>[{\"name\":\"SINCA\",\"url\":\"http://sinca.mma.gob.c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Calabozo</td>\n",
       "      <td>Coronel</td>\n",
       "      <td>CL</td>\n",
       "      <td>2017-12-08T00:00:00.000Z</td>\n",
       "      <td>2017-12-07T21:00:00-03:00</td>\n",
       "      <td>so2</td>\n",
       "      <td>2.54000</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>-36.996431</td>\n",
       "      <td>-73.115805</td>\n",
       "      <td>[{\"name\":\"SINCA\",\"url\":\"http://sinca.mma.gob.c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Romeral</td>\n",
       "      <td>Hijuelas</td>\n",
       "      <td>CL</td>\n",
       "      <td>2017-12-08T00:00:00.000Z</td>\n",
       "      <td>2017-12-07T21:00:00-03:00</td>\n",
       "      <td>so2</td>\n",
       "      <td>13.00000</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>-32.823956</td>\n",
       "      <td>-71.006441</td>\n",
       "      <td>[{\"name\":\"SINCA\",\"url\":\"http://sinca.mma.gob.c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Lilla Essingen (E4/E20)</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>SE</td>\n",
       "      <td>2017-12-08T00:00:00.000Z</td>\n",
       "      <td>2017-12-08T01:00:00+01:00</td>\n",
       "      <td>pm25</td>\n",
       "      <td>2.98254</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>59.325519</td>\n",
       "      <td>18.003961</td>\n",
       "      <td>[{\"name\":\"SLB\",\"url\":\"http://slb.nu/slbanalys/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>E4/E20 Lilla Essingen</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>SE</td>\n",
       "      <td>2017-12-08T00:00:00.000Z</td>\n",
       "      <td>2017-12-08T01:00:00+01:00</td>\n",
       "      <td>no2</td>\n",
       "      <td>51.89750</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>59.325519</td>\n",
       "      <td>18.003961</td>\n",
       "      <td>[{\"name\":\"SLB\",\"url\":\"http://slb.nu/slbanalys/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>E4/E20 Gröndal</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>SE</td>\n",
       "      <td>2017-12-08T00:00:00.000Z</td>\n",
       "      <td>2017-12-08T01:00:00+01:00</td>\n",
       "      <td>no2</td>\n",
       "      <td>37.97250</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{\"name\":\"SLB\",\"url\":\"http://slb.nu/slbanalys/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>E4 Sollentuna Häggvik</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>SE</td>\n",
       "      <td>2017-12-08T00:00:00.000Z</td>\n",
       "      <td>2017-12-08T01:00:00+01:00</td>\n",
       "      <td>no2</td>\n",
       "      <td>55.06750</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>59.443539</td>\n",
       "      <td>17.922361</td>\n",
       "      <td>[{\"name\":\"SLB\",\"url\":\"http://slb.nu/slbanalys/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Hågelbyleden Botkyrka</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>SE</td>\n",
       "      <td>2017-12-08T00:00:00.000Z</td>\n",
       "      <td>2017-12-08T01:00:00+01:00</td>\n",
       "      <td>no2</td>\n",
       "      <td>13.19100</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>59.237058</td>\n",
       "      <td>17.838332</td>\n",
       "      <td>[{\"name\":\"SLB\",\"url\":\"http://slb.nu/slbanalys/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Sveavägen</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>SE</td>\n",
       "      <td>2017-12-08T00:00:00.000Z</td>\n",
       "      <td>2017-12-08T01:00:00+01:00</td>\n",
       "      <td>pm10</td>\n",
       "      <td>14.18930</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>59.345161</td>\n",
       "      <td>18.054282</td>\n",
       "      <td>[{\"name\":\"SLB\",\"url\":\"http://slb.nu/slbanalys/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Estación Centro</td>\n",
       "      <td>Calama</td>\n",
       "      <td>CL</td>\n",
       "      <td>2017-12-08T00:00:00.000Z</td>\n",
       "      <td>2017-12-07T21:00:00-03:00</td>\n",
       "      <td>pm25</td>\n",
       "      <td>8.44000</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>-22.462145</td>\n",
       "      <td>-68.928062</td>\n",
       "      <td>[{\"name\":\"SINCA\",\"url\":\"http://sinca.mma.gob.c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Gävle Södra Kungsgatan</td>\n",
       "      <td>Gävle</td>\n",
       "      <td>SE</td>\n",
       "      <td>2017-12-08T00:00:00.000Z</td>\n",
       "      <td>2017-12-08T01:00:00+01:00</td>\n",
       "      <td>pm10</td>\n",
       "      <td>8.84325</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>60.671552</td>\n",
       "      <td>17.146915</td>\n",
       "      <td>[{\"name\":\"SLB\",\"url\":\"http://slb.nu/slbanalys/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Hornsgatan</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>SE</td>\n",
       "      <td>2017-12-08T00:00:00.000Z</td>\n",
       "      <td>2017-12-08T01:00:00+01:00</td>\n",
       "      <td>pm10</td>\n",
       "      <td>10.67580</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>59.317132</td>\n",
       "      <td>18.048787</td>\n",
       "      <td>[{\"name\":\"SLB\",\"url\":\"http://slb.nu/slbanalys/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Folkungagatan</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>SE</td>\n",
       "      <td>2017-12-08T00:00:00.000Z</td>\n",
       "      <td>2017-12-08T01:00:00+01:00</td>\n",
       "      <td>pm10</td>\n",
       "      <td>15.09910</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>59.314624</td>\n",
       "      <td>18.075856</td>\n",
       "      <td>[{\"name\":\"SLB\",\"url\":\"http://slb.nu/slbanalys/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Norrlandsgatan</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>SE</td>\n",
       "      <td>2017-12-08T00:00:00.000Z</td>\n",
       "      <td>2017-12-08T01:00:00+01:00</td>\n",
       "      <td>pm10</td>\n",
       "      <td>10.47810</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>59.336356</td>\n",
       "      <td>18.070626</td>\n",
       "      <td>[{\"name\":\"SLB\",\"url\":\"http://slb.nu/slbanalys/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Södertälje Turingegatan</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>SE</td>\n",
       "      <td>2017-12-08T00:00:00.000Z</td>\n",
       "      <td>2017-12-08T01:00:00+01:00</td>\n",
       "      <td>pm10</td>\n",
       "      <td>4.78873</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>59.198124</td>\n",
       "      <td>17.621087</td>\n",
       "      <td>[{\"name\":\"SLB\",\"url\":\"http://slb.nu/slbanalys/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Uppsala Kungsgatan</td>\n",
       "      <td>Uppsala</td>\n",
       "      <td>SE</td>\n",
       "      <td>2017-12-08T00:00:00.000Z</td>\n",
       "      <td>2017-12-08T01:00:00+01:00</td>\n",
       "      <td>pm10</td>\n",
       "      <td>8.33501</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>59.859530</td>\n",
       "      <td>17.642484</td>\n",
       "      <td>[{\"name\":\"SLB\",\"url\":\"http://slb.nu/slbanalys/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>E4/E20 Gröndal</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>SE</td>\n",
       "      <td>2017-12-08T00:00:00.000Z</td>\n",
       "      <td>2017-12-08T01:00:00+01:00</td>\n",
       "      <td>pm10</td>\n",
       "      <td>13.52280</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{\"name\":\"SLB\",\"url\":\"http://slb.nu/slbanalys/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>E4/E20 Lilla Essingen</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>SE</td>\n",
       "      <td>2017-12-08T00:00:00.000Z</td>\n",
       "      <td>2017-12-08T01:00:00+01:00</td>\n",
       "      <td>pm10</td>\n",
       "      <td>13.71500</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>59.325519</td>\n",
       "      <td>18.003961</td>\n",
       "      <td>[{\"name\":\"SLB\",\"url\":\"http://slb.nu/slbanalys/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>Bahçelievler</td>\n",
       "      <td>Ankara</td>\n",
       "      <td>TR</td>\n",
       "      <td>2017-12-08T00:00:00.000Z</td>\n",
       "      <td>2017-12-08T03:00:00+03:00</td>\n",
       "      <td>so2</td>\n",
       "      <td>7.00000</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>39.918323</td>\n",
       "      <td>32.822905</td>\n",
       "      <td>[{\"name\":\"National Air Quality Monitoring Netw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>Bahçelievler</td>\n",
       "      <td>Ankara</td>\n",
       "      <td>TR</td>\n",
       "      <td>2017-12-08T00:00:00.000Z</td>\n",
       "      <td>2017-12-08T03:00:00+03:00</td>\n",
       "      <td>no2</td>\n",
       "      <td>34.00000</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>39.918323</td>\n",
       "      <td>32.822905</td>\n",
       "      <td>[{\"name\":\"National Air Quality Monitoring Netw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>Keçiören</td>\n",
       "      <td>Ankara</td>\n",
       "      <td>TR</td>\n",
       "      <td>2017-12-08T00:00:00.000Z</td>\n",
       "      <td>2017-12-08T03:00:00+03:00</td>\n",
       "      <td>so2</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>39.967262</td>\n",
       "      <td>32.862830</td>\n",
       "      <td>[{\"name\":\"National Air Quality Monitoring Netw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>Sıhhıye</td>\n",
       "      <td>Ankara</td>\n",
       "      <td>TR</td>\n",
       "      <td>2017-12-08T00:00:00.000Z</td>\n",
       "      <td>2017-12-08T03:00:00+03:00</td>\n",
       "      <td>so2</td>\n",
       "      <td>7.00000</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>39.927275</td>\n",
       "      <td>32.859411</td>\n",
       "      <td>[{\"name\":\"National Air Quality Monitoring Netw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>Bahabey</td>\n",
       "      <td>Çorum</td>\n",
       "      <td>TR</td>\n",
       "      <td>2017-12-08T00:00:00.000Z</td>\n",
       "      <td>2017-12-08T03:00:00+03:00</td>\n",
       "      <td>no2</td>\n",
       "      <td>36.00000</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>40.546555</td>\n",
       "      <td>34.967299</td>\n",
       "      <td>[{\"name\":\"National Air Quality Monitoring Netw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>Aziziye</td>\n",
       "      <td>Erzurum</td>\n",
       "      <td>TR</td>\n",
       "      <td>2017-12-08T00:00:00.000Z</td>\n",
       "      <td>2017-12-08T03:00:00+03:00</td>\n",
       "      <td>no2</td>\n",
       "      <td>7.00000</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>39.918984</td>\n",
       "      <td>41.271757</td>\n",
       "      <td>[{\"name\":\"National Air Quality Monitoring Netw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>Pasinler</td>\n",
       "      <td>Erzurum</td>\n",
       "      <td>TR</td>\n",
       "      <td>2017-12-08T00:00:00.000Z</td>\n",
       "      <td>2017-12-08T03:00:00+03:00</td>\n",
       "      <td>o3</td>\n",
       "      <td>60.00000</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>40.033451</td>\n",
       "      <td>41.572121</td>\n",
       "      <td>[{\"name\":\"National Air Quality Monitoring Netw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>Taşhan</td>\n",
       "      <td>Erzurum</td>\n",
       "      <td>TR</td>\n",
       "      <td>2017-12-08T00:00:00.000Z</td>\n",
       "      <td>2017-12-08T03:00:00+03:00</td>\n",
       "      <td>no2</td>\n",
       "      <td>14.00000</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>39.908334</td>\n",
       "      <td>41.273226</td>\n",
       "      <td>[{\"name\":\"National Air Quality Monitoring Netw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>Taşhan</td>\n",
       "      <td>Erzurum</td>\n",
       "      <td>TR</td>\n",
       "      <td>2017-12-08T00:00:00.000Z</td>\n",
       "      <td>2017-12-08T03:00:00+03:00</td>\n",
       "      <td>co</td>\n",
       "      <td>865.00000</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>39.908334</td>\n",
       "      <td>41.273226</td>\n",
       "      <td>[{\"name\":\"National Air Quality Monitoring Netw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>Sarıyer</td>\n",
       "      <td>İstanbul</td>\n",
       "      <td>TR</td>\n",
       "      <td>2017-12-08T00:00:00.000Z</td>\n",
       "      <td>2017-12-08T03:00:00+03:00</td>\n",
       "      <td>so2</td>\n",
       "      <td>13.00000</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>41.128889</td>\n",
       "      <td>29.049722</td>\n",
       "      <td>[{\"name\":\"National Air Quality Monitoring Netw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>Güzelyalı</td>\n",
       "      <td>İzmir</td>\n",
       "      <td>TR</td>\n",
       "      <td>2017-12-08T00:00:00.000Z</td>\n",
       "      <td>2017-12-08T03:00:00+03:00</td>\n",
       "      <td>no2</td>\n",
       "      <td>92.00000</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>38.395833</td>\n",
       "      <td>27.082778</td>\n",
       "      <td>[{\"name\":\"National Air Quality Monitoring Netw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>Güzelyalı</td>\n",
       "      <td>İzmir</td>\n",
       "      <td>TR</td>\n",
       "      <td>2017-12-08T00:00:00.000Z</td>\n",
       "      <td>2017-12-08T03:00:00+03:00</td>\n",
       "      <td>co</td>\n",
       "      <td>276.00000</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>38.395833</td>\n",
       "      <td>27.082778</td>\n",
       "      <td>[{\"name\":\"National Air Quality Monitoring Netw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>Elbistan</td>\n",
       "      <td>Kahramanmaraş</td>\n",
       "      <td>TR</td>\n",
       "      <td>2017-12-08T00:00:00.000Z</td>\n",
       "      <td>2017-12-08T03:00:00+03:00</td>\n",
       "      <td>pm10</td>\n",
       "      <td>59.00000</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>38.203741</td>\n",
       "      <td>37.198162</td>\n",
       "      <td>[{\"name\":\"National Air Quality Monitoring Netw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>Trafik</td>\n",
       "      <td>Kars</td>\n",
       "      <td>TR</td>\n",
       "      <td>2017-12-08T00:00:00.000Z</td>\n",
       "      <td>2017-12-08T03:00:00+03:00</td>\n",
       "      <td>pm10</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>40.600961</td>\n",
       "      <td>43.096822</td>\n",
       "      <td>[{\"name\":\"National Air Quality Monitoring Netw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>Nisekh</td>\n",
       "      <td>Ulaanbaatar</td>\n",
       "      <td>MN</td>\n",
       "      <td>2017-12-08T00:00:00.000Z</td>\n",
       "      <td>2017-12-08T08:00:00+08:00</td>\n",
       "      <td>pm10</td>\n",
       "      <td>141.00000</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>47.863943</td>\n",
       "      <td>106.779094</td>\n",
       "      <td>[{\"name\":\"Agaar.mn\",\"url\":\"http://agaar.mn/\"},...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>Nisekh</td>\n",
       "      <td>Ulaanbaatar</td>\n",
       "      <td>MN</td>\n",
       "      <td>2017-12-08T00:00:00.000Z</td>\n",
       "      <td>2017-12-08T08:00:00+08:00</td>\n",
       "      <td>so2</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>47.863943</td>\n",
       "      <td>106.779094</td>\n",
       "      <td>[{\"name\":\"Agaar.mn\",\"url\":\"http://agaar.mn/\"},...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>Nisekh</td>\n",
       "      <td>Ulaanbaatar</td>\n",
       "      <td>MN</td>\n",
       "      <td>2017-12-08T00:00:00.000Z</td>\n",
       "      <td>2017-12-08T08:00:00+08:00</td>\n",
       "      <td>no2</td>\n",
       "      <td>14.00000</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>47.863943</td>\n",
       "      <td>106.779094</td>\n",
       "      <td>[{\"name\":\"Agaar.mn\",\"url\":\"http://agaar.mn/\"},...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>MNB</td>\n",
       "      <td>Ulaanbaatar</td>\n",
       "      <td>MN</td>\n",
       "      <td>2017-12-08T00:00:00.000Z</td>\n",
       "      <td>2017-12-08T08:00:00+08:00</td>\n",
       "      <td>pm10</td>\n",
       "      <td>316.00000</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>47.929732</td>\n",
       "      <td>106.888629</td>\n",
       "      <td>[{\"name\":\"Agaar.mn\",\"url\":\"http://agaar.mn/\"},...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>MNB</td>\n",
       "      <td>Ulaanbaatar</td>\n",
       "      <td>MN</td>\n",
       "      <td>2017-12-08T00:00:00.000Z</td>\n",
       "      <td>2017-12-08T08:00:00+08:00</td>\n",
       "      <td>so2</td>\n",
       "      <td>61.00000</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>47.929732</td>\n",
       "      <td>106.888629</td>\n",
       "      <td>[{\"name\":\"Agaar.mn\",\"url\":\"http://agaar.mn/\"},...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>Nisekh</td>\n",
       "      <td>Ulaanbaatar</td>\n",
       "      <td>MN</td>\n",
       "      <td>2017-12-08T00:00:00.000Z</td>\n",
       "      <td>2017-12-08T08:00:00+08:00</td>\n",
       "      <td>pm25</td>\n",
       "      <td>131.00000</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>47.863943</td>\n",
       "      <td>106.779094</td>\n",
       "      <td>[{\"name\":\"Agaar.mn\",\"url\":\"http://agaar.mn/\"},...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>Nisekh</td>\n",
       "      <td>Ulaanbaatar</td>\n",
       "      <td>MN</td>\n",
       "      <td>2017-12-08T00:00:00.000Z</td>\n",
       "      <td>2017-12-08T08:00:00+08:00</td>\n",
       "      <td>co</td>\n",
       "      <td>1554.00000</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>47.863943</td>\n",
       "      <td>106.779094</td>\n",
       "      <td>[{\"name\":\"Agaar.mn\",\"url\":\"http://agaar.mn/\"},...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>Nisekh</td>\n",
       "      <td>Ulaanbaatar</td>\n",
       "      <td>MN</td>\n",
       "      <td>2017-12-08T00:00:00.000Z</td>\n",
       "      <td>2017-12-08T08:00:00+08:00</td>\n",
       "      <td>o3</td>\n",
       "      <td>15.00000</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>47.863943</td>\n",
       "      <td>106.779094</td>\n",
       "      <td>[{\"name\":\"Agaar.mn\",\"url\":\"http://agaar.mn/\"},...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>MNB</td>\n",
       "      <td>Ulaanbaatar</td>\n",
       "      <td>MN</td>\n",
       "      <td>2017-12-08T00:00:00.000Z</td>\n",
       "      <td>2017-12-08T08:00:00+08:00</td>\n",
       "      <td>pm25</td>\n",
       "      <td>311.00000</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>47.929732</td>\n",
       "      <td>106.888629</td>\n",
       "      <td>[{\"name\":\"Agaar.mn\",\"url\":\"http://agaar.mn/\"},...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>MNB</td>\n",
       "      <td>Ulaanbaatar</td>\n",
       "      <td>MN</td>\n",
       "      <td>2017-12-08T00:00:00.000Z</td>\n",
       "      <td>2017-12-08T08:00:00+08:00</td>\n",
       "      <td>co</td>\n",
       "      <td>7952.00000</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>47.929732</td>\n",
       "      <td>106.888629</td>\n",
       "      <td>[{\"name\":\"Agaar.mn\",\"url\":\"http://agaar.mn/\"},...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>MNB</td>\n",
       "      <td>Ulaanbaatar</td>\n",
       "      <td>MN</td>\n",
       "      <td>2017-12-08T00:00:00.000Z</td>\n",
       "      <td>2017-12-08T08:00:00+08:00</td>\n",
       "      <td>no2</td>\n",
       "      <td>81.00000</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>47.929732</td>\n",
       "      <td>106.888629</td>\n",
       "      <td>[{\"name\":\"Agaar.mn\",\"url\":\"http://agaar.mn/\"},...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Misheel expo</td>\n",
       "      <td>Ulaanbaatar</td>\n",
       "      <td>MN</td>\n",
       "      <td>2017-12-08T00:00:00.000Z</td>\n",
       "      <td>2017-12-08T08:00:00+08:00</td>\n",
       "      <td>pm10</td>\n",
       "      <td>175.00000</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>47.894339</td>\n",
       "      <td>106.882472</td>\n",
       "      <td>[{\"name\":\"Agaar.mn\",\"url\":\"http://agaar.mn/\"},...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Misheel expo</td>\n",
       "      <td>Ulaanbaatar</td>\n",
       "      <td>MN</td>\n",
       "      <td>2017-12-08T00:00:00.000Z</td>\n",
       "      <td>2017-12-08T08:00:00+08:00</td>\n",
       "      <td>so2</td>\n",
       "      <td>18.00000</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>47.894339</td>\n",
       "      <td>106.882472</td>\n",
       "      <td>[{\"name\":\"Agaar.mn\",\"url\":\"http://agaar.mn/\"},...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Misheel expo</td>\n",
       "      <td>Ulaanbaatar</td>\n",
       "      <td>MN</td>\n",
       "      <td>2017-12-08T00:00:00.000Z</td>\n",
       "      <td>2017-12-08T08:00:00+08:00</td>\n",
       "      <td>o3</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>47.894339</td>\n",
       "      <td>106.882472</td>\n",
       "      <td>[{\"name\":\"Agaar.mn\",\"url\":\"http://agaar.mn/\"},...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Bukhiin urguu</td>\n",
       "      <td>Ulaanbaatar</td>\n",
       "      <td>MN</td>\n",
       "      <td>2017-12-08T00:00:00.000Z</td>\n",
       "      <td>2017-12-08T08:00:00+08:00</td>\n",
       "      <td>so2</td>\n",
       "      <td>22.00000</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>47.917606</td>\n",
       "      <td>106.937361</td>\n",
       "      <td>[{\"name\":\"Agaar.mn\",\"url\":\"http://agaar.mn/\"},...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Bukhiin urguu</td>\n",
       "      <td>Ulaanbaatar</td>\n",
       "      <td>MN</td>\n",
       "      <td>2017-12-08T00:00:00.000Z</td>\n",
       "      <td>2017-12-08T08:00:00+08:00</td>\n",
       "      <td>pm25</td>\n",
       "      <td>22.00000</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>47.917606</td>\n",
       "      <td>106.937361</td>\n",
       "      <td>[{\"name\":\"Agaar.mn\",\"url\":\"http://agaar.mn/\"},...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    location           city country                       utc  \\\n",
       "0               Escuela E-10      Tocopilla      CL  2017-12-08T00:00:00.000Z   \n",
       "1               Escuela E-10      Tocopilla      CL  2017-12-08T01:00:00.000Z   \n",
       "2               Escuela E-10      Tocopilla      CL  2017-12-08T00:00:00.000Z   \n",
       "3               Escuela E-10      Tocopilla      CL  2017-12-08T00:00:00.000Z   \n",
       "4               Escuela E-10      Tocopilla      CL  2017-12-08T00:00:00.000Z   \n",
       "5               Escuela E-10      Tocopilla      CL  2017-12-08T00:00:00.000Z   \n",
       "6               Escuela E-10      Tocopilla      CL  2017-12-08T00:00:00.000Z   \n",
       "7                  Chiu Chiu         Calama      CL  2017-12-08T00:00:00.000Z   \n",
       "8            Santa Margarita         Catemu      CL  2017-12-08T00:00:00.000Z   \n",
       "9             Nueva Libertad     Talcahuano      CL  2017-12-08T00:00:00.000Z   \n",
       "10                  Lo Campo      Panquehue      CL  2017-12-08T00:00:00.000Z   \n",
       "11               Coronel Sur        Coronel      CL  2017-12-08T00:00:00.000Z   \n",
       "12                    Catemu         Catemu      CL  2017-12-08T00:00:00.000Z   \n",
       "13                  Calabozo        Coronel      CL  2017-12-08T00:00:00.000Z   \n",
       "14                   Romeral       Hijuelas      CL  2017-12-08T00:00:00.000Z   \n",
       "15   Lilla Essingen (E4/E20)      Stockholm      SE  2017-12-08T00:00:00.000Z   \n",
       "16     E4/E20 Lilla Essingen      Stockholm      SE  2017-12-08T00:00:00.000Z   \n",
       "17            E4/E20 Gröndal      Stockholm      SE  2017-12-08T00:00:00.000Z   \n",
       "18     E4 Sollentuna Häggvik      Stockholm      SE  2017-12-08T00:00:00.000Z   \n",
       "19     Hågelbyleden Botkyrka      Stockholm      SE  2017-12-08T00:00:00.000Z   \n",
       "20                 Sveavägen      Stockholm      SE  2017-12-08T00:00:00.000Z   \n",
       "21           Estación Centro         Calama      CL  2017-12-08T00:00:00.000Z   \n",
       "22    Gävle Södra Kungsgatan          Gävle      SE  2017-12-08T00:00:00.000Z   \n",
       "23                Hornsgatan      Stockholm      SE  2017-12-08T00:00:00.000Z   \n",
       "24             Folkungagatan      Stockholm      SE  2017-12-08T00:00:00.000Z   \n",
       "25            Norrlandsgatan      Stockholm      SE  2017-12-08T00:00:00.000Z   \n",
       "26   Södertälje Turingegatan      Stockholm      SE  2017-12-08T00:00:00.000Z   \n",
       "27        Uppsala Kungsgatan        Uppsala      SE  2017-12-08T00:00:00.000Z   \n",
       "28            E4/E20 Gröndal      Stockholm      SE  2017-12-08T00:00:00.000Z   \n",
       "29     E4/E20 Lilla Essingen      Stockholm      SE  2017-12-08T00:00:00.000Z   \n",
       "..                       ...            ...     ...                       ...   \n",
       "970             Bahçelievler         Ankara      TR  2017-12-08T00:00:00.000Z   \n",
       "971             Bahçelievler         Ankara      TR  2017-12-08T00:00:00.000Z   \n",
       "972                 Keçiören         Ankara      TR  2017-12-08T00:00:00.000Z   \n",
       "973                  Sıhhıye         Ankara      TR  2017-12-08T00:00:00.000Z   \n",
       "974                  Bahabey          Çorum      TR  2017-12-08T00:00:00.000Z   \n",
       "975                  Aziziye        Erzurum      TR  2017-12-08T00:00:00.000Z   \n",
       "976                 Pasinler        Erzurum      TR  2017-12-08T00:00:00.000Z   \n",
       "977                   Taşhan        Erzurum      TR  2017-12-08T00:00:00.000Z   \n",
       "978                   Taşhan        Erzurum      TR  2017-12-08T00:00:00.000Z   \n",
       "979                  Sarıyer       İstanbul      TR  2017-12-08T00:00:00.000Z   \n",
       "980                Güzelyalı          İzmir      TR  2017-12-08T00:00:00.000Z   \n",
       "981                Güzelyalı          İzmir      TR  2017-12-08T00:00:00.000Z   \n",
       "982                 Elbistan  Kahramanmaraş      TR  2017-12-08T00:00:00.000Z   \n",
       "983                   Trafik           Kars      TR  2017-12-08T00:00:00.000Z   \n",
       "984                   Nisekh    Ulaanbaatar      MN  2017-12-08T00:00:00.000Z   \n",
       "985                   Nisekh    Ulaanbaatar      MN  2017-12-08T00:00:00.000Z   \n",
       "986                   Nisekh    Ulaanbaatar      MN  2017-12-08T00:00:00.000Z   \n",
       "987                      MNB    Ulaanbaatar      MN  2017-12-08T00:00:00.000Z   \n",
       "988                      MNB    Ulaanbaatar      MN  2017-12-08T00:00:00.000Z   \n",
       "989                   Nisekh    Ulaanbaatar      MN  2017-12-08T00:00:00.000Z   \n",
       "990                   Nisekh    Ulaanbaatar      MN  2017-12-08T00:00:00.000Z   \n",
       "991                   Nisekh    Ulaanbaatar      MN  2017-12-08T00:00:00.000Z   \n",
       "992                      MNB    Ulaanbaatar      MN  2017-12-08T00:00:00.000Z   \n",
       "993                      MNB    Ulaanbaatar      MN  2017-12-08T00:00:00.000Z   \n",
       "994                      MNB    Ulaanbaatar      MN  2017-12-08T00:00:00.000Z   \n",
       "995             Misheel expo    Ulaanbaatar      MN  2017-12-08T00:00:00.000Z   \n",
       "996             Misheel expo    Ulaanbaatar      MN  2017-12-08T00:00:00.000Z   \n",
       "997             Misheel expo    Ulaanbaatar      MN  2017-12-08T00:00:00.000Z   \n",
       "998            Bukhiin urguu    Ulaanbaatar      MN  2017-12-08T00:00:00.000Z   \n",
       "999            Bukhiin urguu    Ulaanbaatar      MN  2017-12-08T00:00:00.000Z   \n",
       "\n",
       "                         local parameter       value   unit   latitude  \\\n",
       "0    2017-12-07T21:00:00-03:00      pm25     4.09000  µg/m³ -22.085519   \n",
       "1    2017-12-07T22:00:00-03:00      pm25     5.31000  µg/m³ -22.085519   \n",
       "2    2017-12-07T21:00:00-03:00       so2     1.30000  µg/m³ -22.085519   \n",
       "3    2017-12-07T21:00:00-03:00        o3    40.16000  µg/m³ -22.085519   \n",
       "4    2017-12-07T21:00:00-03:00       no2     1.53000  µg/m³ -22.085519   \n",
       "5    2017-12-07T21:00:00-03:00      pm10    23.43000  µg/m³ -22.085519   \n",
       "6    2017-12-07T21:00:00-03:00        co   556.86000  µg/m³ -22.085519   \n",
       "7    2017-12-07T21:00:00-03:00       so2     2.08000  µg/m³ -22.342264   \n",
       "8    2017-12-07T21:00:00-03:00       so2    57.00000  µg/m³ -32.776573   \n",
       "9    2017-12-07T21:00:00-03:00      pm25    38.65000  µg/m³ -36.735998   \n",
       "10   2017-12-07T21:00:00-03:00       so2    12.00000  µg/m³ -32.797715   \n",
       "11   2017-12-07T21:00:00-03:00      pm10    32.03000  µg/m³ -37.031702   \n",
       "12   2017-12-07T21:00:00-03:00       so2    13.00000  µg/m³ -32.779208   \n",
       "13   2017-12-07T21:00:00-03:00       so2     2.54000  µg/m³ -36.996431   \n",
       "14   2017-12-07T21:00:00-03:00       so2    13.00000  µg/m³ -32.823956   \n",
       "15   2017-12-08T01:00:00+01:00      pm25     2.98254  µg/m³  59.325519   \n",
       "16   2017-12-08T01:00:00+01:00       no2    51.89750  µg/m³  59.325519   \n",
       "17   2017-12-08T01:00:00+01:00       no2    37.97250  µg/m³        NaN   \n",
       "18   2017-12-08T01:00:00+01:00       no2    55.06750  µg/m³  59.443539   \n",
       "19   2017-12-08T01:00:00+01:00       no2    13.19100  µg/m³  59.237058   \n",
       "20   2017-12-08T01:00:00+01:00      pm10    14.18930  µg/m³  59.345161   \n",
       "21   2017-12-07T21:00:00-03:00      pm25     8.44000  µg/m³ -22.462145   \n",
       "22   2017-12-08T01:00:00+01:00      pm10     8.84325  µg/m³  60.671552   \n",
       "23   2017-12-08T01:00:00+01:00      pm10    10.67580  µg/m³  59.317132   \n",
       "24   2017-12-08T01:00:00+01:00      pm10    15.09910  µg/m³  59.314624   \n",
       "25   2017-12-08T01:00:00+01:00      pm10    10.47810  µg/m³  59.336356   \n",
       "26   2017-12-08T01:00:00+01:00      pm10     4.78873  µg/m³  59.198124   \n",
       "27   2017-12-08T01:00:00+01:00      pm10     8.33501  µg/m³  59.859530   \n",
       "28   2017-12-08T01:00:00+01:00      pm10    13.52280  µg/m³        NaN   \n",
       "29   2017-12-08T01:00:00+01:00      pm10    13.71500  µg/m³  59.325519   \n",
       "..                         ...       ...         ...    ...        ...   \n",
       "970  2017-12-08T03:00:00+03:00       so2     7.00000  µg/m³  39.918323   \n",
       "971  2017-12-08T03:00:00+03:00       no2    34.00000  µg/m³  39.918323   \n",
       "972  2017-12-08T03:00:00+03:00       so2     5.00000  µg/m³  39.967262   \n",
       "973  2017-12-08T03:00:00+03:00       so2     7.00000  µg/m³  39.927275   \n",
       "974  2017-12-08T03:00:00+03:00       no2    36.00000  µg/m³  40.546555   \n",
       "975  2017-12-08T03:00:00+03:00       no2     7.00000  µg/m³  39.918984   \n",
       "976  2017-12-08T03:00:00+03:00        o3    60.00000  µg/m³  40.033451   \n",
       "977  2017-12-08T03:00:00+03:00       no2    14.00000  µg/m³  39.908334   \n",
       "978  2017-12-08T03:00:00+03:00        co   865.00000  µg/m³  39.908334   \n",
       "979  2017-12-08T03:00:00+03:00       so2    13.00000  µg/m³  41.128889   \n",
       "980  2017-12-08T03:00:00+03:00       no2    92.00000  µg/m³  38.395833   \n",
       "981  2017-12-08T03:00:00+03:00        co   276.00000  µg/m³  38.395833   \n",
       "982  2017-12-08T03:00:00+03:00      pm10    59.00000  µg/m³  38.203741   \n",
       "983  2017-12-08T03:00:00+03:00      pm10    10.00000  µg/m³  40.600961   \n",
       "984  2017-12-08T08:00:00+08:00      pm10   141.00000  µg/m³  47.863943   \n",
       "985  2017-12-08T08:00:00+08:00       so2     4.00000  µg/m³  47.863943   \n",
       "986  2017-12-08T08:00:00+08:00       no2    14.00000  µg/m³  47.863943   \n",
       "987  2017-12-08T08:00:00+08:00      pm10   316.00000  µg/m³  47.929732   \n",
       "988  2017-12-08T08:00:00+08:00       so2    61.00000  µg/m³  47.929732   \n",
       "989  2017-12-08T08:00:00+08:00      pm25   131.00000  µg/m³  47.863943   \n",
       "990  2017-12-08T08:00:00+08:00        co  1554.00000  µg/m³  47.863943   \n",
       "991  2017-12-08T08:00:00+08:00        o3    15.00000  µg/m³  47.863943   \n",
       "992  2017-12-08T08:00:00+08:00      pm25   311.00000  µg/m³  47.929732   \n",
       "993  2017-12-08T08:00:00+08:00        co  7952.00000  µg/m³  47.929732   \n",
       "994  2017-12-08T08:00:00+08:00       no2    81.00000  µg/m³  47.929732   \n",
       "995  2017-12-08T08:00:00+08:00      pm10   175.00000  µg/m³  47.894339   \n",
       "996  2017-12-08T08:00:00+08:00       so2    18.00000  µg/m³  47.894339   \n",
       "997  2017-12-08T08:00:00+08:00        o3     2.00000  µg/m³  47.894339   \n",
       "998  2017-12-08T08:00:00+08:00       so2    22.00000  µg/m³  47.917606   \n",
       "999  2017-12-08T08:00:00+08:00      pm25    22.00000  µg/m³  47.917606   \n",
       "\n",
       "      longitude                                        attribution  \n",
       "0    -70.188683  [{\"name\":\"SINCA\",\"url\":\"http://sinca.mma.gob.c...  \n",
       "1    -70.188683  [{\"name\":\"SINCA\",\"url\":\"http://sinca.mma.gob.c...  \n",
       "2    -70.188683  [{\"name\":\"SINCA\",\"url\":\"http://sinca.mma.gob.c...  \n",
       "3    -70.188683  [{\"name\":\"SINCA\",\"url\":\"http://sinca.mma.gob.c...  \n",
       "4    -70.188683  [{\"name\":\"SINCA\",\"url\":\"http://sinca.mma.gob.c...  \n",
       "5    -70.188683  [{\"name\":\"SINCA\",\"url\":\"http://sinca.mma.gob.c...  \n",
       "6    -70.188683  [{\"name\":\"SINCA\",\"url\":\"http://sinca.mma.gob.c...  \n",
       "7    -68.650897  [{\"name\":\"SINCA\",\"url\":\"http://sinca.mma.gob.c...  \n",
       "8    -70.938144  [{\"name\":\"SINCA\",\"url\":\"http://sinca.mma.gob.c...  \n",
       "9    -73.118693  [{\"name\":\"SINCA\",\"url\":\"http://sinca.mma.gob.c...  \n",
       "10   -70.898037  [{\"name\":\"SINCA\",\"url\":\"http://sinca.mma.gob.c...  \n",
       "11   -73.138689  [{\"name\":\"SINCA\",\"url\":\"http://sinca.mma.gob.c...  \n",
       "12   -70.959114  [{\"name\":\"SINCA\",\"url\":\"http://sinca.mma.gob.c...  \n",
       "13   -73.115805  [{\"name\":\"SINCA\",\"url\":\"http://sinca.mma.gob.c...  \n",
       "14   -71.006441  [{\"name\":\"SINCA\",\"url\":\"http://sinca.mma.gob.c...  \n",
       "15    18.003961  [{\"name\":\"SLB\",\"url\":\"http://slb.nu/slbanalys/...  \n",
       "16    18.003961  [{\"name\":\"SLB\",\"url\":\"http://slb.nu/slbanalys/...  \n",
       "17          NaN  [{\"name\":\"SLB\",\"url\":\"http://slb.nu/slbanalys/...  \n",
       "18    17.922361  [{\"name\":\"SLB\",\"url\":\"http://slb.nu/slbanalys/...  \n",
       "19    17.838332  [{\"name\":\"SLB\",\"url\":\"http://slb.nu/slbanalys/...  \n",
       "20    18.054282  [{\"name\":\"SLB\",\"url\":\"http://slb.nu/slbanalys/...  \n",
       "21   -68.928062  [{\"name\":\"SINCA\",\"url\":\"http://sinca.mma.gob.c...  \n",
       "22    17.146915  [{\"name\":\"SLB\",\"url\":\"http://slb.nu/slbanalys/...  \n",
       "23    18.048787  [{\"name\":\"SLB\",\"url\":\"http://slb.nu/slbanalys/...  \n",
       "24    18.075856  [{\"name\":\"SLB\",\"url\":\"http://slb.nu/slbanalys/...  \n",
       "25    18.070626  [{\"name\":\"SLB\",\"url\":\"http://slb.nu/slbanalys/...  \n",
       "26    17.621087  [{\"name\":\"SLB\",\"url\":\"http://slb.nu/slbanalys/...  \n",
       "27    17.642484  [{\"name\":\"SLB\",\"url\":\"http://slb.nu/slbanalys/...  \n",
       "28          NaN  [{\"name\":\"SLB\",\"url\":\"http://slb.nu/slbanalys/...  \n",
       "29    18.003961  [{\"name\":\"SLB\",\"url\":\"http://slb.nu/slbanalys/...  \n",
       "..          ...                                                ...  \n",
       "970   32.822905  [{\"name\":\"National Air Quality Monitoring Netw...  \n",
       "971   32.822905  [{\"name\":\"National Air Quality Monitoring Netw...  \n",
       "972   32.862830  [{\"name\":\"National Air Quality Monitoring Netw...  \n",
       "973   32.859411  [{\"name\":\"National Air Quality Monitoring Netw...  \n",
       "974   34.967299  [{\"name\":\"National Air Quality Monitoring Netw...  \n",
       "975   41.271757  [{\"name\":\"National Air Quality Monitoring Netw...  \n",
       "976   41.572121  [{\"name\":\"National Air Quality Monitoring Netw...  \n",
       "977   41.273226  [{\"name\":\"National Air Quality Monitoring Netw...  \n",
       "978   41.273226  [{\"name\":\"National Air Quality Monitoring Netw...  \n",
       "979   29.049722  [{\"name\":\"National Air Quality Monitoring Netw...  \n",
       "980   27.082778  [{\"name\":\"National Air Quality Monitoring Netw...  \n",
       "981   27.082778  [{\"name\":\"National Air Quality Monitoring Netw...  \n",
       "982   37.198162  [{\"name\":\"National Air Quality Monitoring Netw...  \n",
       "983   43.096822  [{\"name\":\"National Air Quality Monitoring Netw...  \n",
       "984  106.779094  [{\"name\":\"Agaar.mn\",\"url\":\"http://agaar.mn/\"},...  \n",
       "985  106.779094  [{\"name\":\"Agaar.mn\",\"url\":\"http://agaar.mn/\"},...  \n",
       "986  106.779094  [{\"name\":\"Agaar.mn\",\"url\":\"http://agaar.mn/\"},...  \n",
       "987  106.888629  [{\"name\":\"Agaar.mn\",\"url\":\"http://agaar.mn/\"},...  \n",
       "988  106.888629  [{\"name\":\"Agaar.mn\",\"url\":\"http://agaar.mn/\"},...  \n",
       "989  106.779094  [{\"name\":\"Agaar.mn\",\"url\":\"http://agaar.mn/\"},...  \n",
       "990  106.779094  [{\"name\":\"Agaar.mn\",\"url\":\"http://agaar.mn/\"},...  \n",
       "991  106.779094  [{\"name\":\"Agaar.mn\",\"url\":\"http://agaar.mn/\"},...  \n",
       "992  106.888629  [{\"name\":\"Agaar.mn\",\"url\":\"http://agaar.mn/\"},...  \n",
       "993  106.888629  [{\"name\":\"Agaar.mn\",\"url\":\"http://agaar.mn/\"},...  \n",
       "994  106.888629  [{\"name\":\"Agaar.mn\",\"url\":\"http://agaar.mn/\"},...  \n",
       "995  106.882472  [{\"name\":\"Agaar.mn\",\"url\":\"http://agaar.mn/\"},...  \n",
       "996  106.882472  [{\"name\":\"Agaar.mn\",\"url\":\"http://agaar.mn/\"},...  \n",
       "997  106.882472  [{\"name\":\"Agaar.mn\",\"url\":\"http://agaar.mn/\"},...  \n",
       "998  106.937361  [{\"name\":\"Agaar.mn\",\"url\":\"http://agaar.mn/\"},...  \n",
       "999  106.937361  [{\"name\":\"Agaar.mn\",\"url\":\"http://agaar.mn/\"},...  \n",
       "\n",
       "[1000 rows x 11 columns]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec8.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add locations from these two sample days, make sure that further adds are successfully de-duped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"error\":[\"table \\\"open_aq_locations2\\\" does not exist\"]}\n"
     ]
    }
   ],
   "source": [
    "delete_table(\"open_aq_locations2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"error\":[\"You must indicate a sql query\"]}\n",
      "Deduping with target in mind: True\n",
      "Target table shape: (9356, 5)\n",
      "obs shape: (7271, 5)\n",
      "shared shape: (7271, 5)\n",
      "temp_df shape: (7271, 6)\n",
      "Number of new observations added to open_aq_locations2: 0\n",
      "Deduping with target in mind: True\n",
      "Target table shape: (9356, 5)\n",
      "obs shape: (7271, 5)\n",
      "shared shape: (7271, 5)\n",
      "temp_df shape: (7271, 6)\n",
      "Number of new observations added to open_aq_locations2: 0\n",
      "Deduping with target in mind: True\n",
      "Target table shape: (9356, 5)\n",
      "obs shape: (6864, 5)\n",
      "shared shape: (6864, 5)\n",
      "temp_df shape: (6864, 6)\n",
      "Number of new observations added to open_aq_locations2: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delete_table(\"open_aq_locations2\")\n",
    "\n",
    "kwargs = {\n",
    "    \"data_df\":dec8,\n",
    "    \"target_table_name\":\"open_aq_locations2\",\n",
    "    \"cols_and_types\":cols_and_types_locations,\n",
    "    \"cols_with_apostrophes\":[\"location\", \"city\",\"country\"],\n",
    "    \"float_cols_to_round\":[\"latitude\", \"longitude\"],\n",
    "    \"precision\":6,\n",
    "    \"datetime_column\":None,\n",
    "    \"datetime_cutoff\":None,\n",
    "    \"want_data_since_cutoff\":None,\n",
    "    \"dedupe_with_target\":True\n",
    "}\n",
    "\n",
    "update_table_without_duplicates(**kwargs)\n",
    "update_table_without_duplicates(**kwargs)\n",
    "\n",
    "kwargs = {\n",
    "    \"data_df\":dec9,\n",
    "    \"target_table_name\":\"open_aq_locations2\",\n",
    "    \"cols_and_types\":cols_and_types_locations,\n",
    "    \"cols_with_apostrophes\":[\"location\", \"city\",\"country\"],\n",
    "    \"float_cols_to_round\":[\"latitude\", \"longitude\"],\n",
    "    \"precision\":6,\n",
    "    \"datetime_column\":None,\n",
    "    \"datetime_cutoff\":None,\n",
    "    \"want_data_since_cutoff\":None,\n",
    "    \"dedupe_with_target\":True\n",
    "}\n",
    "\n",
    "update_table_without_duplicates(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add history of observations from these two sample days, make sure that further adds are successfully de-duped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deduping with target in mind: True\n",
      "Target table shape: (1840, 9)\n",
      "obs shape: (489096, 9)\n",
      "shared shape: (0, 9)\n",
      "temp_df shape: (489096, 10)\n",
      "Number of new observations added to open_aq_history: 489096\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Completed up until index: 60\n",
      "Completed up until index: 80\n",
      "Completed up until index: 100\n",
      "Completed up until index: 120\n",
      "Completed up until index: 140\n",
      "Completed up until index: 160\n",
      "Completed up until index: 180\n",
      "Completed up until index: 200\n",
      "Completed up until index: 220\n",
      "Completed up until index: 240\n",
      "Completed up until index: 260\n",
      "Completed up until index: 280\n",
      "Completed up until index: 300\n",
      "Completed up until index: 320\n",
      "Completed up until index: 340\n",
      "Completed up until index: 360\n",
      "Completed up until index: 380\n",
      "Completed up until index: 400\n",
      "Completed up until index: 420\n",
      "Completed up until index: 440\n",
      "Completed up until index: 460\n",
      "Completed up until index: 480\n",
      "Completed up until index: 500\n",
      "Completed up until index: 520\n",
      "Completed up until index: 540\n",
      "Completed up until index: 560\n",
      "Completed up until index: 580\n",
      "Completed up until index: 600\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-176-cadf478d43a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m }\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mupdate_table_without_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mupdate_table_without_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-168-27cbe4e60dbb>\u001b[0m in \u001b[0;36mupdate_table_without_duplicates\u001b[0;34m(data_df, target_table_name, cols_and_types, float_cols_to_round, precision, cols_with_apostrophes, datetime_column, datetime_cutoff, want_data_since_cutoff, dedupe_with_target)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnumber_new_observations\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;31m# Add genuinely new observations to the existing table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mupdate_in_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_table_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols_and_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols_with_apostrophes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;31m# Return number of new observations for logging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-168-27cbe4e60dbb>\u001b[0m in \u001b[0;36mupdate_in_batches\u001b[0;34m(data_df, batch_size, target_table_name, cols_and_types, cols_with_apostrophes)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;31m# Create Insert SQL statement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minsert_into_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_table_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols_and_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;31m# Help with trouble shooting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-168-27cbe4e60dbb>\u001b[0m in \u001b[0;36minsert_into_table\u001b[0;34m(data_df, target_table_name, column_names, cols_and_types)\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[0;34m\"\"\"Craft insert statement for Carto table\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\", \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdump_row_contents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols_and_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m     insert_value_sql = \"\"\"\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, broadcast, raw, reduce, args, **kwds)\u001b[0m\n\u001b[1;32m   4260\u001b[0m                         \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4261\u001b[0m                         \u001b[0mreduce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4262\u001b[0;31m                         ignore_failures=ignore_failures)\n\u001b[0m\u001b[1;32m   4263\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4264\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_broadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_apply_standard\u001b[0;34m(self, func, axis, ignore_failures, reduce)\u001b[0m\n\u001b[1;32m   4316\u001b[0m                     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_agg_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4317\u001b[0m                     result = lib.reduce(values, func, axis=axis, dummy=dummy,\n\u001b[0;32m-> 4318\u001b[0;31m                                         labels=labels)\n\u001b[0m\u001b[1;32m   4319\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4320\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/src/reduce.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.reduce (pandas/_libs/lib.c:44036)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/src/reduce.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.Reducer.get_result (pandas/_libs/lib.c:33629)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-168-27cbe4e60dbb>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[0;34m\"\"\"Craft insert statement for Carto table\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\", \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdump_row_contents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols_and_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m     insert_value_sql = \"\"\"\n",
      "\u001b[0;32m<ipython-input-168-27cbe4e60dbb>\u001b[0m in \u001b[0;36mdump_row_contents\u001b[0;34m(row, cols_and_types)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mix\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcols_and_types\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"varchar\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mdump\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"'\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"',\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mcols_and_types\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"timestamp\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0;31m# This is particular to the OpenAQ application\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   2460\u001b[0m         \u001b[0;31m# if we have something that is Index-like, then\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2461\u001b[0m         \u001b[0;31m# use this, e.g. DatetimeIndex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2462\u001b[0;31m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_values'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2463\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2464\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_values\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;34m\"\"\" return the internal repr of this data \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternal_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36minternal_values\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   4220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4221\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minternal_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4222\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_block\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternal_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4224\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m_block\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   4122\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4124\u001b[0;31m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4125\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4126\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "kwargs = {\n",
    "    \"data_df\":dec8,\n",
    "    \"target_table_name\":\"open_aq_history\",\n",
    "    \"cols_and_types\":cols_and_types_history,\n",
    "    \"cols_with_apostrophes\":[\"location\", \"city\", \"country\"],\n",
    "    \"float_cols_to_round\":[\"latitude\", \"longitude\", \"value\"],\n",
    "    \"precision\":6,\n",
    "    \"datetime_column\":\"utc\",\n",
    "    \"datetime_cutoff\":None,\n",
    "    \"want_data_since_cutoff\":None,\n",
    "    \"dedupe_with_target\":True\n",
    "}\n",
    "\n",
    "update_table_without_duplicates(**kwargs)\n",
    "update_table_without_duplicates(**kwargs)\n",
    "\n",
    "kwargs = {\n",
    "    \"data_df\":dec9,\n",
    "    \"target_table_name\":\"open_aq_history\",\n",
    "    \"cols_and_types\":cols_and_types_history,\n",
    "    \"cols_with_apostrophes\":[\"location\", \"city\", \"country\"],\n",
    "    \"float_cols_to_round\":[\"latitude\", \"longitude\", \"value\"],\n",
    "    \"precision\":6,\n",
    "    \"datetime_column\":\"utc\",\n",
    "    \"datetime_cutoff\":None,\n",
    "    \"want_data_since_cutoff\":None,\n",
    "    \"dedupe_with_target\":True\n",
    "}\n",
    "\n",
    "update_table_without_duplicates(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>utc</th>\n",
       "      <th>local</th>\n",
       "      <th>parameter</th>\n",
       "      <th>value</th>\n",
       "      <th>unit</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>attribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3060</th>\n",
       "      <td>100 ail</td>\n",
       "      <td>Ulaanbaatar</td>\n",
       "      <td>MN</td>\n",
       "      <td>2017-12-08T01:00:00.000Z</td>\n",
       "      <td>2017-12-08T09:00:00+08:00</td>\n",
       "      <td>co</td>\n",
       "      <td>1591.0</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>47.932906</td>\n",
       "      <td>106.921383</td>\n",
       "      <td>[{\"name\":\"Agaar.mn\",\"url\":\"http://agaar.mn/\"},...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5626</th>\n",
       "      <td>100 ail</td>\n",
       "      <td>Ulaanbaatar</td>\n",
       "      <td>MN</td>\n",
       "      <td>2017-12-08T01:45:00.000Z</td>\n",
       "      <td>2017-12-08T09:45:00+08:00</td>\n",
       "      <td>co</td>\n",
       "      <td>1717.0</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>47.932906</td>\n",
       "      <td>106.921383</td>\n",
       "      <td>[{\"name\":\"Agaar.mn\",\"url\":\"http://agaar.mn/\"},...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7573</th>\n",
       "      <td>100 ail</td>\n",
       "      <td>Ulaanbaatar</td>\n",
       "      <td>MN</td>\n",
       "      <td>2017-12-08T02:15:00.000Z</td>\n",
       "      <td>2017-12-08T10:15:00+08:00</td>\n",
       "      <td>co</td>\n",
       "      <td>1888.0</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>47.932906</td>\n",
       "      <td>106.921383</td>\n",
       "      <td>[{\"name\":\"Agaar.mn\",\"url\":\"http://agaar.mn/\"},...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10561</th>\n",
       "      <td>100 ail</td>\n",
       "      <td>Ulaanbaatar</td>\n",
       "      <td>MN</td>\n",
       "      <td>2017-12-08T02:45:00.000Z</td>\n",
       "      <td>2017-12-08T10:45:00+08:00</td>\n",
       "      <td>co</td>\n",
       "      <td>1854.0</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>47.932906</td>\n",
       "      <td>106.921383</td>\n",
       "      <td>[{\"name\":\"Agaar.mn\",\"url\":\"http://agaar.mn/\"},...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15337</th>\n",
       "      <td>100 ail</td>\n",
       "      <td>Ulaanbaatar</td>\n",
       "      <td>MN</td>\n",
       "      <td>2017-12-08T03:45:00.000Z</td>\n",
       "      <td>2017-12-08T11:45:00+08:00</td>\n",
       "      <td>co</td>\n",
       "      <td>1854.0</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>47.932906</td>\n",
       "      <td>106.921383</td>\n",
       "      <td>[{\"name\":\"Agaar.mn\",\"url\":\"http://agaar.mn/\"},...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17724</th>\n",
       "      <td>100 ail</td>\n",
       "      <td>Ulaanbaatar</td>\n",
       "      <td>MN</td>\n",
       "      <td>2017-12-08T04:15:00.000Z</td>\n",
       "      <td>2017-12-08T12:15:00+08:00</td>\n",
       "      <td>co</td>\n",
       "      <td>2688.0</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>47.932906</td>\n",
       "      <td>106.921383</td>\n",
       "      <td>[{\"name\":\"Agaar.mn\",\"url\":\"http://agaar.mn/\"},...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21442</th>\n",
       "      <td>100 ail</td>\n",
       "      <td>Ulaanbaatar</td>\n",
       "      <td>MN</td>\n",
       "      <td>2017-12-08T05:00:00.000Z</td>\n",
       "      <td>2017-12-08T13:00:00+08:00</td>\n",
       "      <td>co</td>\n",
       "      <td>2950.0</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>47.932906</td>\n",
       "      <td>106.921383</td>\n",
       "      <td>[{\"name\":\"Agaar.mn\",\"url\":\"http://agaar.mn/\"},...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26759</th>\n",
       "      <td>100 ail</td>\n",
       "      <td>Ulaanbaatar</td>\n",
       "      <td>MN</td>\n",
       "      <td>2017-12-08T05:45:00.000Z</td>\n",
       "      <td>2017-12-08T13:45:00+08:00</td>\n",
       "      <td>co</td>\n",
       "      <td>1421.0</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>47.932906</td>\n",
       "      <td>106.921383</td>\n",
       "      <td>[{\"name\":\"Agaar.mn\",\"url\":\"http://agaar.mn/\"},...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29583</th>\n",
       "      <td>100 ail</td>\n",
       "      <td>Ulaanbaatar</td>\n",
       "      <td>MN</td>\n",
       "      <td>2017-12-08T06:30:00.000Z</td>\n",
       "      <td>2017-12-08T14:30:00+08:00</td>\n",
       "      <td>co</td>\n",
       "      <td>981.0</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>47.932906</td>\n",
       "      <td>106.921383</td>\n",
       "      <td>[{\"name\":\"Agaar.mn\",\"url\":\"http://agaar.mn/\"},...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29751</th>\n",
       "      <td>100 ail</td>\n",
       "      <td>Ulaanbaatar</td>\n",
       "      <td>MN</td>\n",
       "      <td>2017-12-08T06:45:00.000Z</td>\n",
       "      <td>2017-12-08T14:45:00+08:00</td>\n",
       "      <td>co</td>\n",
       "      <td>925.0</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>47.932906</td>\n",
       "      <td>106.921383</td>\n",
       "      <td>[{\"name\":\"Agaar.mn\",\"url\":\"http://agaar.mn/\"},...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48056</th>\n",
       "      <td>100 ail</td>\n",
       "      <td>Ulaanbaatar</td>\n",
       "      <td>MN</td>\n",
       "      <td>2017-12-08T07:30:00.000Z</td>\n",
       "      <td>2017-12-08T15:30:00+08:00</td>\n",
       "      <td>co</td>\n",
       "      <td>881.0</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>47.932906</td>\n",
       "      <td>106.921383</td>\n",
       "      <td>[{\"name\":\"Agaar.mn\",\"url\":\"http://agaar.mn/\"},...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55897</th>\n",
       "      <td>100 ail</td>\n",
       "      <td>Ulaanbaatar</td>\n",
       "      <td>MN</td>\n",
       "      <td>2017-12-08T08:30:00.000Z</td>\n",
       "      <td>2017-12-08T16:30:00+08:00</td>\n",
       "      <td>co</td>\n",
       "      <td>788.0</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>47.932906</td>\n",
       "      <td>106.921383</td>\n",
       "      <td>[{\"name\":\"Agaar.mn\",\"url\":\"http://agaar.mn/\"},...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57959</th>\n",
       "      <td>100 ail</td>\n",
       "      <td>Ulaanbaatar</td>\n",
       "      <td>MN</td>\n",
       "      <td>2017-12-08T09:15:00.000Z</td>\n",
       "      <td>2017-12-08T17:15:00+08:00</td>\n",
       "      <td>co</td>\n",
       "      <td>1275.0</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>47.932906</td>\n",
       "      <td>106.921383</td>\n",
       "      <td>[{\"name\":\"Agaar.mn\",\"url\":\"http://agaar.mn/\"},...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74276</th>\n",
       "      <td>100 ail</td>\n",
       "      <td>Ulaanbaatar</td>\n",
       "      <td>MN</td>\n",
       "      <td>2017-12-08T10:45:00.000Z</td>\n",
       "      <td>2017-12-08T18:45:00+08:00</td>\n",
       "      <td>co</td>\n",
       "      <td>3771.0</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>47.932906</td>\n",
       "      <td>106.921383</td>\n",
       "      <td>[{\"name\":\"Agaar.mn\",\"url\":\"http://agaar.mn/\"},...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74357</th>\n",
       "      <td>100 ail</td>\n",
       "      <td>Ulaanbaatar</td>\n",
       "      <td>MN</td>\n",
       "      <td>2017-12-08T11:00:00.000Z</td>\n",
       "      <td>2017-12-08T19:00:00+08:00</td>\n",
       "      <td>co</td>\n",
       "      <td>3694.0</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>47.932906</td>\n",
       "      <td>106.921383</td>\n",
       "      <td>[{\"name\":\"Agaar.mn\",\"url\":\"http://agaar.mn/\"},...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75986</th>\n",
       "      <td>100 ail</td>\n",
       "      <td>Ulaanbaatar</td>\n",
       "      <td>MN</td>\n",
       "      <td>2017-12-08T11:30:00.000Z</td>\n",
       "      <td>2017-12-08T19:30:00+08:00</td>\n",
       "      <td>co</td>\n",
       "      <td>3056.0</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>47.932906</td>\n",
       "      <td>106.921383</td>\n",
       "      <td>[{\"name\":\"Agaar.mn\",\"url\":\"http://agaar.mn/\"},...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99035</th>\n",
       "      <td>100 ail</td>\n",
       "      <td>Ulaanbaatar</td>\n",
       "      <td>MN</td>\n",
       "      <td>2017-12-08T18:45:00.000Z</td>\n",
       "      <td>2017-12-09T02:45:00+08:00</td>\n",
       "      <td>co</td>\n",
       "      <td>3656.0</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>47.932906</td>\n",
       "      <td>106.921383</td>\n",
       "      <td>[{\"name\":\"Agaar.mn\",\"url\":\"http://agaar.mn/\"},...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105028</th>\n",
       "      <td>100 ail</td>\n",
       "      <td>Ulaanbaatar</td>\n",
       "      <td>MN</td>\n",
       "      <td>2017-12-08T19:30:00.000Z</td>\n",
       "      <td>2017-12-09T03:30:00+08:00</td>\n",
       "      <td>co</td>\n",
       "      <td>3506.0</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>47.932906</td>\n",
       "      <td>106.921383</td>\n",
       "      <td>[{\"name\":\"Agaar.mn\",\"url\":\"http://agaar.mn/\"},...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109705</th>\n",
       "      <td>100 ail</td>\n",
       "      <td>Ulaanbaatar</td>\n",
       "      <td>MN</td>\n",
       "      <td>2017-12-08T20:30:00.000Z</td>\n",
       "      <td>2017-12-09T04:30:00+08:00</td>\n",
       "      <td>co</td>\n",
       "      <td>5263.0</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>47.932906</td>\n",
       "      <td>106.921383</td>\n",
       "      <td>[{\"name\":\"Agaar.mn\",\"url\":\"http://agaar.mn/\"},...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114471</th>\n",
       "      <td>100 ail</td>\n",
       "      <td>Ulaanbaatar</td>\n",
       "      <td>MN</td>\n",
       "      <td>2017-12-08T21:00:00.000Z</td>\n",
       "      <td>2017-12-09T05:00:00+08:00</td>\n",
       "      <td>co</td>\n",
       "      <td>4966.0</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>47.932906</td>\n",
       "      <td>106.921383</td>\n",
       "      <td>[{\"name\":\"Agaar.mn\",\"url\":\"http://agaar.mn/\"},...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       location         city country                       utc  \\\n",
       "3060    100 ail  Ulaanbaatar      MN  2017-12-08T01:00:00.000Z   \n",
       "5626    100 ail  Ulaanbaatar      MN  2017-12-08T01:45:00.000Z   \n",
       "7573    100 ail  Ulaanbaatar      MN  2017-12-08T02:15:00.000Z   \n",
       "10561   100 ail  Ulaanbaatar      MN  2017-12-08T02:45:00.000Z   \n",
       "15337   100 ail  Ulaanbaatar      MN  2017-12-08T03:45:00.000Z   \n",
       "17724   100 ail  Ulaanbaatar      MN  2017-12-08T04:15:00.000Z   \n",
       "21442   100 ail  Ulaanbaatar      MN  2017-12-08T05:00:00.000Z   \n",
       "26759   100 ail  Ulaanbaatar      MN  2017-12-08T05:45:00.000Z   \n",
       "29583   100 ail  Ulaanbaatar      MN  2017-12-08T06:30:00.000Z   \n",
       "29751   100 ail  Ulaanbaatar      MN  2017-12-08T06:45:00.000Z   \n",
       "48056   100 ail  Ulaanbaatar      MN  2017-12-08T07:30:00.000Z   \n",
       "55897   100 ail  Ulaanbaatar      MN  2017-12-08T08:30:00.000Z   \n",
       "57959   100 ail  Ulaanbaatar      MN  2017-12-08T09:15:00.000Z   \n",
       "74276   100 ail  Ulaanbaatar      MN  2017-12-08T10:45:00.000Z   \n",
       "74357   100 ail  Ulaanbaatar      MN  2017-12-08T11:00:00.000Z   \n",
       "75986   100 ail  Ulaanbaatar      MN  2017-12-08T11:30:00.000Z   \n",
       "99035   100 ail  Ulaanbaatar      MN  2017-12-08T18:45:00.000Z   \n",
       "105028  100 ail  Ulaanbaatar      MN  2017-12-08T19:30:00.000Z   \n",
       "109705  100 ail  Ulaanbaatar      MN  2017-12-08T20:30:00.000Z   \n",
       "114471  100 ail  Ulaanbaatar      MN  2017-12-08T21:00:00.000Z   \n",
       "\n",
       "                            local parameter   value   unit   latitude  \\\n",
       "3060    2017-12-08T09:00:00+08:00        co  1591.0  µg/m³  47.932906   \n",
       "5626    2017-12-08T09:45:00+08:00        co  1717.0  µg/m³  47.932906   \n",
       "7573    2017-12-08T10:15:00+08:00        co  1888.0  µg/m³  47.932906   \n",
       "10561   2017-12-08T10:45:00+08:00        co  1854.0  µg/m³  47.932906   \n",
       "15337   2017-12-08T11:45:00+08:00        co  1854.0  µg/m³  47.932906   \n",
       "17724   2017-12-08T12:15:00+08:00        co  2688.0  µg/m³  47.932906   \n",
       "21442   2017-12-08T13:00:00+08:00        co  2950.0  µg/m³  47.932906   \n",
       "26759   2017-12-08T13:45:00+08:00        co  1421.0  µg/m³  47.932906   \n",
       "29583   2017-12-08T14:30:00+08:00        co   981.0  µg/m³  47.932906   \n",
       "29751   2017-12-08T14:45:00+08:00        co   925.0  µg/m³  47.932906   \n",
       "48056   2017-12-08T15:30:00+08:00        co   881.0  µg/m³  47.932906   \n",
       "55897   2017-12-08T16:30:00+08:00        co   788.0  µg/m³  47.932906   \n",
       "57959   2017-12-08T17:15:00+08:00        co  1275.0  µg/m³  47.932906   \n",
       "74276   2017-12-08T18:45:00+08:00        co  3771.0  µg/m³  47.932906   \n",
       "74357   2017-12-08T19:00:00+08:00        co  3694.0  µg/m³  47.932906   \n",
       "75986   2017-12-08T19:30:00+08:00        co  3056.0  µg/m³  47.932906   \n",
       "99035   2017-12-09T02:45:00+08:00        co  3656.0  µg/m³  47.932906   \n",
       "105028  2017-12-09T03:30:00+08:00        co  3506.0  µg/m³  47.932906   \n",
       "109705  2017-12-09T04:30:00+08:00        co  5263.0  µg/m³  47.932906   \n",
       "114471  2017-12-09T05:00:00+08:00        co  4966.0  µg/m³  47.932906   \n",
       "\n",
       "         longitude                                        attribution  \n",
       "3060    106.921383  [{\"name\":\"Agaar.mn\",\"url\":\"http://agaar.mn/\"},...  \n",
       "5626    106.921383  [{\"name\":\"Agaar.mn\",\"url\":\"http://agaar.mn/\"},...  \n",
       "7573    106.921383  [{\"name\":\"Agaar.mn\",\"url\":\"http://agaar.mn/\"},...  \n",
       "10561   106.921383  [{\"name\":\"Agaar.mn\",\"url\":\"http://agaar.mn/\"},...  \n",
       "15337   106.921383  [{\"name\":\"Agaar.mn\",\"url\":\"http://agaar.mn/\"},...  \n",
       "17724   106.921383  [{\"name\":\"Agaar.mn\",\"url\":\"http://agaar.mn/\"},...  \n",
       "21442   106.921383  [{\"name\":\"Agaar.mn\",\"url\":\"http://agaar.mn/\"},...  \n",
       "26759   106.921383  [{\"name\":\"Agaar.mn\",\"url\":\"http://agaar.mn/\"},...  \n",
       "29583   106.921383  [{\"name\":\"Agaar.mn\",\"url\":\"http://agaar.mn/\"},...  \n",
       "29751   106.921383  [{\"name\":\"Agaar.mn\",\"url\":\"http://agaar.mn/\"},...  \n",
       "48056   106.921383  [{\"name\":\"Agaar.mn\",\"url\":\"http://agaar.mn/\"},...  \n",
       "55897   106.921383  [{\"name\":\"Agaar.mn\",\"url\":\"http://agaar.mn/\"},...  \n",
       "57959   106.921383  [{\"name\":\"Agaar.mn\",\"url\":\"http://agaar.mn/\"},...  \n",
       "74276   106.921383  [{\"name\":\"Agaar.mn\",\"url\":\"http://agaar.mn/\"},...  \n",
       "74357   106.921383  [{\"name\":\"Agaar.mn\",\"url\":\"http://agaar.mn/\"},...  \n",
       "75986   106.921383  [{\"name\":\"Agaar.mn\",\"url\":\"http://agaar.mn/\"},...  \n",
       "99035   106.921383  [{\"name\":\"Agaar.mn\",\"url\":\"http://agaar.mn/\"},...  \n",
       "105028  106.921383  [{\"name\":\"Agaar.mn\",\"url\":\"http://agaar.mn/\"},...  \n",
       "109705  106.921383  [{\"name\":\"Agaar.mn\",\"url\":\"http://agaar.mn/\"},...  \n",
       "114471  106.921383  [{\"name\":\"Agaar.mn\",\"url\":\"http://agaar.mn/\"},...  "
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec8.sort_values(by=[\"location\", \"city\", \"country\", \"parameter\"]).head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>latitude</th>\n",
       "      <th>location</th>\n",
       "      <th>longitude</th>\n",
       "      <th>parameter</th>\n",
       "      <th>unit</th>\n",
       "      <th>utc</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>Kocaeli</td>\n",
       "      <td>TR</td>\n",
       "      <td>40.771010</td>\n",
       "      <td>Alikahya-MTHM</td>\n",
       "      <td>30.007700</td>\n",
       "      <td>no2</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>2017-12-08T00:00:00Z</td>\n",
       "      <td>-1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>Kocaeli</td>\n",
       "      <td>TR</td>\n",
       "      <td>40.771010</td>\n",
       "      <td>Alikahya-MTHM</td>\n",
       "      <td>30.007700</td>\n",
       "      <td>no2</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>2017-12-08T00:00:00Z</td>\n",
       "      <td>-1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>Kocaeli</td>\n",
       "      <td>TR</td>\n",
       "      <td>40.771010</td>\n",
       "      <td>Alikahya-MTHM</td>\n",
       "      <td>30.007700</td>\n",
       "      <td>pm10</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>2017-12-08T00:00:00Z</td>\n",
       "      <td>49.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>Kocaeli</td>\n",
       "      <td>TR</td>\n",
       "      <td>40.771010</td>\n",
       "      <td>Alikahya-MTHM</td>\n",
       "      <td>30.007700</td>\n",
       "      <td>pm10</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>2017-12-08T00:00:00Z</td>\n",
       "      <td>49.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>Kocaeli</td>\n",
       "      <td>TR</td>\n",
       "      <td>40.771010</td>\n",
       "      <td>Alikahya-MTHM</td>\n",
       "      <td>30.007700</td>\n",
       "      <td>so2</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>2017-12-08T00:00:00Z</td>\n",
       "      <td>6.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>Kocaeli</td>\n",
       "      <td>TR</td>\n",
       "      <td>40.771010</td>\n",
       "      <td>Alikahya-MTHM</td>\n",
       "      <td>30.007700</td>\n",
       "      <td>so2</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>2017-12-08T00:00:00Z</td>\n",
       "      <td>6.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>Yalova</td>\n",
       "      <td>TR</td>\n",
       "      <td>40.700580</td>\n",
       "      <td>Altınova-MTHM</td>\n",
       "      <td>29.507850</td>\n",
       "      <td>no2</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>2017-12-08T00:00:00Z</td>\n",
       "      <td>15.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820</th>\n",
       "      <td>Yalova</td>\n",
       "      <td>TR</td>\n",
       "      <td>40.700580</td>\n",
       "      <td>Altınova-MTHM</td>\n",
       "      <td>29.507850</td>\n",
       "      <td>no2</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>2017-12-08T00:00:00Z</td>\n",
       "      <td>15.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>Yalova</td>\n",
       "      <td>TR</td>\n",
       "      <td>40.700580</td>\n",
       "      <td>Altınova-MTHM</td>\n",
       "      <td>29.507850</td>\n",
       "      <td>o3</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>2017-12-08T00:00:00Z</td>\n",
       "      <td>52.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>Yalova</td>\n",
       "      <td>TR</td>\n",
       "      <td>40.700580</td>\n",
       "      <td>Altınova-MTHM</td>\n",
       "      <td>29.507850</td>\n",
       "      <td>o3</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>2017-12-08T00:00:00Z</td>\n",
       "      <td>52.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>Yalova</td>\n",
       "      <td>TR</td>\n",
       "      <td>40.700580</td>\n",
       "      <td>Altınova-MTHM</td>\n",
       "      <td>29.507850</td>\n",
       "      <td>so2</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>2017-12-08T00:00:00Z</td>\n",
       "      <td>8.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>Yalova</td>\n",
       "      <td>TR</td>\n",
       "      <td>40.700580</td>\n",
       "      <td>Altınova-MTHM</td>\n",
       "      <td>29.507850</td>\n",
       "      <td>so2</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>2017-12-08T00:00:00Z</td>\n",
       "      <td>8.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>臺南市</td>\n",
       "      <td>TW</td>\n",
       "      <td>23.048333</td>\n",
       "      <td>Annan</td>\n",
       "      <td>120.218333</td>\n",
       "      <td>co</td>\n",
       "      <td>ppm</td>\n",
       "      <td>2017-12-08T00:00:00Z</td>\n",
       "      <td>0.3200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>臺南市</td>\n",
       "      <td>TW</td>\n",
       "      <td>23.048333</td>\n",
       "      <td>Annan</td>\n",
       "      <td>120.218333</td>\n",
       "      <td>co</td>\n",
       "      <td>ppm</td>\n",
       "      <td>2017-12-08T00:00:00Z</td>\n",
       "      <td>0.3200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>臺南市</td>\n",
       "      <td>TW</td>\n",
       "      <td>23.048333</td>\n",
       "      <td>Annan</td>\n",
       "      <td>120.218333</td>\n",
       "      <td>no2</td>\n",
       "      <td>ppm</td>\n",
       "      <td>2017-12-08T00:00:00Z</td>\n",
       "      <td>0.0120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>臺南市</td>\n",
       "      <td>TW</td>\n",
       "      <td>23.048333</td>\n",
       "      <td>Annan</td>\n",
       "      <td>120.218333</td>\n",
       "      <td>no2</td>\n",
       "      <td>ppm</td>\n",
       "      <td>2017-12-08T00:00:00Z</td>\n",
       "      <td>0.0120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>臺南市</td>\n",
       "      <td>TW</td>\n",
       "      <td>23.048333</td>\n",
       "      <td>Annan</td>\n",
       "      <td>120.218333</td>\n",
       "      <td>o3</td>\n",
       "      <td>ppm</td>\n",
       "      <td>2017-12-08T00:00:00Z</td>\n",
       "      <td>0.0320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>臺南市</td>\n",
       "      <td>TW</td>\n",
       "      <td>23.048333</td>\n",
       "      <td>Annan</td>\n",
       "      <td>120.218333</td>\n",
       "      <td>o3</td>\n",
       "      <td>ppm</td>\n",
       "      <td>2017-12-08T00:00:00Z</td>\n",
       "      <td>0.0320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>臺南市</td>\n",
       "      <td>TW</td>\n",
       "      <td>23.048333</td>\n",
       "      <td>Annan</td>\n",
       "      <td>120.218333</td>\n",
       "      <td>pm10</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>2017-12-08T00:00:00Z</td>\n",
       "      <td>28.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>臺南市</td>\n",
       "      <td>TW</td>\n",
       "      <td>23.048333</td>\n",
       "      <td>Annan</td>\n",
       "      <td>120.218333</td>\n",
       "      <td>pm10</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>2017-12-08T00:00:00Z</td>\n",
       "      <td>28.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>臺南市</td>\n",
       "      <td>TW</td>\n",
       "      <td>23.048333</td>\n",
       "      <td>Annan</td>\n",
       "      <td>120.218333</td>\n",
       "      <td>pm25</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>2017-12-08T00:00:00Z</td>\n",
       "      <td>14.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>臺南市</td>\n",
       "      <td>TW</td>\n",
       "      <td>23.048333</td>\n",
       "      <td>Annan</td>\n",
       "      <td>120.218333</td>\n",
       "      <td>pm25</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>2017-12-08T00:00:00Z</td>\n",
       "      <td>14.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>臺南市</td>\n",
       "      <td>TW</td>\n",
       "      <td>23.048333</td>\n",
       "      <td>Annan</td>\n",
       "      <td>120.218333</td>\n",
       "      <td>so2</td>\n",
       "      <td>ppm</td>\n",
       "      <td>2017-12-08T00:00:00Z</td>\n",
       "      <td>0.0015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>臺南市</td>\n",
       "      <td>TW</td>\n",
       "      <td>23.048333</td>\n",
       "      <td>Annan</td>\n",
       "      <td>120.218333</td>\n",
       "      <td>so2</td>\n",
       "      <td>ppm</td>\n",
       "      <td>2017-12-08T00:00:00Z</td>\n",
       "      <td>0.0015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>Yalova</td>\n",
       "      <td>TR</td>\n",
       "      <td>40.529350</td>\n",
       "      <td>Armutlu-MTHM</td>\n",
       "      <td>28.784590</td>\n",
       "      <td>no2</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>2017-12-08T00:00:00Z</td>\n",
       "      <td>15.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>Yalova</td>\n",
       "      <td>TR</td>\n",
       "      <td>40.529350</td>\n",
       "      <td>Armutlu-MTHM</td>\n",
       "      <td>28.784590</td>\n",
       "      <td>no2</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>2017-12-08T00:00:00Z</td>\n",
       "      <td>15.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Yalova</td>\n",
       "      <td>TR</td>\n",
       "      <td>40.529350</td>\n",
       "      <td>Armutlu-MTHM</td>\n",
       "      <td>28.784590</td>\n",
       "      <td>o3</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>2017-12-08T00:00:00Z</td>\n",
       "      <td>44.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>Yalova</td>\n",
       "      <td>TR</td>\n",
       "      <td>40.529350</td>\n",
       "      <td>Armutlu-MTHM</td>\n",
       "      <td>28.784590</td>\n",
       "      <td>o3</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>2017-12-08T00:00:00Z</td>\n",
       "      <td>44.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Yalova</td>\n",
       "      <td>TR</td>\n",
       "      <td>40.529350</td>\n",
       "      <td>Armutlu-MTHM</td>\n",
       "      <td>28.784590</td>\n",
       "      <td>pm10</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>2017-12-08T00:00:00Z</td>\n",
       "      <td>14.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>Yalova</td>\n",
       "      <td>TR</td>\n",
       "      <td>40.529350</td>\n",
       "      <td>Armutlu-MTHM</td>\n",
       "      <td>28.784590</td>\n",
       "      <td>pm10</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>2017-12-08T00:00:00Z</td>\n",
       "      <td>14.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>İstanbul</td>\n",
       "      <td>TR</td>\n",
       "      <td>41.024420</td>\n",
       "      <td>Ümraniye-MTHM</td>\n",
       "      <td>29.099730</td>\n",
       "      <td>pm10</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>2017-12-08T00:00:00Z</td>\n",
       "      <td>25.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>İstanbul</td>\n",
       "      <td>TR</td>\n",
       "      <td>41.024420</td>\n",
       "      <td>Ümraniye-MTHM</td>\n",
       "      <td>29.099730</td>\n",
       "      <td>pm10</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>2017-12-08T00:00:00Z</td>\n",
       "      <td>25.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>İstanbul</td>\n",
       "      <td>TR</td>\n",
       "      <td>41.024420</td>\n",
       "      <td>Ümraniye-MTHM</td>\n",
       "      <td>29.099730</td>\n",
       "      <td>so2</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>2017-12-08T00:00:00Z</td>\n",
       "      <td>6.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>İstanbul</td>\n",
       "      <td>TR</td>\n",
       "      <td>41.024420</td>\n",
       "      <td>Ümraniye-MTHM</td>\n",
       "      <td>29.099730</td>\n",
       "      <td>so2</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>2017-12-08T00:00:00Z</td>\n",
       "      <td>6.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Bursa</td>\n",
       "      <td>TR</td>\n",
       "      <td>40.080890</td>\n",
       "      <td>İnegöl-MTHM</td>\n",
       "      <td>29.500240</td>\n",
       "      <td>no2</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>2017-12-08T00:00:00Z</td>\n",
       "      <td>33.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>Bursa</td>\n",
       "      <td>TR</td>\n",
       "      <td>40.080890</td>\n",
       "      <td>İnegöl-MTHM</td>\n",
       "      <td>29.500240</td>\n",
       "      <td>no2</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>2017-12-08T00:00:00Z</td>\n",
       "      <td>33.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Bursa</td>\n",
       "      <td>TR</td>\n",
       "      <td>40.080890</td>\n",
       "      <td>İnegöl-MTHM</td>\n",
       "      <td>29.500240</td>\n",
       "      <td>pm10</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>2017-12-08T00:00:00Z</td>\n",
       "      <td>70.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>Bursa</td>\n",
       "      <td>TR</td>\n",
       "      <td>40.080890</td>\n",
       "      <td>İnegöl-MTHM</td>\n",
       "      <td>29.500240</td>\n",
       "      <td>pm10</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>2017-12-08T00:00:00Z</td>\n",
       "      <td>70.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Bursa</td>\n",
       "      <td>TR</td>\n",
       "      <td>40.080890</td>\n",
       "      <td>İnegöl-MTHM</td>\n",
       "      <td>29.500240</td>\n",
       "      <td>so2</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>2017-12-08T00:00:00Z</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>Bursa</td>\n",
       "      <td>TR</td>\n",
       "      <td>40.080890</td>\n",
       "      <td>İnegöl-MTHM</td>\n",
       "      <td>29.500240</td>\n",
       "      <td>so2</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>2017-12-08T00:00:00Z</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Kocaeli</td>\n",
       "      <td>TR</td>\n",
       "      <td>40.768110</td>\n",
       "      <td>İzmit-MTHM</td>\n",
       "      <td>29.938120</td>\n",
       "      <td>co</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>2017-12-08T00:00:00Z</td>\n",
       "      <td>2849.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>Kocaeli</td>\n",
       "      <td>TR</td>\n",
       "      <td>40.768110</td>\n",
       "      <td>İzmit-MTHM</td>\n",
       "      <td>29.938120</td>\n",
       "      <td>co</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>2017-12-08T00:00:00Z</td>\n",
       "      <td>2849.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Kocaeli</td>\n",
       "      <td>TR</td>\n",
       "      <td>40.768110</td>\n",
       "      <td>İzmit-MTHM</td>\n",
       "      <td>29.938120</td>\n",
       "      <td>no2</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>2017-12-08T00:00:00Z</td>\n",
       "      <td>57.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>Kocaeli</td>\n",
       "      <td>TR</td>\n",
       "      <td>40.768110</td>\n",
       "      <td>İzmit-MTHM</td>\n",
       "      <td>29.938120</td>\n",
       "      <td>no2</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>2017-12-08T00:00:00Z</td>\n",
       "      <td>57.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>Kocaeli</td>\n",
       "      <td>TR</td>\n",
       "      <td>40.768110</td>\n",
       "      <td>İzmit-MTHM</td>\n",
       "      <td>29.938120</td>\n",
       "      <td>pm10</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>2017-12-08T00:00:00Z</td>\n",
       "      <td>116.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>Kocaeli</td>\n",
       "      <td>TR</td>\n",
       "      <td>40.768110</td>\n",
       "      <td>İzmit-MTHM</td>\n",
       "      <td>29.938120</td>\n",
       "      <td>pm10</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>2017-12-08T00:00:00Z</td>\n",
       "      <td>116.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>İstanbul</td>\n",
       "      <td>TR</td>\n",
       "      <td>41.170460</td>\n",
       "      <td>Şile-MTHM</td>\n",
       "      <td>29.563360</td>\n",
       "      <td>no2</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>2017-12-08T00:00:00Z</td>\n",
       "      <td>21.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>İstanbul</td>\n",
       "      <td>TR</td>\n",
       "      <td>41.170460</td>\n",
       "      <td>Şile-MTHM</td>\n",
       "      <td>29.563360</td>\n",
       "      <td>no2</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>2017-12-08T00:00:00Z</td>\n",
       "      <td>21.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>İstanbul</td>\n",
       "      <td>TR</td>\n",
       "      <td>41.170460</td>\n",
       "      <td>Şile-MTHM</td>\n",
       "      <td>29.563360</td>\n",
       "      <td>o3</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>2017-12-08T00:00:00Z</td>\n",
       "      <td>16.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>İstanbul</td>\n",
       "      <td>TR</td>\n",
       "      <td>41.170460</td>\n",
       "      <td>Şile-MTHM</td>\n",
       "      <td>29.563360</td>\n",
       "      <td>o3</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>2017-12-08T00:00:00Z</td>\n",
       "      <td>16.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>İstanbul</td>\n",
       "      <td>TR</td>\n",
       "      <td>41.170460</td>\n",
       "      <td>Şile-MTHM</td>\n",
       "      <td>29.563360</td>\n",
       "      <td>pm10</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>2017-12-08T00:00:00Z</td>\n",
       "      <td>45.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>İstanbul</td>\n",
       "      <td>TR</td>\n",
       "      <td>41.170460</td>\n",
       "      <td>Şile-MTHM</td>\n",
       "      <td>29.563360</td>\n",
       "      <td>pm10</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>2017-12-08T00:00:00Z</td>\n",
       "      <td>45.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>İstanbul</td>\n",
       "      <td>TR</td>\n",
       "      <td>41.002450</td>\n",
       "      <td>Şirinevler-MTHM</td>\n",
       "      <td>28.838660</td>\n",
       "      <td>co</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>2017-12-08T00:00:00Z</td>\n",
       "      <td>245.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>İstanbul</td>\n",
       "      <td>TR</td>\n",
       "      <td>41.002450</td>\n",
       "      <td>Şirinevler-MTHM</td>\n",
       "      <td>28.838660</td>\n",
       "      <td>co</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>2017-12-08T00:00:00Z</td>\n",
       "      <td>245.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>İstanbul</td>\n",
       "      <td>TR</td>\n",
       "      <td>41.002450</td>\n",
       "      <td>Şirinevler-MTHM</td>\n",
       "      <td>28.838660</td>\n",
       "      <td>no2</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>2017-12-08T00:00:00Z</td>\n",
       "      <td>48.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>İstanbul</td>\n",
       "      <td>TR</td>\n",
       "      <td>41.002450</td>\n",
       "      <td>Şirinevler-MTHM</td>\n",
       "      <td>28.838660</td>\n",
       "      <td>no2</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>2017-12-08T00:00:00Z</td>\n",
       "      <td>48.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>İstanbul</td>\n",
       "      <td>TR</td>\n",
       "      <td>41.002450</td>\n",
       "      <td>Şirinevler-MTHM</td>\n",
       "      <td>28.838660</td>\n",
       "      <td>pm10</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>2017-12-08T00:00:00Z</td>\n",
       "      <td>28.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>İstanbul</td>\n",
       "      <td>TR</td>\n",
       "      <td>41.002450</td>\n",
       "      <td>Şirinevler-MTHM</td>\n",
       "      <td>28.838660</td>\n",
       "      <td>pm10</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>2017-12-08T00:00:00Z</td>\n",
       "      <td>28.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>İstanbul</td>\n",
       "      <td>TR</td>\n",
       "      <td>41.002450</td>\n",
       "      <td>Şirinevler-MTHM</td>\n",
       "      <td>28.838660</td>\n",
       "      <td>so2</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>2017-12-08T00:00:00Z</td>\n",
       "      <td>5.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>İstanbul</td>\n",
       "      <td>TR</td>\n",
       "      <td>41.002450</td>\n",
       "      <td>Şirinevler-MTHM</td>\n",
       "      <td>28.838660</td>\n",
       "      <td>so2</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>2017-12-08T00:00:00Z</td>\n",
       "      <td>5.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1280 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         city country   latitude         location   longitude parameter  \\\n",
       "152   Kocaeli      TR  40.771010    Alikahya-MTHM   30.007700       no2   \n",
       "812   Kocaeli      TR  40.771010    Alikahya-MTHM   30.007700       no2   \n",
       "151   Kocaeli      TR  40.771010    Alikahya-MTHM   30.007700      pm10   \n",
       "811   Kocaeli      TR  40.771010    Alikahya-MTHM   30.007700      pm10   \n",
       "157   Kocaeli      TR  40.771010    Alikahya-MTHM   30.007700       so2   \n",
       "817   Kocaeli      TR  40.771010    Alikahya-MTHM   30.007700       so2   \n",
       "160    Yalova      TR  40.700580    Altınova-MTHM   29.507850       no2   \n",
       "820    Yalova      TR  40.700580    Altınova-MTHM   29.507850       no2   \n",
       "147    Yalova      TR  40.700580    Altınova-MTHM   29.507850        o3   \n",
       "807    Yalova      TR  40.700580    Altınova-MTHM   29.507850        o3   \n",
       "161    Yalova      TR  40.700580    Altınova-MTHM   29.507850       so2   \n",
       "821    Yalova      TR  40.700580    Altınova-MTHM   29.507850       so2   \n",
       "247       臺南市      TW  23.048333            Annan  120.218333        co   \n",
       "907       臺南市      TW  23.048333            Annan  120.218333        co   \n",
       "240       臺南市      TW  23.048333            Annan  120.218333       no2   \n",
       "900       臺南市      TW  23.048333            Annan  120.218333       no2   \n",
       "238       臺南市      TW  23.048333            Annan  120.218333        o3   \n",
       "898       臺南市      TW  23.048333            Annan  120.218333        o3   \n",
       "260       臺南市      TW  23.048333            Annan  120.218333      pm10   \n",
       "920       臺南市      TW  23.048333            Annan  120.218333      pm10   \n",
       "234       臺南市      TW  23.048333            Annan  120.218333      pm25   \n",
       "894       臺南市      TW  23.048333            Annan  120.218333      pm25   \n",
       "237       臺南市      TW  23.048333            Annan  120.218333       so2   \n",
       "897       臺南市      TW  23.048333            Annan  120.218333       so2   \n",
       "148    Yalova      TR  40.529350     Armutlu-MTHM   28.784590       no2   \n",
       "808    Yalova      TR  40.529350     Armutlu-MTHM   28.784590       no2   \n",
       "43     Yalova      TR  40.529350     Armutlu-MTHM   28.784590        o3   \n",
       "703    Yalova      TR  40.529350     Armutlu-MTHM   28.784590        o3   \n",
       "42     Yalova      TR  40.529350     Armutlu-MTHM   28.784590      pm10   \n",
       "702    Yalova      TR  40.529350     Armutlu-MTHM   28.784590      pm10   \n",
       "..        ...     ...        ...              ...         ...       ...   \n",
       "120  İstanbul      TR  41.024420    Ümraniye-MTHM   29.099730      pm10   \n",
       "780  İstanbul      TR  41.024420    Ümraniye-MTHM   29.099730      pm10   \n",
       "74   İstanbul      TR  41.024420    Ümraniye-MTHM   29.099730       so2   \n",
       "734  İstanbul      TR  41.024420    Ümraniye-MTHM   29.099730       so2   \n",
       "59      Bursa      TR  40.080890      İnegöl-MTHM   29.500240       no2   \n",
       "719     Bursa      TR  40.080890      İnegöl-MTHM   29.500240       no2   \n",
       "51      Bursa      TR  40.080890      İnegöl-MTHM   29.500240      pm10   \n",
       "711     Bursa      TR  40.080890      İnegöl-MTHM   29.500240      pm10   \n",
       "84      Bursa      TR  40.080890      İnegöl-MTHM   29.500240       so2   \n",
       "744     Bursa      TR  40.080890      İnegöl-MTHM   29.500240       so2   \n",
       "121   Kocaeli      TR  40.768110       İzmit-MTHM   29.938120        co   \n",
       "781   Kocaeli      TR  40.768110       İzmit-MTHM   29.938120        co   \n",
       "101   Kocaeli      TR  40.768110       İzmit-MTHM   29.938120       no2   \n",
       "761   Kocaeli      TR  40.768110       İzmit-MTHM   29.938120       no2   \n",
       "138   Kocaeli      TR  40.768110       İzmit-MTHM   29.938120      pm10   \n",
       "798   Kocaeli      TR  40.768110       İzmit-MTHM   29.938120      pm10   \n",
       "72   İstanbul      TR  41.170460        Şile-MTHM   29.563360       no2   \n",
       "732  İstanbul      TR  41.170460        Şile-MTHM   29.563360       no2   \n",
       "71   İstanbul      TR  41.170460        Şile-MTHM   29.563360        o3   \n",
       "731  İstanbul      TR  41.170460        Şile-MTHM   29.563360        o3   \n",
       "70   İstanbul      TR  41.170460        Şile-MTHM   29.563360      pm10   \n",
       "730  İstanbul      TR  41.170460        Şile-MTHM   29.563360      pm10   \n",
       "96   İstanbul      TR  41.002450  Şirinevler-MTHM   28.838660        co   \n",
       "756  İstanbul      TR  41.002450  Şirinevler-MTHM   28.838660        co   \n",
       "95   İstanbul      TR  41.002450  Şirinevler-MTHM   28.838660       no2   \n",
       "755  İstanbul      TR  41.002450  Şirinevler-MTHM   28.838660       no2   \n",
       "73   İstanbul      TR  41.002450  Şirinevler-MTHM   28.838660      pm10   \n",
       "733  İstanbul      TR  41.002450  Şirinevler-MTHM   28.838660      pm10   \n",
       "134  İstanbul      TR  41.002450  Şirinevler-MTHM   28.838660       so2   \n",
       "794  İstanbul      TR  41.002450  Şirinevler-MTHM   28.838660       so2   \n",
       "\n",
       "      unit                   utc      value  \n",
       "152  µg/m³  2017-12-08T00:00:00Z    -1.0000  \n",
       "812  µg/m³  2017-12-08T00:00:00Z    -1.0000  \n",
       "151  µg/m³  2017-12-08T00:00:00Z    49.0000  \n",
       "811  µg/m³  2017-12-08T00:00:00Z    49.0000  \n",
       "157  µg/m³  2017-12-08T00:00:00Z     6.0000  \n",
       "817  µg/m³  2017-12-08T00:00:00Z     6.0000  \n",
       "160  µg/m³  2017-12-08T00:00:00Z    15.0000  \n",
       "820  µg/m³  2017-12-08T00:00:00Z    15.0000  \n",
       "147  µg/m³  2017-12-08T00:00:00Z    52.0000  \n",
       "807  µg/m³  2017-12-08T00:00:00Z    52.0000  \n",
       "161  µg/m³  2017-12-08T00:00:00Z     8.0000  \n",
       "821  µg/m³  2017-12-08T00:00:00Z     8.0000  \n",
       "247    ppm  2017-12-08T00:00:00Z     0.3200  \n",
       "907    ppm  2017-12-08T00:00:00Z     0.3200  \n",
       "240    ppm  2017-12-08T00:00:00Z     0.0120  \n",
       "900    ppm  2017-12-08T00:00:00Z     0.0120  \n",
       "238    ppm  2017-12-08T00:00:00Z     0.0320  \n",
       "898    ppm  2017-12-08T00:00:00Z     0.0320  \n",
       "260  µg/m³  2017-12-08T00:00:00Z    28.0000  \n",
       "920  µg/m³  2017-12-08T00:00:00Z    28.0000  \n",
       "234  µg/m³  2017-12-08T00:00:00Z    14.0000  \n",
       "894  µg/m³  2017-12-08T00:00:00Z    14.0000  \n",
       "237    ppm  2017-12-08T00:00:00Z     0.0015  \n",
       "897    ppm  2017-12-08T00:00:00Z     0.0015  \n",
       "148  µg/m³  2017-12-08T00:00:00Z    15.0000  \n",
       "808  µg/m³  2017-12-08T00:00:00Z    15.0000  \n",
       "43   µg/m³  2017-12-08T00:00:00Z    44.0000  \n",
       "703  µg/m³  2017-12-08T00:00:00Z    44.0000  \n",
       "42   µg/m³  2017-12-08T00:00:00Z    14.0000  \n",
       "702  µg/m³  2017-12-08T00:00:00Z    14.0000  \n",
       "..     ...                   ...        ...  \n",
       "120  µg/m³  2017-12-08T00:00:00Z    25.0000  \n",
       "780  µg/m³  2017-12-08T00:00:00Z    25.0000  \n",
       "74   µg/m³  2017-12-08T00:00:00Z     6.0000  \n",
       "734  µg/m³  2017-12-08T00:00:00Z     6.0000  \n",
       "59   µg/m³  2017-12-08T00:00:00Z    33.0000  \n",
       "719  µg/m³  2017-12-08T00:00:00Z    33.0000  \n",
       "51   µg/m³  2017-12-08T00:00:00Z    70.0000  \n",
       "711  µg/m³  2017-12-08T00:00:00Z    70.0000  \n",
       "84   µg/m³  2017-12-08T00:00:00Z     0.0000  \n",
       "744  µg/m³  2017-12-08T00:00:00Z     0.0000  \n",
       "121  µg/m³  2017-12-08T00:00:00Z  2849.0000  \n",
       "781  µg/m³  2017-12-08T00:00:00Z  2849.0000  \n",
       "101  µg/m³  2017-12-08T00:00:00Z    57.0000  \n",
       "761  µg/m³  2017-12-08T00:00:00Z    57.0000  \n",
       "138  µg/m³  2017-12-08T00:00:00Z   116.0000  \n",
       "798  µg/m³  2017-12-08T00:00:00Z   116.0000  \n",
       "72   µg/m³  2017-12-08T00:00:00Z    21.0000  \n",
       "732  µg/m³  2017-12-08T00:00:00Z    21.0000  \n",
       "71   µg/m³  2017-12-08T00:00:00Z    16.0000  \n",
       "731  µg/m³  2017-12-08T00:00:00Z    16.0000  \n",
       "70   µg/m³  2017-12-08T00:00:00Z    45.0000  \n",
       "730  µg/m³  2017-12-08T00:00:00Z    45.0000  \n",
       "96   µg/m³  2017-12-08T00:00:00Z   245.0000  \n",
       "756  µg/m³  2017-12-08T00:00:00Z   245.0000  \n",
       "95   µg/m³  2017-12-08T00:00:00Z    48.0000  \n",
       "755  µg/m³  2017-12-08T00:00:00Z    48.0000  \n",
       "73   µg/m³  2017-12-08T00:00:00Z    28.0000  \n",
       "733  µg/m³  2017-12-08T00:00:00Z    28.0000  \n",
       "134  µg/m³  2017-12-08T00:00:00Z     5.0000  \n",
       "794  µg/m³  2017-12-08T00:00:00Z     5.0000  \n",
       "\n",
       "[1280 rows x 9 columns]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = pd.DataFrame(select_from_table(\"open_aq_history\").json()[\"rows\"])\n",
    "#duped = history.duplicated(keep=False)\n",
    "#print(\"num duped:\", duped.sum())\n",
    "#history.loc[duped].sort_values(by=[\"location\", \"city\", \"country\", \"parameter\"])\n",
    "history.sort_values(by=[\"location\", \"city\", \"country\", \"parameter\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2017-12-08T00:00:00Z', '2017-12-08T01:00:00Z',\n",
       "       '2017-12-08T02:00:00Z'], dtype=object)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history[\"utc\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop over all CSVs in the OpenAQ record and capture the unique locations.\n",
    "\n",
    "Locations are included as long as they have the same \"location\", \"city\", \"country\" fields, and their \"latitude\" and \"longitude\" fields are equal to 6 significant figures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2015-06-29.csv',\n",
       " '2015-06-30.csv',\n",
       " '2015-07-01.csv',\n",
       " '2015-07-02.csv',\n",
       " '2015-07-03.csv',\n",
       " '2015-07-04.csv',\n",
       " '2015-07-06.csv',\n",
       " '2015-07-07.csv',\n",
       " '2015-07-08.csv',\n",
       " '2015-07-09.csv',\n",
       " '2015-07-10.csv',\n",
       " '2015-07-11.csv',\n",
       " '2015-07-12.csv',\n",
       " '2015-07-13.csv',\n",
       " '2015-07-14.csv',\n",
       " '2015-07-15.csv',\n",
       " '2015-07-16.csv',\n",
       " '2015-07-17.csv',\n",
       " '2015-07-18.csv',\n",
       " '2015-07-20.csv',\n",
       " '2015-07-21.csv',\n",
       " '2015-07-22.csv',\n",
       " '2015-07-23.csv',\n",
       " '2015-07-24.csv',\n",
       " '2015-08-02.csv',\n",
       " '2015-08-03.csv',\n",
       " '2015-08-04.csv',\n",
       " '2015-08-05.csv',\n",
       " '2015-08-06.csv',\n",
       " '2015-08-07.csv',\n",
       " '2015-08-08.csv',\n",
       " '2015-08-09.csv',\n",
       " '2015-08-10.csv',\n",
       " '2015-08-11.csv',\n",
       " '2015-08-12.csv',\n",
       " '2015-08-13.csv',\n",
       " '2015-08-14.csv',\n",
       " '2015-08-15.csv',\n",
       " '2015-08-16.csv',\n",
       " '2015-08-17.csv',\n",
       " '2015-08-18.csv',\n",
       " '2015-08-19.csv',\n",
       " '2015-08-20.csv',\n",
       " '2015-08-21.csv',\n",
       " '2015-08-22.csv',\n",
       " '2015-08-23.csv',\n",
       " '2015-08-24.csv',\n",
       " '2015-08-25.csv',\n",
       " '2015-08-26.csv',\n",
       " '2015-08-27.csv',\n",
       " '2015-08-28.csv',\n",
       " '2015-08-29.csv',\n",
       " '2015-08-30.csv',\n",
       " '2015-08-31.csv',\n",
       " '2015-09-01.csv',\n",
       " '2015-09-02.csv',\n",
       " '2015-09-03.csv',\n",
       " '2015-09-04.csv',\n",
       " '2015-09-05.csv',\n",
       " '2015-09-06.csv',\n",
       " '2015-09-07.csv',\n",
       " '2015-09-08.csv',\n",
       " '2015-09-09.csv',\n",
       " '2015-09-10.csv',\n",
       " '2015-09-11.csv',\n",
       " '2015-09-12.csv',\n",
       " '2015-09-13.csv',\n",
       " '2015-09-14.csv',\n",
       " '2015-09-15.csv',\n",
       " '2015-09-16.csv',\n",
       " '2015-09-17.csv',\n",
       " '2015-09-18.csv',\n",
       " '2015-09-19.csv',\n",
       " '2015-09-20.csv',\n",
       " '2015-09-21.csv',\n",
       " '2015-09-22.csv',\n",
       " '2015-09-23.csv',\n",
       " '2015-09-24.csv',\n",
       " '2015-09-25.csv',\n",
       " '2015-09-26.csv',\n",
       " '2015-09-27.csv',\n",
       " '2015-09-28.csv',\n",
       " '2015-09-29.csv',\n",
       " '2015-09-30.csv',\n",
       " '2015-10-01.csv',\n",
       " '2015-10-02.csv',\n",
       " '2015-10-03.csv',\n",
       " '2015-10-04.csv',\n",
       " '2015-10-05.csv',\n",
       " '2015-10-06.csv',\n",
       " '2015-10-07.csv',\n",
       " '2015-10-08.csv',\n",
       " '2015-10-09.csv',\n",
       " '2015-10-10.csv',\n",
       " '2015-10-11.csv',\n",
       " '2015-10-12.csv',\n",
       " '2015-10-13.csv',\n",
       " '2015-10-14.csv',\n",
       " '2015-10-15.csv',\n",
       " '2015-10-16.csv',\n",
       " '2015-10-17.csv',\n",
       " '2015-10-18.csv',\n",
       " '2015-10-19.csv',\n",
       " '2015-10-20.csv',\n",
       " '2015-10-21.csv',\n",
       " '2015-10-22.csv',\n",
       " '2015-10-23.csv',\n",
       " '2015-10-24.csv',\n",
       " '2015-10-25.csv',\n",
       " '2015-10-26.csv',\n",
       " '2015-10-27.csv',\n",
       " '2015-10-28.csv',\n",
       " '2015-10-29.csv',\n",
       " '2015-10-30.csv',\n",
       " '2015-10-31.csv',\n",
       " '2015-11-01.csv',\n",
       " '2015-11-02.csv',\n",
       " '2015-11-03.csv',\n",
       " '2015-11-04.csv',\n",
       " '2015-11-05.csv',\n",
       " '2015-11-06.csv',\n",
       " '2015-11-07.csv',\n",
       " '2015-11-08.csv',\n",
       " '2015-11-09.csv',\n",
       " '2015-11-10.csv',\n",
       " '2015-11-11.csv',\n",
       " '2015-11-12.csv',\n",
       " '2015-11-13.csv',\n",
       " '2015-11-14.csv',\n",
       " '2015-11-15.csv',\n",
       " '2015-11-16.csv',\n",
       " '2015-11-17.csv',\n",
       " '2015-11-18.csv',\n",
       " '2015-11-19.csv',\n",
       " '2015-11-20.csv',\n",
       " '2015-11-21.csv',\n",
       " '2015-11-22.csv',\n",
       " '2015-11-23.csv',\n",
       " '2015-11-24.csv',\n",
       " '2015-11-25.csv',\n",
       " '2015-11-26.csv',\n",
       " '2015-11-27.csv',\n",
       " '2015-11-28.csv',\n",
       " '2015-11-29.csv',\n",
       " '2015-11-30.csv',\n",
       " '2015-12-01.csv',\n",
       " '2015-12-02.csv',\n",
       " '2015-12-03.csv',\n",
       " '2015-12-04.csv',\n",
       " '2015-12-05.csv',\n",
       " '2015-12-06.csv',\n",
       " '2015-12-07.csv',\n",
       " '2015-12-08.csv',\n",
       " '2015-12-09.csv',\n",
       " '2015-12-10.csv',\n",
       " '2015-12-11.csv',\n",
       " '2015-12-12.csv',\n",
       " '2015-12-13.csv',\n",
       " '2015-12-14.csv',\n",
       " '2015-12-15.csv',\n",
       " '2015-12-16.csv',\n",
       " '2015-12-17.csv',\n",
       " '2015-12-18.csv',\n",
       " '2015-12-19.csv',\n",
       " '2015-12-20.csv',\n",
       " '2015-12-21.csv',\n",
       " '2015-12-22.csv',\n",
       " '2015-12-23.csv',\n",
       " '2015-12-24.csv',\n",
       " '2015-12-25.csv',\n",
       " '2015-12-26.csv',\n",
       " '2015-12-27.csv',\n",
       " '2015-12-28.csv',\n",
       " '2015-12-29.csv',\n",
       " '2015-12-30.csv',\n",
       " '2016-01-03.csv',\n",
       " '2016-01-04.csv',\n",
       " '2016-01-05.csv',\n",
       " '2016-01-06.csv',\n",
       " '2016-01-07.csv',\n",
       " '2016-01-08.csv',\n",
       " '2016-01-09.csv',\n",
       " '2016-01-10.csv',\n",
       " '2016-01-11.csv',\n",
       " '2016-01-12.csv',\n",
       " '2016-01-13.csv',\n",
       " '2016-01-14.csv',\n",
       " '2016-01-15.csv',\n",
       " '2016-01-16.csv',\n",
       " '2016-01-17.csv',\n",
       " '2016-01-18.csv',\n",
       " '2016-01-19.csv',\n",
       " '2016-01-20.csv',\n",
       " '2016-01-21.csv',\n",
       " '2016-01-22.csv',\n",
       " '2016-01-23.csv',\n",
       " '2016-01-24.csv',\n",
       " '2016-01-25.csv',\n",
       " '2016-01-26.csv',\n",
       " '2016-01-27.csv',\n",
       " '2016-01-28.csv',\n",
       " '2016-01-29.csv',\n",
       " '2016-01-30.csv',\n",
       " '2016-01-31.csv',\n",
       " '2016-02-01.csv',\n",
       " '2016-02-02.csv',\n",
       " '2016-02-03.csv',\n",
       " '2016-02-04.csv',\n",
       " '2016-02-05.csv',\n",
       " '2016-02-06.csv',\n",
       " '2016-02-07.csv',\n",
       " '2016-02-08.csv',\n",
       " '2016-02-09.csv',\n",
       " '2016-02-10.csv',\n",
       " '2016-02-11.csv',\n",
       " '2016-02-12.csv',\n",
       " '2016-02-13.csv',\n",
       " '2016-02-14.csv',\n",
       " '2016-02-15.csv',\n",
       " '2016-02-16.csv',\n",
       " '2016-02-17.csv',\n",
       " '2016-02-18.csv',\n",
       " '2016-02-19.csv',\n",
       " '2016-02-20.csv',\n",
       " '2016-02-21.csv',\n",
       " '2016-02-22.csv',\n",
       " '2016-02-23.csv',\n",
       " '2016-02-24.csv',\n",
       " '2016-02-25.csv',\n",
       " '2016-02-26.csv',\n",
       " '2016-02-27.csv',\n",
       " '2016-02-28.csv',\n",
       " '2016-02-29.csv',\n",
       " '2016-03-01.csv',\n",
       " '2016-03-02.csv',\n",
       " '2016-03-03.csv',\n",
       " '2016-03-04.csv',\n",
       " '2016-03-05.csv',\n",
       " '2016-03-06.csv',\n",
       " '2016-03-07.csv',\n",
       " '2016-03-08.csv',\n",
       " '2016-03-09.csv',\n",
       " '2016-03-10.csv',\n",
       " '2016-03-11.csv',\n",
       " '2016-03-12.csv',\n",
       " '2016-03-13.csv',\n",
       " '2016-03-14.csv',\n",
       " '2016-03-15.csv',\n",
       " '2016-03-16.csv',\n",
       " '2016-03-17.csv',\n",
       " '2016-03-18.csv',\n",
       " '2016-03-19.csv',\n",
       " '2016-03-20.csv',\n",
       " '2016-03-21.csv',\n",
       " '2016-03-22.csv',\n",
       " '2016-03-23.csv',\n",
       " '2016-03-24.csv',\n",
       " '2016-03-25.csv',\n",
       " '2016-03-26.csv',\n",
       " '2016-03-27.csv',\n",
       " '2016-03-28.csv',\n",
       " '2016-03-29.csv',\n",
       " '2016-03-30.csv',\n",
       " '2016-03-31.csv',\n",
       " '2016-04-01.csv',\n",
       " '2016-04-02.csv',\n",
       " '2016-04-03.csv',\n",
       " '2016-04-04.csv',\n",
       " '2016-04-05.csv',\n",
       " '2016-04-06.csv',\n",
       " '2016-04-07.csv',\n",
       " '2016-04-08.csv',\n",
       " '2016-04-09.csv',\n",
       " '2016-04-10.csv',\n",
       " '2016-04-11.csv',\n",
       " '2016-04-12.csv',\n",
       " '2016-04-13.csv',\n",
       " '2016-04-14.csv',\n",
       " '2016-04-15.csv',\n",
       " '2016-04-16.csv',\n",
       " '2016-04-17.csv',\n",
       " '2016-04-18.csv',\n",
       " '2016-04-19.csv',\n",
       " '2016-04-20.csv',\n",
       " '2016-04-21.csv',\n",
       " '2016-04-22.csv',\n",
       " '2016-04-23.csv',\n",
       " '2016-04-24.csv',\n",
       " '2016-04-25.csv',\n",
       " '2016-04-26.csv',\n",
       " '2016-04-27.csv',\n",
       " '2016-04-28.csv',\n",
       " '2016-04-29.csv',\n",
       " '2016-04-30.csv',\n",
       " '2016-05-01.csv',\n",
       " '2016-05-02.csv',\n",
       " '2016-05-03.csv',\n",
       " '2016-05-04.csv',\n",
       " '2016-05-05.csv',\n",
       " '2016-05-06.csv',\n",
       " '2016-05-07.csv',\n",
       " '2016-05-08.csv',\n",
       " '2016-05-09.csv',\n",
       " '2016-05-10.csv',\n",
       " '2016-05-11.csv',\n",
       " '2016-05-12.csv',\n",
       " '2016-05-13.csv',\n",
       " '2016-05-14.csv',\n",
       " '2016-05-15.csv',\n",
       " '2016-05-16.csv',\n",
       " '2016-05-17.csv',\n",
       " '2016-05-18.csv',\n",
       " '2016-05-19.csv',\n",
       " '2016-05-20.csv',\n",
       " '2016-05-21.csv',\n",
       " '2016-05-22.csv',\n",
       " '2016-05-23.csv',\n",
       " '2016-05-24.csv',\n",
       " '2016-05-25.csv',\n",
       " '2016-05-26.csv',\n",
       " '2016-05-27.csv',\n",
       " '2016-05-28.csv',\n",
       " '2016-05-29.csv',\n",
       " '2016-05-30.csv',\n",
       " '2016-05-31.csv',\n",
       " '2016-06-01.csv',\n",
       " '2016-06-02.csv',\n",
       " '2016-06-03.csv',\n",
       " '2016-06-04.csv',\n",
       " '2016-06-05.csv',\n",
       " '2016-06-06.csv',\n",
       " '2016-06-07.csv',\n",
       " '2016-06-08.csv',\n",
       " '2016-06-09.csv',\n",
       " '2016-06-10.csv',\n",
       " '2016-06-11.csv',\n",
       " '2016-06-12.csv',\n",
       " '2016-06-13.csv',\n",
       " '2016-06-14.csv',\n",
       " '2016-06-15.csv',\n",
       " '2016-06-16.csv',\n",
       " '2016-06-17.csv',\n",
       " '2016-06-18.csv',\n",
       " '2016-06-19.csv',\n",
       " '2016-06-20.csv',\n",
       " '2016-06-21.csv',\n",
       " '2016-06-22.csv',\n",
       " '2016-06-23.csv',\n",
       " '2016-06-24.csv',\n",
       " '2016-06-25.csv',\n",
       " '2016-06-26.csv',\n",
       " '2016-06-27.csv',\n",
       " '2016-06-28.csv',\n",
       " '2016-06-29.csv',\n",
       " '2016-06-30.csv',\n",
       " '2016-07-01.csv',\n",
       " '2016-07-02.csv',\n",
       " '2016-07-03.csv',\n",
       " '2016-07-04.csv',\n",
       " '2016-07-05.csv',\n",
       " '2016-07-06.csv',\n",
       " '2016-07-07.csv',\n",
       " '2016-07-08.csv',\n",
       " '2016-07-09.csv',\n",
       " '2016-07-10.csv',\n",
       " '2016-07-11.csv',\n",
       " '2016-07-12.csv',\n",
       " '2016-07-13.csv',\n",
       " '2016-07-14.csv',\n",
       " '2016-07-15.csv',\n",
       " '2016-07-16.csv',\n",
       " '2016-07-17.csv',\n",
       " '2016-07-18.csv',\n",
       " '2016-07-19.csv',\n",
       " '2016-07-20.csv',\n",
       " '2016-07-21.csv',\n",
       " '2016-07-22.csv',\n",
       " '2016-07-23.csv',\n",
       " '2016-07-24.csv',\n",
       " '2016-07-25.csv',\n",
       " '2016-07-26.csv',\n",
       " '2016-07-27.csv',\n",
       " '2016-07-28.csv',\n",
       " '2016-07-29.csv',\n",
       " '2016-07-30.csv',\n",
       " '2016-07-31.csv',\n",
       " '2016-08-01.csv',\n",
       " '2016-08-02.csv',\n",
       " '2016-08-03.csv',\n",
       " '2016-08-04.csv',\n",
       " '2016-08-05.csv',\n",
       " '2016-08-06.csv',\n",
       " '2016-08-07.csv',\n",
       " '2016-08-08.csv',\n",
       " '2016-08-09.csv',\n",
       " '2016-08-10.csv',\n",
       " '2016-08-11.csv',\n",
       " '2016-08-12.csv',\n",
       " '2016-08-13.csv',\n",
       " '2016-08-14.csv',\n",
       " '2016-08-15.csv',\n",
       " '2016-08-16.csv',\n",
       " '2016-08-17.csv',\n",
       " '2016-08-18.csv',\n",
       " '2016-08-19.csv',\n",
       " '2016-08-20.csv',\n",
       " '2016-08-21.csv',\n",
       " '2016-08-22.csv',\n",
       " '2016-08-23.csv',\n",
       " '2016-08-24.csv',\n",
       " '2016-08-25.csv',\n",
       " '2016-08-26.csv',\n",
       " '2016-08-27.csv',\n",
       " '2016-08-28.csv',\n",
       " '2016-08-29.csv',\n",
       " '2016-08-30.csv',\n",
       " '2016-08-31.csv',\n",
       " '2016-09-01.csv',\n",
       " '2016-09-02.csv',\n",
       " '2016-09-03.csv',\n",
       " '2016-09-04.csv',\n",
       " '2016-09-05.csv',\n",
       " '2016-09-06.csv',\n",
       " '2016-09-07.csv',\n",
       " '2016-09-08.csv',\n",
       " '2016-09-09.csv',\n",
       " '2016-09-10.csv',\n",
       " '2016-09-11.csv',\n",
       " '2016-09-12.csv',\n",
       " '2016-09-13.csv',\n",
       " '2016-09-14.csv',\n",
       " '2016-09-15.csv',\n",
       " '2016-09-16.csv',\n",
       " '2016-09-17.csv',\n",
       " '2016-09-18.csv',\n",
       " '2016-09-19.csv',\n",
       " '2016-09-20.csv',\n",
       " '2016-09-21.csv',\n",
       " '2016-09-22.csv',\n",
       " '2016-09-23.csv',\n",
       " '2016-09-24.csv',\n",
       " '2016-09-25.csv',\n",
       " '2016-09-26.csv',\n",
       " '2016-09-27.csv',\n",
       " '2016-09-28.csv',\n",
       " '2016-09-29.csv',\n",
       " '2016-09-30.csv',\n",
       " '2016-10-01.csv',\n",
       " '2016-10-02.csv',\n",
       " '2016-10-03.csv',\n",
       " '2016-10-04.csv',\n",
       " '2016-10-05.csv',\n",
       " '2016-10-06.csv',\n",
       " '2016-10-07.csv',\n",
       " '2016-10-08.csv',\n",
       " '2016-10-09.csv',\n",
       " '2016-10-10.csv',\n",
       " '2016-10-11.csv',\n",
       " '2016-10-12.csv',\n",
       " '2016-10-13.csv',\n",
       " '2016-10-14.csv',\n",
       " '2016-10-15.csv',\n",
       " '2016-10-16.csv',\n",
       " '2016-10-17.csv',\n",
       " '2016-10-18.csv',\n",
       " '2016-10-19.csv',\n",
       " '2016-10-20.csv',\n",
       " '2016-10-21.csv',\n",
       " '2016-10-22.csv',\n",
       " '2016-10-23.csv',\n",
       " '2016-10-24.csv',\n",
       " '2016-10-25.csv',\n",
       " '2016-10-26.csv',\n",
       " '2016-10-27.csv',\n",
       " '2016-10-28.csv',\n",
       " '2016-10-29.csv',\n",
       " '2016-10-30.csv',\n",
       " '2016-10-31.csv',\n",
       " '2016-11-01.csv',\n",
       " '2016-11-02.csv',\n",
       " '2016-11-03.csv',\n",
       " '2016-11-04.csv',\n",
       " '2016-11-05.csv',\n",
       " '2016-11-06.csv',\n",
       " '2016-11-07.csv',\n",
       " '2016-11-08.csv',\n",
       " '2016-11-09.csv',\n",
       " '2016-11-10.csv',\n",
       " '2016-11-11.csv',\n",
       " '2016-11-12.csv',\n",
       " '2016-11-13.csv',\n",
       " '2016-11-14.csv',\n",
       " '2016-11-15.csv',\n",
       " '2016-11-16.csv',\n",
       " '2016-11-17.csv',\n",
       " '2016-11-18.csv',\n",
       " '2016-11-19.csv',\n",
       " '2016-11-20.csv',\n",
       " '2016-11-21.csv',\n",
       " '2016-11-22.csv',\n",
       " '2016-11-23.csv',\n",
       " '2016-11-24.csv',\n",
       " '2016-11-25.csv',\n",
       " '2016-11-26.csv',\n",
       " '2016-11-27.csv',\n",
       " '2016-11-28.csv',\n",
       " '2016-11-29.csv',\n",
       " '2016-11-30.csv',\n",
       " '2016-12-01.csv',\n",
       " '2016-12-02.csv',\n",
       " '2016-12-03.csv',\n",
       " '2016-12-04.csv',\n",
       " '2016-12-05.csv',\n",
       " '2016-12-06.csv',\n",
       " '2016-12-07.csv',\n",
       " '2016-12-08.csv',\n",
       " '2016-12-09.csv',\n",
       " '2016-12-10.csv',\n",
       " '2016-12-11.csv',\n",
       " '2016-12-12.csv',\n",
       " '2016-12-13.csv',\n",
       " '2016-12-14.csv',\n",
       " '2016-12-15.csv',\n",
       " '2016-12-16.csv',\n",
       " '2016-12-17.csv',\n",
       " '2016-12-18.csv',\n",
       " '2016-12-19.csv',\n",
       " '2016-12-20.csv',\n",
       " '2016-12-21.csv',\n",
       " '2016-12-22.csv',\n",
       " '2016-12-23.csv',\n",
       " '2016-12-24.csv',\n",
       " '2016-12-25.csv',\n",
       " '2016-12-26.csv',\n",
       " '2016-12-27.csv',\n",
       " '2016-12-28.csv',\n",
       " '2016-12-29.csv',\n",
       " '2016-12-30.csv',\n",
       " '2016-12-31.csv',\n",
       " '2017-01-01.csv',\n",
       " '2017-01-02.csv',\n",
       " '2017-01-03.csv',\n",
       " '2017-01-04.csv',\n",
       " '2017-01-05.csv',\n",
       " '2017-01-06.csv',\n",
       " '2017-01-07.csv',\n",
       " '2017-01-08.csv',\n",
       " '2017-01-09.csv',\n",
       " '2017-01-10.csv',\n",
       " '2017-01-11.csv',\n",
       " '2017-01-12.csv',\n",
       " '2017-01-13.csv',\n",
       " '2017-01-14.csv',\n",
       " '2017-01-15.csv',\n",
       " '2017-01-16.csv',\n",
       " '2017-01-17.csv',\n",
       " '2017-01-18.csv',\n",
       " '2017-01-19.csv',\n",
       " '2017-01-20.csv',\n",
       " '2017-01-21.csv',\n",
       " '2017-01-22.csv',\n",
       " '2017-01-23.csv',\n",
       " '2017-01-24.csv',\n",
       " '2017-01-25.csv',\n",
       " '2017-01-26.csv',\n",
       " '2017-01-27.csv',\n",
       " '2017-01-28.csv',\n",
       " '2017-01-29.csv',\n",
       " '2017-01-30.csv',\n",
       " '2017-01-31.csv',\n",
       " '2017-02-01.csv',\n",
       " '2017-02-02.csv',\n",
       " '2017-02-03.csv',\n",
       " '2017-02-04.csv',\n",
       " '2017-02-05.csv',\n",
       " '2017-02-06.csv',\n",
       " '2017-02-07.csv',\n",
       " '2017-02-08.csv',\n",
       " '2017-02-09.csv',\n",
       " '2017-02-10.csv',\n",
       " '2017-02-11.csv',\n",
       " '2017-02-12.csv',\n",
       " '2017-02-13.csv',\n",
       " '2017-02-14.csv',\n",
       " '2017-02-15.csv',\n",
       " '2017-02-16.csv',\n",
       " '2017-02-17.csv',\n",
       " '2017-02-18.csv',\n",
       " '2017-02-19.csv',\n",
       " '2017-02-20.csv',\n",
       " '2017-02-21.csv',\n",
       " '2017-02-22.csv',\n",
       " '2017-02-23.csv',\n",
       " '2017-02-24.csv',\n",
       " '2017-02-25.csv',\n",
       " '2017-02-26.csv',\n",
       " '2017-02-27.csv',\n",
       " '2017-02-28.csv',\n",
       " '2017-03-01.csv',\n",
       " '2017-03-02.csv',\n",
       " '2017-03-03.csv',\n",
       " '2017-03-04.csv',\n",
       " '2017-03-05.csv',\n",
       " '2017-03-06.csv',\n",
       " '2017-03-07.csv',\n",
       " '2017-03-08.csv',\n",
       " '2017-03-09.csv',\n",
       " '2017-03-10.csv',\n",
       " '2017-03-11.csv',\n",
       " '2017-03-12.csv',\n",
       " '2017-03-13.csv',\n",
       " '2017-03-14.csv',\n",
       " '2017-03-15.csv',\n",
       " '2017-03-16.csv',\n",
       " '2017-03-17.csv',\n",
       " '2017-03-18.csv',\n",
       " '2017-03-19.csv',\n",
       " '2017-03-20.csv',\n",
       " '2017-03-21.csv',\n",
       " '2017-03-22.csv',\n",
       " '2017-03-23.csv',\n",
       " '2017-03-24.csv',\n",
       " '2017-03-25.csv',\n",
       " '2017-03-26.csv',\n",
       " '2017-03-27.csv',\n",
       " '2017-03-28.csv',\n",
       " '2017-03-29.csv',\n",
       " '2017-03-30.csv',\n",
       " '2017-03-31.csv',\n",
       " '2017-04-01.csv',\n",
       " '2017-04-02.csv',\n",
       " '2017-04-03.csv',\n",
       " '2017-04-04.csv',\n",
       " '2017-04-05.csv',\n",
       " '2017-04-06.csv',\n",
       " '2017-04-07.csv',\n",
       " '2017-04-08.csv',\n",
       " '2017-04-09.csv',\n",
       " '2017-04-10.csv',\n",
       " '2017-04-11.csv',\n",
       " '2017-04-12.csv',\n",
       " '2017-04-13.csv',\n",
       " '2017-04-14.csv',\n",
       " '2017-04-15.csv',\n",
       " '2017-04-16.csv',\n",
       " '2017-04-17.csv',\n",
       " '2017-04-18.csv',\n",
       " '2017-04-19.csv',\n",
       " '2017-04-20.csv',\n",
       " '2017-04-21.csv',\n",
       " '2017-04-22.csv',\n",
       " '2017-04-23.csv',\n",
       " '2017-04-24.csv',\n",
       " '2017-04-25.csv',\n",
       " '2017-04-26.csv',\n",
       " '2017-04-27.csv',\n",
       " '2017-04-28.csv',\n",
       " '2017-04-29.csv',\n",
       " '2017-04-30.csv',\n",
       " '2017-05-01.csv',\n",
       " '2017-05-02.csv',\n",
       " '2017-05-03.csv',\n",
       " '2017-05-04.csv',\n",
       " '2017-05-05.csv',\n",
       " '2017-05-06.csv',\n",
       " '2017-05-07.csv',\n",
       " '2017-05-08.csv',\n",
       " '2017-05-09.csv',\n",
       " '2017-05-10.csv',\n",
       " '2017-05-11.csv',\n",
       " '2017-05-12.csv',\n",
       " '2017-05-13.csv',\n",
       " '2017-05-14.csv',\n",
       " '2017-05-15.csv',\n",
       " '2017-05-16.csv',\n",
       " '2017-05-17.csv',\n",
       " '2017-05-18.csv',\n",
       " '2017-05-19.csv',\n",
       " '2017-05-20.csv',\n",
       " '2017-05-21.csv',\n",
       " '2017-05-22.csv',\n",
       " '2017-05-23.csv',\n",
       " '2017-05-24.csv',\n",
       " '2017-05-25.csv',\n",
       " '2017-05-26.csv',\n",
       " '2017-05-27.csv',\n",
       " '2017-05-28.csv',\n",
       " '2017-05-29.csv',\n",
       " '2017-05-30.csv',\n",
       " '2017-05-31.csv',\n",
       " '2017-06-01.csv',\n",
       " '2017-06-02.csv',\n",
       " '2017-06-03.csv',\n",
       " '2017-06-04.csv',\n",
       " '2017-06-05.csv',\n",
       " '2017-06-06.csv',\n",
       " '2017-06-07.csv',\n",
       " '2017-06-08.csv',\n",
       " '2017-06-09.csv',\n",
       " '2017-06-10.csv',\n",
       " '2017-06-11.csv',\n",
       " '2017-06-12.csv',\n",
       " '2017-06-13.csv',\n",
       " '2017-06-14.csv',\n",
       " '2017-06-15.csv',\n",
       " '2017-06-16.csv',\n",
       " '2017-06-17.csv',\n",
       " '2017-06-18.csv',\n",
       " '2017-06-19.csv',\n",
       " '2017-06-20.csv',\n",
       " '2017-06-21.csv',\n",
       " '2017-06-22.csv',\n",
       " '2017-06-23.csv',\n",
       " '2017-06-24.csv',\n",
       " '2017-06-25.csv',\n",
       " '2017-06-26.csv',\n",
       " '2017-06-27.csv',\n",
       " '2017-06-28.csv',\n",
       " '2017-06-29.csv',\n",
       " '2017-06-30.csv',\n",
       " '2017-07-01.csv',\n",
       " '2017-07-02.csv',\n",
       " '2017-07-03.csv',\n",
       " '2017-07-04.csv',\n",
       " '2017-07-05.csv',\n",
       " '2017-07-06.csv',\n",
       " '2017-07-07.csv',\n",
       " '2017-07-08.csv',\n",
       " '2017-07-09.csv',\n",
       " '2017-07-10.csv',\n",
       " '2017-07-11.csv',\n",
       " '2017-07-12.csv',\n",
       " '2017-07-13.csv',\n",
       " '2017-07-14.csv',\n",
       " '2017-07-15.csv',\n",
       " '2017-07-16.csv',\n",
       " '2017-07-17.csv',\n",
       " '2017-07-18.csv',\n",
       " '2017-07-19.csv',\n",
       " '2017-07-20.csv',\n",
       " '2017-07-21.csv',\n",
       " '2017-07-22.csv',\n",
       " '2017-07-23.csv',\n",
       " '2017-07-24.csv',\n",
       " '2017-07-25.csv',\n",
       " '2017-07-26.csv',\n",
       " '2017-07-27.csv',\n",
       " '2017-07-28.csv',\n",
       " '2017-07-29.csv',\n",
       " '2017-07-30.csv',\n",
       " '2017-07-31.csv',\n",
       " '2017-08-01.csv',\n",
       " '2017-08-02.csv',\n",
       " '2017-08-03.csv',\n",
       " '2017-08-04.csv',\n",
       " '2017-08-05.csv',\n",
       " '2017-08-06.csv',\n",
       " '2017-08-07.csv',\n",
       " '2017-08-08.csv',\n",
       " '2017-08-09.csv',\n",
       " '2017-08-10.csv',\n",
       " '2017-08-11.csv',\n",
       " '2017-08-12.csv',\n",
       " '2017-08-13.csv',\n",
       " '2017-08-14.csv',\n",
       " '2017-08-15.csv',\n",
       " '2017-08-16.csv',\n",
       " '2017-08-17.csv',\n",
       " '2017-08-18.csv',\n",
       " '2017-08-19.csv',\n",
       " '2017-08-20.csv',\n",
       " '2017-08-21.csv',\n",
       " '2017-08-22.csv',\n",
       " '2017-08-23.csv',\n",
       " '2017-08-24.csv',\n",
       " '2017-08-25.csv',\n",
       " '2017-08-26.csv',\n",
       " '2017-08-27.csv',\n",
       " '2017-08-28.csv',\n",
       " '2017-08-29.csv',\n",
       " '2017-08-30.csv',\n",
       " '2017-08-31.csv',\n",
       " '2017-09-01.csv',\n",
       " '2017-09-02.csv',\n",
       " '2017-09-03.csv',\n",
       " '2017-09-04.csv',\n",
       " '2017-09-05.csv',\n",
       " '2017-09-06.csv',\n",
       " '2017-09-07.csv',\n",
       " '2017-09-08.csv',\n",
       " '2017-09-09.csv',\n",
       " '2017-09-10.csv',\n",
       " '2017-09-11.csv',\n",
       " '2017-09-12.csv',\n",
       " '2017-09-13.csv',\n",
       " '2017-09-14.csv',\n",
       " '2017-09-15.csv',\n",
       " '2017-09-16.csv',\n",
       " '2017-09-17.csv',\n",
       " '2017-09-18.csv',\n",
       " '2017-09-19.csv',\n",
       " '2017-09-20.csv',\n",
       " '2017-09-21.csv',\n",
       " '2017-09-22.csv',\n",
       " '2017-09-23.csv',\n",
       " '2017-09-24.csv',\n",
       " '2017-09-25.csv',\n",
       " '2017-09-26.csv',\n",
       " '2017-09-27.csv',\n",
       " '2017-09-28.csv',\n",
       " '2017-09-29.csv',\n",
       " '2017-09-30.csv',\n",
       " '2017-10-01.csv',\n",
       " '2017-10-02.csv',\n",
       " '2017-10-03.csv',\n",
       " '2017-10-04.csv',\n",
       " '2017-10-05.csv',\n",
       " '2017-10-06.csv',\n",
       " '2017-10-07.csv',\n",
       " '2017-10-08.csv',\n",
       " '2017-10-09.csv',\n",
       " '2017-10-10.csv',\n",
       " '2017-10-11.csv',\n",
       " '2017-10-12.csv',\n",
       " '2017-10-13.csv',\n",
       " '2017-10-14.csv',\n",
       " '2017-10-15.csv',\n",
       " '2017-10-16.csv',\n",
       " '2017-10-17.csv',\n",
       " '2017-10-18.csv',\n",
       " '2017-10-19.csv',\n",
       " '2017-10-20.csv',\n",
       " '2017-10-21.csv',\n",
       " '2017-10-22.csv',\n",
       " '2017-10-23.csv',\n",
       " '2017-10-24.csv',\n",
       " '2017-10-25.csv',\n",
       " '2017-10-26.csv',\n",
       " '2017-10-27.csv',\n",
       " '2017-10-28.csv',\n",
       " '2017-10-29.csv',\n",
       " '2017-10-30.csv',\n",
       " '2017-10-31.csv',\n",
       " '2017-11-01.csv',\n",
       " '2017-11-02.csv',\n",
       " '2017-11-03.csv',\n",
       " '2017-11-04.csv',\n",
       " '2017-11-05.csv',\n",
       " '2017-11-06.csv',\n",
       " '2017-11-07.csv',\n",
       " '2017-11-08.csv',\n",
       " '2017-11-09.csv',\n",
       " '2017-11-10.csv',\n",
       " '2017-11-11.csv',\n",
       " '2017-11-12.csv',\n",
       " '2017-11-13.csv',\n",
       " '2017-11-14.csv',\n",
       " '2017-11-15.csv',\n",
       " '2017-11-16.csv',\n",
       " '2017-11-17.csv',\n",
       " '2017-11-18.csv',\n",
       " '2017-11-19.csv',\n",
       " '2017-11-20.csv',\n",
       " '2017-11-21.csv',\n",
       " '2017-11-22.csv',\n",
       " '2017-11-23.csv',\n",
       " '2017-11-24.csv',\n",
       " '2017-11-25.csv',\n",
       " '2017-11-26.csv',\n",
       " '2017-11-27.csv',\n",
       " '2017-11-28.csv',\n",
       " '2017-11-29.csv',\n",
       " '2017-11-30.csv',\n",
       " '2017-12-01.csv',\n",
       " '2017-12-02.csv',\n",
       " '2017-12-03.csv',\n",
       " '2017-12-04.csv',\n",
       " '2017-12-05.csv',\n",
       " '2017-12-06.csv',\n",
       " '2017-12-07.csv',\n",
       " '2017-12-08.csv',\n",
       " '2017-12-09.csv',\n",
       " '2017-12-10.csv',\n",
       " '2017-12-11.csv',\n",
       " '2017-12-12.csv']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket = \"openaq-data\"\n",
    "openaq_data = s3_resource.Bucket(bucket)\n",
    "keys = []\n",
    "for file in openaq_data.objects.filter():\n",
    "    if file.key[-3:] == \"csv\":\n",
    "        keys.append(file.key)\n",
    "keys "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Updating open_aq_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now handling date: 2015-06-29.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{'2015-06-29.csv': 0}\n",
      "Now handling date: 2015-06-30.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{'2015-06-29.csv': 0, '2015-06-30.csv': 0}\n",
      "Now handling date: 2015-07-01.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{'2015-06-29.csv': 0, '2015-06-30.csv': 0, '2015-07-01.csv': 0}\n",
      "Now handling date: 2015-07-02.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{'2015-06-29.csv': 0, '2015-06-30.csv': 0, '2015-07-01.csv': 0, '2015-07-02.csv': 0}\n",
      "Now handling date: 2015-07-03.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{'2015-06-29.csv': 0, '2015-06-30.csv': 0, '2015-07-01.csv': 0, '2015-07-02.csv': 0, '2015-07-03.csv': 0}\n",
      "Now handling date: 2015-07-04.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{'2015-06-29.csv': 0, '2015-06-30.csv': 0, '2015-07-01.csv': 0, '2015-07-02.csv': 0, '2015-07-03.csv': 0, '2015-07-04.csv': 0}\n",
      "Now handling date: 2015-07-06.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{'2015-06-29.csv': 0, '2015-06-30.csv': 0, '2015-07-01.csv': 0, '2015-07-02.csv': 0, '2015-07-03.csv': 0, '2015-07-04.csv': 0, '2015-07-06.csv': 0}\n",
      "Now handling date: 2015-07-07.csv\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    379\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 2.7, use buffering of HTTP responses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m                 \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 2.6 and older, Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: getresponse() got an unexpected keyword argument 'buffering'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-57547176cd78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m }\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mrun_over_history_of_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-55-6f1b54185d02>\u001b[0m in \u001b[0;36mrun_over_history_of_files\u001b[0;34m(list_of_files, target_table_name, cols_and_types, start_ix, end_ix, output_json)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0mnumber_new_observations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_over_single_set_new_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_table_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols_and_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;31m# Keep a history of the number of new observations per day in OpenAQ history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-55-6f1b54185d02>\u001b[0m in \u001b[0;36mrun_over_single_set_new_data\u001b[0;34m(data, target_table_name, cols_and_types)\u001b[0m\n\u001b[1;32m    131\u001b[0m              }\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     \u001b[0mnumber_new_observations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_table_without_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber_new_observations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-55-6f1b54185d02>\u001b[0m in \u001b[0;36mupdate_table_without_duplicates\u001b[0;34m(data_df, target_table_name, cols_and_types, float_cols_to_round, precision, cols_with_apostrophes, datetime_column, datetime_cutoff, want_data_since_cutoff, dedupe_with_target)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# Select data from the target_table to use in de-duping procedure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_from_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_table_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatetime_column\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatetime_cutoff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwant_data_since_cutoff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mtarget_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"rows\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumn_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-55-6f1b54185d02>\u001b[0m in \u001b[0;36mselect_from_table\u001b[0;34m(target_table_name, datetime_column, datetime_cutoff, want_data_since_cutoff)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0mSELECT\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mFROM\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mtable_name\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \"\"\".format(table_name=target_table_name)\n\u001b[0;32m--> 243\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msql_api\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselect_all_sql\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-55-6f1b54185d02>\u001b[0m in \u001b[0;36msql_api\u001b[0;34m(sql, url, key)\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;34m'q'\u001b[0m       \u001b[0;34m:\u001b[0m \u001b[0msql\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     }\n\u001b[0;32m--> 182\u001b[0;31m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/site-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    506\u001b[0m         }\n\u001b[1;32m    507\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    438\u001b[0m                     \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m                 )\n\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    599\u001b[0m                                                   \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m                                                   chunked=chunked)\n\u001b[0m\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m             \u001b[0;31m# If we're going to release the connection in ``finally:``, then\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 2.6 and older, Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m                     \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m                     \u001b[0;31m# Remove the TypeError from the exception chain in Python 3;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1329\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1331\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1332\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/site-packages/urllib3/contrib/pyopenssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOpenSSL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSysCallError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Unexpected EOF'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/site-packages/OpenSSL/SSL.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1712\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL_peek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ssl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1713\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1714\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ssl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1715\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_ssl_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ssl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "output_json = {}\n",
    "\n",
    "kwargs = {\n",
    "    \"list_of_files\":keys, \n",
    "    \"target_table_name\":\"open_aq_locations\", \n",
    "    \"cols_and_types\":cols_and_types_locations, \n",
    "    \"start_ix\":0, \n",
    "    \"end_ix\":len(keys),\n",
    "    \"output_json\":output_json\n",
    "}\n",
    "\n",
    "# Implicit inputs:\n",
    "# kwargs = {\n",
    "#             \"cols_with_apostrophes\":[\"location\", \"city\",\"country\"],\n",
    "#             \"float_cols_to_round\":[\"latitude\", \"longitude\"],\n",
    "#             \"precision\":6,\n",
    "#             \"datetime_column\":\"lastUpdated\",\n",
    "#             \"datetime_cutoff\":None\n",
    "#             \"want_data_since_cutoff\":True\n",
    "#          }\n",
    "\n",
    "run_over_history_of_files(**kwargs)\n",
    "\n",
    "\n",
    "### TO DO:\n",
    "# delete_table(\"open_aq_locations\")\n",
    "# run_over_history_of_files(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Updating open_aq_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "A list of all locations ever reporting to the OpenAQ network:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = select_from_table(\"open_aq_history\", \n",
    "                        #datetime_column=\"lastUpdated\", \n",
    "                        #datetime_cutoff=\"2 days\", \n",
    "                        #want_data_since_cutoff=True\n",
    "                       )\n",
    "\n",
    "#column_order = [\"location\", \"city\", \"country\", \"latitude\", \"longitude\"]\n",
    "all_open_aq_history = pd.DataFrame(res[\"rows\"]) #[column_order]\n",
    "\n",
    "print(\"\\nNumber of duplicates in the table:\", all_open_aq_history.duplicated().sum())\n",
    "\n",
    "print(\"\\nA list of all locations ever reporting to the OpenAQ network:\")\n",
    "all_open_aq_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"rows\":[],\"time\":0.002,\"fields\":{\"lastupdated\":{\"type\":\"date\"},\"value\":{\"type\":\"number\"},\"parameter\":{\"type\":\"string\"},\"sourcename\":{\"type\":\"string\"},\"location\":{\"type\":\"string\"},\"city\":{\"type\":\"string\"},\"iso3\":{\"type\":\"string\"},\"unit\":{\"type\":\"string\"},\"latitude\":{\"type\":\"number\"},\"longitude\":{\"type\":\"number\"}},\"total_rows\":0}'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_json = {}\n",
    "\n",
    "# Updates for last 5 days of observations\n",
    "kwargs = {\n",
    "    \"list_of_files\":keys, \n",
    "    \"target_table_name\":\"open_aq_history\", \n",
    "    \"cols_and_types\":cols_and_types_history, \n",
    "    \"start_ix\":len(keys)-5, \n",
    "    \"end_ix\":len(keys),\n",
    "    \"output_json\":output_json,\n",
    "    \"datetime_cutoff\":\"2 days\"\n",
    "}\n",
    "\n",
    "# Implicit inputs:\n",
    "# kwargs = {\n",
    "#             \"cols_with_apostrophes\":[\"location\", \"city\",\"country\"],\n",
    "#             \"float_cols_to_round\":[\"latitude\", \"longitude\"],\n",
    "#             \"precision\":6,\n",
    "#             \"datetime_column\":\"lastUpdated\",\n",
    "#             \"want_data_since_cutoff\":True\n",
    "#          }\n",
    "\n",
    "run_over_history_of_files(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now handling date: 2015-11-21.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2015-11-22.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2015-11-23.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2015-11-24.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2015-11-25.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2015-11-26.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2015-11-27.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2015-11-28.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2015-11-29.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2015-11-30.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2015-12-01.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2015-12-02.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2015-12-03.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2015-12-04.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2015-12-05.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2015-12-06.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2015-12-07.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2015-12-08.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2015-12-09.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2015-12-10.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2015-12-11.csv\n",
      "Number of new observations added to open_aq_locations: 7\n",
      "Completed up until index: 20\n",
      "Now handling date: 2015-12-12.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2015-12-13.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2015-12-14.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2015-12-15.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2015-12-16.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2015-12-17.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2015-12-18.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2015-12-19.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2015-12-20.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2015-12-21.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2015-12-22.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2015-12-23.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2015-12-24.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2015-12-25.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2015-12-26.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2015-12-27.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2015-12-28.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2015-12-29.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2015-12-30.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-01-03.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-01-04.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-01-05.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-01-06.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-01-07.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-01-08.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-01-09.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-01-10.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-01-11.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-01-12.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-01-13.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-01-14.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-01-15.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-01-16.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-01-17.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-01-18.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-01-19.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-01-20.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-01-21.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-01-22.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-01-23.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-01-24.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-01-25.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-01-26.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-01-27.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-01-28.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-01-29.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-01-30.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-01-31.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-02-01.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-02-02.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-02-03.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-02-04.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-02-05.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-02-06.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-02-07.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-02-08.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-02-09.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-02-10.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-02-11.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-02-12.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-02-13.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-02-14.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-02-15.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-02-16.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-02-17.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-02-18.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-02-19.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-02-20.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-02-21.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-02-22.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-02-23.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-02-24.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-02-25.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-02-26.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-02-27.csv\n",
      "Number of new observations added to open_aq_locations: 11\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-02-28.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-02-29.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-03-01.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-03-02.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-03-03.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-03-04.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-03-05.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-03-06.csv\n",
      "Number of new observations added to open_aq_locations: 257\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Completed up until index: 60\n",
      "Completed up until index: 80\n",
      "Completed up until index: 100\n",
      "Completed up until index: 120\n",
      "Completed up until index: 140\n",
      "Completed up until index: 160\n",
      "Completed up until index: 180\n",
      "Completed up until index: 200\n",
      "Completed up until index: 220\n",
      "Completed up until index: 240\n",
      "Completed up until index: 260\n",
      "Now handling date: 2016-03-07.csv\n",
      "Number of new observations added to open_aq_locations: 17\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-03-08.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-03-09.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-03-10.csv\n",
      "Number of new observations added to open_aq_locations: 63\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Completed up until index: 60\n",
      "Completed up until index: 80\n",
      "Now handling date: 2016-03-11.csv\n",
      "Number of new observations added to open_aq_locations: 17\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-03-12.csv\n",
      "Number of new observations added to open_aq_locations: 6\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-03-13.csv\n",
      "Number of new observations added to open_aq_locations: 18\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-03-14.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-03-15.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-03-16.csv\n",
      "Number of new observations added to open_aq_locations: 8\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-03-17.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-03-18.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-03-19.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-03-20.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-03-21.csv\n",
      "Number of new observations added to open_aq_locations: 11\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-03-22.csv\n",
      "Number of new observations added to open_aq_locations: 9\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-03-23.csv\n",
      "Number of new observations added to open_aq_locations: 16\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-03-24.csv\n",
      "Number of new observations added to open_aq_locations: 8\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-03-25.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-03-26.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-03-27.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-03-28.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-03-29.csv\n",
      "Number of new observations added to open_aq_locations: 9\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-03-30.csv\n",
      "Number of new observations added to open_aq_locations: 24\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Now handling date: 2016-03-31.csv\n",
      "Number of new observations added to open_aq_locations: 12\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-04-01.csv\n",
      "Number of new observations added to open_aq_locations: 54\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Completed up until index: 60\n",
      "Now handling date: 2016-04-02.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-04-03.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-04-04.csv\n",
      "Number of new observations added to open_aq_locations: 27\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Now handling date: 2016-04-05.csv\n",
      "Number of new observations added to open_aq_locations: 18\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-04-06.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-04-07.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-04-08.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-04-09.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-04-10.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-04-11.csv\n",
      "Number of new observations added to open_aq_locations: 4\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-04-12.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-04-13.csv\n",
      "Number of new observations added to open_aq_locations: 4\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-04-14.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-04-15.csv\n",
      "Number of new observations added to open_aq_locations: 4\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-04-16.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-04-17.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-04-18.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-04-19.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-04-20.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-04-21.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-04-22.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-04-23.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-04-24.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-04-25.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-04-26.csv\n",
      "Number of new observations added to open_aq_locations: 13\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-04-27.csv\n",
      "Number of new observations added to open_aq_locations: 4\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-04-28.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-04-29.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-04-30.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-05-01.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-05-02.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-05-03.csv\n",
      "Number of new observations added to open_aq_locations: 4\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-05-04.csv\n",
      "Number of new observations added to open_aq_locations: 5\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-05-05.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-05-06.csv\n",
      "Number of new observations added to open_aq_locations: 7\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-05-07.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-05-08.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-05-09.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-05-10.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-05-11.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-05-12.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-05-13.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-05-14.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-05-15.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-05-16.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-05-17.csv\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-350-44d1a1265560>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Now handling date:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://openaq-data.s3.amazonaws.com/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         kwargs = {\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    390\u001b[0m     \u001b[0mcompression\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_infer_compression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m     filepath_or_buffer, _, compression = get_filepath_or_buffer(\n\u001b[0;32m--> 392\u001b[0;31m         filepath_or_buffer, encoding, compression)\n\u001b[0m\u001b[1;32m    393\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'compression'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression)\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0;31m# Override compression based on Content-Encoding header\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0mcompression\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'gzip'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    460\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m                     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_safe_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mIncompleteRead\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_close_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_safe_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    610\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMAXAMOUNT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mIncompleteRead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1000\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1002\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1003\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    863\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Read on closed or unwrapped SSL socket.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 865\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    866\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSSL_ERROR_EOF\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    623\u001b[0m         \"\"\"\n\u001b[1;32m    624\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 135:310 comes from the code snippet below, to restart code and add in date to output of each loop\n",
    "for csv in keys[135:310]:\n",
    "    if csv[-3:] == \"csv\":\n",
    "        print(\"Now handling date:\", csv)\n",
    "        url = \"https://openaq-data.s3.amazonaws.com/\"+csv\n",
    "        data = pd.read_csv(url)\n",
    "        \n",
    "        kwargs = {\n",
    "            \"data_df\":data,\n",
    "            \"target_table_name\":\"open_aq_locations\",\n",
    "            \"cols_and_types\":cols_and_types_locations,\n",
    "            \"cols_with_apostrophes\":[\"location\", \"city\",\"country\"],\n",
    "            \"float_cols_to_round\":[\"latitude\", \"longitude\"],\n",
    "            \"precision\":6\n",
    "        }\n",
    "\n",
    "        update_table_without_duplicates(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now handling date: 2016-05-16.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-05-17.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-05-18.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-05-19.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-05-20.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-05-21.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-05-22.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-05-23.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-05-24.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-05-25.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-05-26.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-05-27.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-05-28.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-05-29.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-05-30.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-05-31.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-06-01.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-06-02.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-06-03.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-06-04.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-06-05.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-06-06.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-06-07.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-06-08.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-06-09.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-06-10.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-06-11.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-06-12.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-06-13.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-06-14.csv\n",
      "Number of new observations added to open_aq_locations: 4\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-06-15.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-06-16.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-06-17.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-06-18.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-06-19.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-06-20.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-06-21.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-06-22.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-06-23.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-06-24.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-06-25.csv\n",
      "Number of new observations added to open_aq_locations: 5\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-06-26.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-06-27.csv\n",
      "Number of new observations added to open_aq_locations: 5\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-06-28.csv\n",
      "Number of new observations added to open_aq_locations: 4\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-06-29.csv\n",
      "Number of new observations added to open_aq_locations: 4\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-06-30.csv\n",
      "Number of new observations added to open_aq_locations: 4\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-07-01.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-07-02.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-07-03.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-07-04.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-07-05.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-07-06.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-07-07.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-07-08.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-07-09.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-07-10.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-07-11.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-07-12.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-07-13.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-07-14.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-07-15.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-07-16.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-07-17.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-07-18.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-07-19.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-07-20.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-07-21.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-07-22.csv\n",
      "Number of new observations added to open_aq_locations: 8\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-07-23.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-07-24.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-07-25.csv\n",
      "Number of new observations added to open_aq_locations: 4\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-07-26.csv\n",
      "Number of new observations added to open_aq_locations: 6\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-07-27.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-07-28.csv\n",
      "Number of new observations added to open_aq_locations: 15\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-07-29.csv\n",
      "Number of new observations added to open_aq_locations: 4\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-07-30.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-07-31.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-08-01.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-08-02.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-08-03.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-08-04.csv\n",
      "Number of new observations added to open_aq_locations: 4\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-08-05.csv\n",
      "Number of new observations added to open_aq_locations: 4\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-08-06.csv\n",
      "Number of new observations added to open_aq_locations: 5\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-08-07.csv\n",
      "Number of new observations added to open_aq_locations: 5\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-08-08.csv\n",
      "Number of new observations added to open_aq_locations: 10\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-08-09.csv\n",
      "Number of new observations added to open_aq_locations: 5\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-08-10.csv\n",
      "Number of new observations added to open_aq_locations: 5\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-08-11.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-08-12.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-08-13.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-08-14.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-08-15.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-08-16.csv\n",
      "Number of new observations added to open_aq_locations: 4\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-08-17.csv\n",
      "Number of new observations added to open_aq_locations: 4\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-08-18.csv\n",
      "Number of new observations added to open_aq_locations: 7\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-08-19.csv\n",
      "Number of new observations added to open_aq_locations: 4\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-08-20.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-08-21.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-08-22.csv\n",
      "Number of new observations added to open_aq_locations: 4\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-08-23.csv\n",
      "Number of new observations added to open_aq_locations: 5\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-08-24.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-08-25.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-08-26.csv\n",
      "Number of new observations added to open_aq_locations: 4\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-08-27.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-08-28.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-08-29.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-08-30.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-08-31.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-09-01.csv\n",
      "Number of new observations added to open_aq_locations: 4\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-09-02.csv\n",
      "Number of new observations added to open_aq_locations: 4\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-09-03.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-09-04.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-09-05.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-09-06.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-09-07.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-09-08.csv\n",
      "Number of new observations added to open_aq_locations: 5\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-09-09.csv\n",
      "Number of new observations added to open_aq_locations: 4\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-09-10.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-09-11.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-09-12.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-09-13.csv\n",
      "Number of new observations added to open_aq_locations: 4\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-09-14.csv\n",
      "Number of new observations added to open_aq_locations: 4\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-09-15.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-09-16.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-09-17.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-09-18.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-09-19.csv\n",
      "Number of new observations added to open_aq_locations: 5\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-09-20.csv\n",
      "Number of new observations added to open_aq_locations: 8\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-09-21.csv\n",
      "Number of new observations added to open_aq_locations: 8\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-09-22.csv\n",
      "Number of new observations added to open_aq_locations: 7\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-09-23.csv\n",
      "Number of new observations added to open_aq_locations: 5\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-09-24.csv\n",
      "Number of new observations added to open_aq_locations: 7\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-09-25.csv\n",
      "Number of new observations added to open_aq_locations: 7\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-09-26.csv\n",
      "Number of new observations added to open_aq_locations: 6\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-09-27.csv\n",
      "Number of new observations added to open_aq_locations: 4\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-09-28.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-09-29.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-09-30.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-10-01.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-10-02.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-10-03.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-10-04.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-10-05.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-10-06.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-10-07.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-10-08.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-10-09.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-10-10.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-10-11.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-10-12.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-10-13.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-10-14.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-10-15.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-10-16.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-10-17.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-10-18.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-10-19.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-10-20.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-10-21.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-10-22.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-10-23.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-10-24.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-10-25.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-10-26.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-10-27.csv\n",
      "Number of new observations added to open_aq_locations: 6\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-10-28.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-10-29.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-10-30.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-10-31.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-11-01.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-11-02.csv\n",
      "Number of new observations added to open_aq_locations: 4\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-11-03.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-11-04.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-11-05.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-11-06.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-11-07.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-11-08.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-11-09.csv\n",
      "Number of new observations added to open_aq_locations: 18\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-11-10.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-11-11.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-11-12.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-11-13.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-11-14.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-11-15.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-11-16.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-11-17.csv\n",
      "Number of new observations added to open_aq_locations: 303\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Completed up until index: 60\n",
      "Completed up until index: 80\n",
      "Completed up until index: 100\n",
      "Completed up until index: 120\n",
      "Completed up until index: 140\n",
      "Completed up until index: 160\n",
      "Completed up until index: 180\n",
      "Completed up until index: 200\n",
      "Completed up until index: 220\n",
      "Completed up until index: 240\n",
      "Completed up until index: 260\n",
      "Completed up until index: 280\n",
      "Completed up until index: 300\n",
      "Completed up until index: 320\n",
      "Now handling date: 2016-11-18.csv\n",
      "Number of new observations added to open_aq_locations: 292\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Completed up until index: 60\n",
      "Completed up until index: 80\n",
      "Completed up until index: 100\n",
      "Completed up until index: 120\n",
      "Completed up until index: 140\n",
      "Completed up until index: 160\n",
      "Completed up until index: 180\n",
      "Completed up until index: 200\n",
      "Completed up until index: 220\n",
      "Completed up until index: 240\n",
      "Completed up until index: 260\n",
      "Completed up until index: 280\n",
      "Completed up until index: 300\n",
      "Now handling date: 2016-11-19.csv\n",
      "Number of new observations added to open_aq_locations: 27\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Now handling date: 2016-11-20.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-11-21.csv\n",
      "Number of new observations added to open_aq_locations: 906\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Completed up until index: 60\n",
      "Completed up until index: 80\n",
      "Completed up until index: 100\n",
      "Completed up until index: 120\n",
      "Completed up until index: 140\n",
      "Completed up until index: 160\n",
      "Completed up until index: 180\n",
      "Completed up until index: 200\n",
      "Completed up until index: 220\n",
      "Completed up until index: 240\n",
      "Completed up until index: 260\n",
      "Completed up until index: 280\n",
      "Completed up until index: 300\n",
      "Completed up until index: 320\n",
      "Completed up until index: 340\n",
      "Completed up until index: 360\n",
      "Completed up until index: 380\n",
      "Completed up until index: 400\n",
      "Completed up until index: 420\n",
      "Completed up until index: 440\n",
      "Completed up until index: 460\n",
      "Completed up until index: 480\n",
      "Completed up until index: 500\n",
      "Completed up until index: 520\n",
      "Completed up until index: 540\n",
      "Completed up until index: 560\n",
      "Completed up until index: 580\n",
      "Completed up until index: 600\n",
      "Completed up until index: 620\n",
      "Completed up until index: 640\n",
      "Completed up until index: 660\n",
      "Completed up until index: 680\n",
      "Completed up until index: 700\n",
      "Completed up until index: 720\n",
      "Completed up until index: 740\n",
      "Completed up until index: 760\n",
      "Completed up until index: 780\n",
      "Completed up until index: 800\n",
      "Completed up until index: 820\n",
      "Completed up until index: 840\n",
      "Completed up until index: 860\n",
      "Completed up until index: 880\n",
      "Completed up until index: 900\n",
      "Completed up until index: 920\n",
      "Now handling date: 2016-11-22.csv\n",
      "Number of new observations added to open_aq_locations: 8\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-11-23.csv\n",
      "Number of new observations added to open_aq_locations: 66\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Completed up until index: 60\n",
      "Completed up until index: 80\n",
      "Now handling date: 2016-11-24.csv\n",
      "Number of new observations added to open_aq_locations: 45\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Completed up until index: 60\n",
      "Now handling date: 2016-11-25.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-11-26.csv\n",
      "Number of new observations added to open_aq_locations: 5\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-11-27.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-11-28.csv\n",
      "Number of new observations added to open_aq_locations: 4\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-11-29.csv\n",
      "Number of new observations added to open_aq_locations: 4\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-11-30.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-12-01.csv\n",
      "Number of new observations added to open_aq_locations: 6\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-12-02.csv\n",
      "Number of new observations added to open_aq_locations: 8\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-12-03.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-12-04.csv\n",
      "Number of new observations added to open_aq_locations: 4\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-12-05.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-12-06.csv\n",
      "Number of new observations added to open_aq_locations: 4\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-12-07.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-12-08.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-12-09.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-12-10.csv\n",
      "Number of new observations added to open_aq_locations: 73\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Completed up until index: 60\n",
      "Completed up until index: 80\n",
      "Now handling date: 2016-12-11.csv\n",
      "Number of new observations added to open_aq_locations: 13\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-12-12.csv\n",
      "Number of new observations added to open_aq_locations: 26\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Now handling date: 2016-12-13.csv\n",
      "Number of new observations added to open_aq_locations: 4\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-12-14.csv\n",
      "Number of new observations added to open_aq_locations: 4\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-12-15.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-12-16.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-12-17.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-12-18.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-12-19.csv\n",
      "Number of new observations added to open_aq_locations: 4\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-12-20.csv\n",
      "Number of new observations added to open_aq_locations: 67\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Completed up until index: 60\n",
      "Completed up until index: 80\n",
      "Now handling date: 2016-12-21.csv\n",
      "Number of new observations added to open_aq_locations: 8\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-12-22.csv\n",
      "Number of new observations added to open_aq_locations: 5\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-12-23.csv\n",
      "Number of new observations added to open_aq_locations: 48\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Completed up until index: 60\n",
      "Now handling date: 2016-12-24.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-12-25.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-12-26.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-12-27.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-12-28.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-12-29.csv\n",
      "Number of new observations added to open_aq_locations: 4\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-12-30.csv\n",
      "Number of new observations added to open_aq_locations: 4\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-12-31.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-01-01.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-01-02.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-01-03.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-01-04.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-01-05.csv\n",
      "Number of new observations added to open_aq_locations: 12\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-01-06.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-01-07.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-01-08.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-01-09.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-01-10.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-01-11.csv\n",
      "Number of new observations added to open_aq_locations: 29\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Now handling date: 2017-01-12.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-01-13.csv\n",
      "Number of new observations added to open_aq_locations: 4\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-01-14.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-01-15.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-01-16.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-01-17.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-01-18.csv\n",
      "Number of new observations added to open_aq_locations: 15\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-01-19.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-01-20.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-01-21.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-01-22.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-01-23.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-01-24.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-01-25.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-01-26.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-01-27.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-01-28.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-01-29.csv\n",
      "Number of new observations added to open_aq_locations: 32\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Now handling date: 2017-01-30.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-01-31.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-02-01.csv\n",
      "Number of new observations added to open_aq_locations: 4\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-02-02.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-02-03.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-02-04.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-02-05.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-02-06.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-02-07.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-02-08.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-02-09.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-02-10.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-02-11.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-02-12.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-02-13.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-02-14.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-02-15.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-02-16.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-02-17.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-02-18.csv\n",
      "Number of new observations added to open_aq_locations: 743\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Completed up until index: 60\n",
      "Completed up until index: 80\n",
      "Completed up until index: 100\n",
      "Completed up until index: 120\n",
      "Completed up until index: 140\n",
      "Completed up until index: 160\n",
      "Completed up until index: 180\n",
      "Completed up until index: 200\n",
      "Completed up until index: 220\n",
      "Completed up until index: 240\n",
      "Completed up until index: 260\n",
      "Completed up until index: 280\n",
      "Completed up until index: 300\n",
      "Completed up until index: 320\n",
      "Completed up until index: 340\n",
      "Completed up until index: 360\n",
      "Completed up until index: 380\n",
      "Completed up until index: 400\n",
      "Completed up until index: 420\n",
      "Completed up until index: 440\n",
      "Completed up until index: 460\n",
      "Completed up until index: 480\n",
      "Completed up until index: 500\n",
      "Completed up until index: 520\n",
      "Completed up until index: 540\n",
      "Completed up until index: 560\n",
      "Completed up until index: 580\n",
      "Completed up until index: 600\n",
      "Completed up until index: 620\n",
      "Completed up until index: 640\n",
      "Completed up until index: 660\n",
      "Completed up until index: 680\n",
      "Completed up until index: 700\n",
      "Completed up until index: 720\n",
      "Completed up until index: 740\n",
      "Completed up until index: 760\n",
      "Now handling date: 2017-02-19.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-02-20.csv\n",
      "Number of new observations added to open_aq_locations: 5\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-02-21.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-02-22.csv\n",
      "Number of new observations added to open_aq_locations: 85\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Completed up until index: 60\n",
      "Completed up until index: 80\n",
      "Completed up until index: 100\n",
      "Now handling date: 2017-02-23.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-02-24.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-02-25.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-02-26.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-02-27.csv\n",
      "Number of new observations added to open_aq_locations: 5\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-02-28.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-03-01.csv\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-359-23cd19519912>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Now handling date:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://openaq-data.s3.amazonaws.com/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         kwargs = {\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    390\u001b[0m     \u001b[0mcompression\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_infer_compression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m     filepath_or_buffer, _, compression = get_filepath_or_buffer(\n\u001b[0;32m--> 392\u001b[0;31m         filepath_or_buffer, encoding, compression)\n\u001b[0m\u001b[1;32m    393\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'compression'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression)\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_urlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m         \u001b[0mcontent_encoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Content-Encoding'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcontent_encoding\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'gzip'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0;31m# post-process response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    542\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[0;32m--> 544\u001b[0;31m                                   '_open', req)\n\u001b[0m\u001b[1;32m    545\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mhttps_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1359\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mhttps_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m             return self.do_open(http.client.HTTPSConnection, req,\n\u001b[0;32m-> 1361\u001b[0;31m                 context=self._context, check_hostname=self._check_hostname)\n\u001b[0m\u001b[1;32m   1362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m         \u001b[0mhttps_request\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAbstractHTTPHandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_request_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1319\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# timeout error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1322\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m             \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1329\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1331\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1332\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1000\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1002\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1003\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    863\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Read on closed or unwrapped SSL socket.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 865\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    866\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSSL_ERROR_EOF\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    623\u001b[0m         \"\"\"\n\u001b[1;32m    624\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 310 comes from the code snippet below, to restart code and add in date to output of each loop\n",
    "for csv in keys[309:598]:\n",
    "    if csv[-3:] == \"csv\":\n",
    "        print(\"Now handling date:\", csv)\n",
    "        url = \"https://openaq-data.s3.amazonaws.com/\"+csv\n",
    "        data = pd.read_csv(url)\n",
    "        \n",
    "        kwargs = {\n",
    "            \"data_df\":data,\n",
    "            \"target_table_name\":\"open_aq_locations\",\n",
    "            \"cols_and_types\":cols_and_types_locations,\n",
    "            \"cols_with_apostrophes\":[\"location\", \"city\",\"country\"],\n",
    "            \"float_cols_to_round\":[\"latitude\", \"longitude\"],\n",
    "            \"precision\":6\n",
    "        }\n",
    "\n",
    "        update_table_without_duplicates(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now handling date: 2017-02-28.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-03-01.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-03-02.csv\n",
      "Number of new observations added to open_aq_locations: 5\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-03-03.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-03-04.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-03-05.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-03-06.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-03-07.csv\n",
      "Number of new observations added to open_aq_locations: 4\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-03-08.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-03-09.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-03-10.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-03-11.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-03-12.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-03-13.csv\n",
      "Number of new observations added to open_aq_locations: 5\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-03-14.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-03-15.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-03-16.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-03-17.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-03-18.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-03-19.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-03-20.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-03-21.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-03-22.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-03-23.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-03-24.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-03-25.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-03-26.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-03-27.csv\n",
      "Number of new observations added to open_aq_locations: 4\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-03-28.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-03-29.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-03-30.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-03-31.csv\n",
      "Number of new observations added to open_aq_locations: 4\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-04-01.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-04-02.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-04-03.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-04-04.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-04-05.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-04-06.csv\n",
      "Number of new observations added to open_aq_locations: 4\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-04-07.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-04-08.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-04-09.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-04-10.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-04-11.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-04-12.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2017-04-13.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-04-14.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2017-04-15.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2017-04-16.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2017-04-17.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2017-04-18.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2017-04-19.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2017-04-20.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2017-04-21.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2017-04-22.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2017-04-23.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-04-24.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2017-04-25.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2017-04-26.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2017-04-27.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2017-04-28.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2017-04-29.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2017-04-30.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2017-05-01.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2017-05-02.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2017-05-03.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2017-05-04.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-05-05.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2017-05-06.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2017-05-07.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2017-05-08.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2017-05-09.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2017-05-10.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2017-05-11.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-05-12.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2017-05-13.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2017-05-14.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2017-05-15.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2017-05-16.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2017-05-17.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2017-05-18.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2017-05-19.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2017-05-20.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2017-05-21.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2017-05-22.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2017-05-23.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2017-05-24.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-05-25.csv\n",
      "Number of new observations added to open_aq_locations: 310\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Completed up until index: 60\n",
      "Completed up until index: 80\n",
      "Completed up until index: 100\n",
      "Completed up until index: 120\n",
      "Completed up until index: 140\n",
      "Completed up until index: 160\n",
      "Completed up until index: 180\n",
      "Completed up until index: 200\n",
      "Completed up until index: 220\n",
      "Completed up until index: 240\n",
      "Completed up until index: 260\n",
      "Completed up until index: 280\n",
      "Completed up until index: 300\n",
      "Completed up until index: 320\n",
      "Now handling date: 2017-05-26.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-05-27.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-05-28.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2017-05-29.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-05-30.csv\n",
      "Number of new observations added to open_aq_locations: 17\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-05-31.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-06-01.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-06-02.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-06-03.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-06-04.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-06-05.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2017-06-06.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-06-07.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-06-08.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-06-09.csv\n",
      "Number of new observations added to open_aq_locations: 48\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Completed up until index: 60\n",
      "Now handling date: 2017-06-10.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2017-06-11.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-06-12.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-06-13.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2017-06-14.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2017-06-15.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-06-16.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2017-06-17.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-06-18.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-06-19.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2017-06-20.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-06-21.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-06-22.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-06-23.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2017-06-24.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2017-06-25.csv\n",
      "Number of new observations added to open_aq_locations: 11\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-06-26.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2017-06-27.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2017-06-28.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-06-29.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2017-06-30.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-07-01.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-07-02.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-07-03.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-07-04.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-07-05.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-07-06.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2017-07-07.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-07-08.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-07-09.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-07-10.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-07-11.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-07-12.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2017-07-13.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2017-07-14.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-07-15.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2017-07-16.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-07-17.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2017-07-18.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-07-19.csv\n",
      "Number of new observations added to open_aq_locations: 5\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-07-20.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-07-21.csv\n",
      "Number of new observations added to open_aq_locations: 5\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-07-22.csv\n",
      "Number of new observations added to open_aq_locations: 4\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-07-23.csv\n",
      "Number of new observations added to open_aq_locations: 4\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-07-24.csv\n",
      "Number of new observations added to open_aq_locations: 5\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-07-25.csv\n",
      "Number of new observations added to open_aq_locations: 63\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Completed up until index: 60\n",
      "Completed up until index: 80\n",
      "Now handling date: 2017-07-26.csv\n",
      "Number of new observations added to open_aq_locations: 6\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-07-27.csv\n",
      "Number of new observations added to open_aq_locations: 89\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Completed up until index: 60\n",
      "Completed up until index: 80\n",
      "Completed up until index: 100\n",
      "Now handling date: 2017-07-28.csv\n",
      "Number of new observations added to open_aq_locations: 4\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-07-29.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-07-30.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-07-31.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-08-01.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-08-02.csv\n",
      "Number of new observations added to open_aq_locations: 4\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-08-03.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-08-04.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-08-05.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-08-06.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-08-07.csv\n",
      "Number of new observations added to open_aq_locations: 5\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-08-08.csv\n",
      "Number of new observations added to open_aq_locations: 4\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-08-09.csv\n",
      "Number of new observations added to open_aq_locations: 5\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-08-10.csv\n",
      "Number of new observations added to open_aq_locations: 1775\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Completed up until index: 60\n",
      "Completed up until index: 80\n",
      "Completed up until index: 100\n",
      "Completed up until index: 120\n",
      "Completed up until index: 140\n",
      "Completed up until index: 160\n",
      "Completed up until index: 180\n",
      "Completed up until index: 200\n",
      "Completed up until index: 220\n",
      "Completed up until index: 240\n",
      "Completed up until index: 260\n",
      "Completed up until index: 280\n",
      "Completed up until index: 300\n",
      "Completed up until index: 320\n",
      "Completed up until index: 340\n",
      "Completed up until index: 360\n",
      "Completed up until index: 380\n",
      "Completed up until index: 400\n",
      "Completed up until index: 420\n",
      "Completed up until index: 440\n",
      "Completed up until index: 460\n",
      "Completed up until index: 480\n",
      "Completed up until index: 500\n",
      "Completed up until index: 520\n",
      "Completed up until index: 540\n",
      "Completed up until index: 560\n",
      "Completed up until index: 580\n",
      "Completed up until index: 600\n",
      "Completed up until index: 620\n",
      "Completed up until index: 640\n",
      "Completed up until index: 660\n",
      "Completed up until index: 680\n",
      "Completed up until index: 700\n",
      "Completed up until index: 720\n",
      "Completed up until index: 740\n",
      "Completed up until index: 760\n",
      "Completed up until index: 780\n",
      "Completed up until index: 800\n",
      "Completed up until index: 820\n",
      "Completed up until index: 840\n",
      "Completed up until index: 860\n",
      "Completed up until index: 880\n",
      "Completed up until index: 900\n",
      "Completed up until index: 920\n",
      "Completed up until index: 940\n",
      "Completed up until index: 960\n",
      "Completed up until index: 980\n",
      "Completed up until index: 1000\n",
      "Completed up until index: 1020\n",
      "Completed up until index: 1040\n",
      "Completed up until index: 1060\n",
      "Completed up until index: 1080\n",
      "Completed up until index: 1100\n",
      "Completed up until index: 1120\n",
      "Completed up until index: 1140\n",
      "Completed up until index: 1160\n",
      "Completed up until index: 1180\n",
      "Completed up until index: 1200\n",
      "Completed up until index: 1220\n",
      "Completed up until index: 1240\n",
      "Completed up until index: 1260\n",
      "Completed up until index: 1280\n",
      "Completed up until index: 1300\n",
      "Completed up until index: 1320\n",
      "Completed up until index: 1340\n",
      "Completed up until index: 1360\n",
      "Completed up until index: 1380\n",
      "Completed up until index: 1400\n",
      "Completed up until index: 1420\n",
      "Completed up until index: 1440\n",
      "Completed up until index: 1460\n",
      "Completed up until index: 1480\n",
      "Completed up until index: 1500\n",
      "Completed up until index: 1520\n",
      "Completed up until index: 1540\n",
      "Completed up until index: 1560\n",
      "Completed up until index: 1580\n",
      "Completed up until index: 1600\n",
      "Completed up until index: 1620\n",
      "Completed up until index: 1640\n",
      "Completed up until index: 1660\n",
      "Completed up until index: 1680\n",
      "Completed up until index: 1700\n",
      "Completed up until index: 1720\n",
      "Completed up until index: 1740\n",
      "Completed up until index: 1760\n",
      "Completed up until index: 1780\n",
      "Now handling date: 2017-08-11.csv\n",
      "Number of new observations added to open_aq_locations: 1653\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Completed up until index: 60\n",
      "Completed up until index: 80\n",
      "Completed up until index: 100\n",
      "Completed up until index: 120\n",
      "Completed up until index: 140\n",
      "Completed up until index: 160\n",
      "Completed up until index: 180\n",
      "Completed up until index: 200\n",
      "Completed up until index: 220\n",
      "Completed up until index: 240\n",
      "Completed up until index: 260\n",
      "Completed up until index: 280\n",
      "Completed up until index: 300\n",
      "Completed up until index: 320\n",
      "Completed up until index: 340\n",
      "Completed up until index: 360\n",
      "Completed up until index: 380\n",
      "Completed up until index: 400\n",
      "Completed up until index: 420\n",
      "Completed up until index: 440\n",
      "Completed up until index: 460\n",
      "Completed up until index: 480\n",
      "Completed up until index: 500\n",
      "Completed up until index: 520\n",
      "Completed up until index: 540\n",
      "Completed up until index: 560\n",
      "Completed up until index: 580\n",
      "Completed up until index: 600\n",
      "Completed up until index: 620\n",
      "Completed up until index: 640\n",
      "Completed up until index: 660\n",
      "Completed up until index: 680\n",
      "Completed up until index: 700\n",
      "Completed up until index: 720\n",
      "Completed up until index: 740\n",
      "Completed up until index: 760\n",
      "Completed up until index: 780\n",
      "Completed up until index: 800\n",
      "Completed up until index: 820\n",
      "Completed up until index: 840\n",
      "Completed up until index: 860\n",
      "Completed up until index: 880\n",
      "Completed up until index: 900\n",
      "Completed up until index: 920\n",
      "Completed up until index: 940\n",
      "Completed up until index: 960\n",
      "Completed up until index: 980\n",
      "Completed up until index: 1000\n",
      "Completed up until index: 1020\n",
      "Completed up until index: 1040\n",
      "Completed up until index: 1060\n",
      "Completed up until index: 1080\n",
      "Completed up until index: 1100\n",
      "Completed up until index: 1120\n",
      "Completed up until index: 1140\n",
      "Completed up until index: 1160\n",
      "Completed up until index: 1180\n",
      "Completed up until index: 1200\n",
      "Completed up until index: 1220\n",
      "Completed up until index: 1240\n",
      "Completed up until index: 1260\n",
      "Completed up until index: 1280\n",
      "Completed up until index: 1300\n",
      "Completed up until index: 1320\n",
      "Completed up until index: 1340\n",
      "Completed up until index: 1360\n",
      "Completed up until index: 1380\n",
      "Completed up until index: 1400\n",
      "Completed up until index: 1420\n",
      "Completed up until index: 1440\n",
      "Completed up until index: 1460\n",
      "Completed up until index: 1480\n",
      "Completed up until index: 1500\n",
      "Completed up until index: 1520\n",
      "Completed up until index: 1540\n",
      "Completed up until index: 1560\n",
      "Completed up until index: 1580\n",
      "Completed up until index: 1600\n",
      "Completed up until index: 1620\n",
      "Completed up until index: 1640\n",
      "Completed up until index: 1660\n",
      "Now handling date: 2017-08-12.csv\n",
      "Number of new observations added to open_aq_locations: 1205\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Completed up until index: 60\n",
      "Completed up until index: 80\n",
      "Completed up until index: 100\n",
      "Completed up until index: 120\n",
      "Completed up until index: 140\n",
      "Completed up until index: 160\n",
      "Completed up until index: 180\n",
      "Completed up until index: 200\n",
      "Completed up until index: 220\n",
      "Completed up until index: 240\n",
      "Completed up until index: 260\n",
      "Completed up until index: 280\n",
      "Completed up until index: 300\n",
      "Completed up until index: 320\n",
      "Completed up until index: 340\n",
      "Completed up until index: 360\n",
      "Completed up until index: 380\n",
      "Completed up until index: 400\n",
      "Completed up until index: 420\n",
      "Completed up until index: 440\n",
      "Completed up until index: 460\n",
      "Completed up until index: 480\n",
      "Completed up until index: 500\n",
      "Completed up until index: 520\n",
      "Completed up until index: 540\n",
      "Completed up until index: 560\n",
      "Completed up until index: 580\n",
      "Completed up until index: 600\n",
      "Completed up until index: 620\n",
      "Completed up until index: 640\n",
      "Completed up until index: 660\n",
      "Completed up until index: 680\n",
      "Completed up until index: 700\n",
      "Completed up until index: 720\n",
      "Completed up until index: 740\n",
      "Completed up until index: 760\n",
      "Completed up until index: 780\n",
      "Completed up until index: 800\n",
      "Completed up until index: 820\n",
      "Completed up until index: 840\n",
      "Completed up until index: 860\n",
      "Completed up until index: 880\n",
      "Completed up until index: 900\n",
      "Completed up until index: 920\n",
      "Completed up until index: 940\n",
      "Completed up until index: 960\n",
      "Completed up until index: 980\n",
      "Completed up until index: 1000\n",
      "Completed up until index: 1020\n",
      "Completed up until index: 1040\n",
      "Completed up until index: 1060\n",
      "Completed up until index: 1080\n",
      "Completed up until index: 1100\n",
      "Completed up until index: 1120\n",
      "Completed up until index: 1140\n",
      "Completed up until index: 1160\n",
      "Completed up until index: 1180\n",
      "Completed up until index: 1200\n",
      "Completed up until index: 1220\n",
      "Now handling date: 2017-08-13.csv\n",
      "Number of new observations added to open_aq_locations: 1061\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Completed up until index: 60\n",
      "Completed up until index: 80\n",
      "Completed up until index: 100\n",
      "Completed up until index: 120\n",
      "Completed up until index: 140\n",
      "Completed up until index: 160\n",
      "Completed up until index: 180\n",
      "Completed up until index: 200\n",
      "Completed up until index: 220\n",
      "Completed up until index: 240\n",
      "Completed up until index: 260\n",
      "Completed up until index: 280\n",
      "Completed up until index: 300\n",
      "Completed up until index: 320\n",
      "Completed up until index: 340\n",
      "Completed up until index: 360\n",
      "Completed up until index: 380\n",
      "Completed up until index: 400\n",
      "Completed up until index: 420\n",
      "Completed up until index: 440\n",
      "Completed up until index: 460\n",
      "Completed up until index: 480\n",
      "Completed up until index: 500\n",
      "Completed up until index: 520\n",
      "Completed up until index: 540\n",
      "Completed up until index: 560\n",
      "Completed up until index: 580\n",
      "Completed up until index: 600\n",
      "Completed up until index: 620\n",
      "Completed up until index: 640\n",
      "Completed up until index: 660\n",
      "Completed up until index: 680\n",
      "Completed up until index: 700\n",
      "Completed up until index: 720\n",
      "Completed up until index: 740\n",
      "Completed up until index: 760\n",
      "Completed up until index: 780\n",
      "Completed up until index: 800\n",
      "Completed up until index: 820\n",
      "Completed up until index: 840\n",
      "Completed up until index: 860\n",
      "Completed up until index: 880\n",
      "Completed up until index: 900\n",
      "Completed up until index: 920\n",
      "Completed up until index: 940\n",
      "Completed up until index: 960\n",
      "Completed up until index: 980\n",
      "Completed up until index: 1000\n",
      "Completed up until index: 1020\n",
      "Completed up until index: 1040\n",
      "Completed up until index: 1060\n",
      "Completed up until index: 1080\n",
      "Now handling date: 2017-08-14.csv\n",
      "Number of new observations added to open_aq_locations: 775\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Completed up until index: 60\n",
      "Completed up until index: 80\n",
      "Completed up until index: 100\n",
      "Completed up until index: 120\n",
      "Completed up until index: 140\n",
      "Completed up until index: 160\n",
      "Completed up until index: 180\n",
      "Completed up until index: 200\n",
      "Completed up until index: 220\n",
      "Completed up until index: 240\n",
      "Completed up until index: 260\n",
      "Completed up until index: 280\n",
      "Completed up until index: 300\n",
      "Completed up until index: 320\n",
      "Completed up until index: 340\n",
      "Completed up until index: 360\n",
      "Completed up until index: 380\n",
      "Completed up until index: 400\n",
      "Completed up until index: 420\n",
      "Completed up until index: 440\n",
      "Completed up until index: 460\n",
      "Completed up until index: 480\n",
      "Completed up until index: 500\n",
      "Completed up until index: 520\n",
      "Completed up until index: 540\n",
      "Completed up until index: 560\n",
      "Completed up until index: 580\n",
      "Completed up until index: 600\n",
      "Completed up until index: 620\n",
      "Completed up until index: 640\n",
      "Completed up until index: 660\n",
      "Completed up until index: 680\n",
      "Completed up until index: 700\n",
      "Completed up until index: 720\n",
      "Completed up until index: 740\n",
      "Completed up until index: 760\n",
      "Completed up until index: 780\n",
      "Now handling date: 2017-08-15.csv\n",
      "Number of new observations added to open_aq_locations: 581\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Completed up until index: 60\n",
      "Completed up until index: 80\n",
      "Completed up until index: 100\n",
      "Completed up until index: 120\n",
      "Completed up until index: 140\n",
      "Completed up until index: 160\n",
      "Completed up until index: 180\n",
      "Completed up until index: 200\n",
      "Completed up until index: 220\n",
      "Completed up until index: 240\n",
      "Completed up until index: 260\n",
      "Completed up until index: 280\n",
      "Completed up until index: 300\n",
      "Completed up until index: 320\n",
      "Completed up until index: 340\n",
      "Completed up until index: 360\n",
      "Completed up until index: 380\n",
      "Completed up until index: 400\n",
      "Completed up until index: 420\n",
      "Completed up until index: 440\n",
      "Completed up until index: 460\n",
      "Completed up until index: 480\n",
      "Completed up until index: 500\n",
      "Completed up until index: 520\n",
      "Completed up until index: 540\n",
      "Completed up until index: 560\n",
      "Completed up until index: 580\n",
      "Completed up until index: 600\n",
      "Now handling date: 2017-08-16.csv\n",
      "Number of new observations added to open_aq_locations: 486\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Completed up until index: 60\n",
      "Completed up until index: 80\n",
      "Completed up until index: 100\n",
      "Completed up until index: 120\n",
      "Completed up until index: 140\n",
      "Completed up until index: 160\n",
      "Completed up until index: 180\n",
      "Completed up until index: 200\n",
      "Completed up until index: 220\n",
      "Completed up until index: 240\n",
      "Completed up until index: 260\n",
      "Completed up until index: 280\n",
      "Completed up until index: 300\n",
      "Completed up until index: 320\n",
      "Completed up until index: 340\n",
      "Completed up until index: 360\n",
      "Completed up until index: 380\n",
      "Completed up until index: 400\n",
      "Completed up until index: 420\n",
      "Completed up until index: 440\n",
      "Completed up until index: 460\n",
      "Completed up until index: 480\n",
      "Completed up until index: 500\n",
      "Now handling date: 2017-08-17.csv\n",
      "Number of new observations added to open_aq_locations: 345\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Completed up until index: 60\n",
      "Completed up until index: 80\n",
      "Completed up until index: 100\n",
      "Completed up until index: 120\n",
      "Completed up until index: 140\n",
      "Completed up until index: 160\n",
      "Completed up until index: 180\n",
      "Completed up until index: 200\n",
      "Completed up until index: 220\n",
      "Completed up until index: 240\n",
      "Completed up until index: 260\n",
      "Completed up until index: 280\n",
      "Completed up until index: 300\n",
      "Completed up until index: 320\n",
      "Completed up until index: 340\n",
      "Completed up until index: 360\n",
      "Now handling date: 2017-08-18.csv\n",
      "Number of new observations added to open_aq_locations: 314\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Completed up until index: 60\n",
      "Completed up until index: 80\n",
      "Completed up until index: 100\n",
      "Completed up until index: 120\n",
      "Completed up until index: 140\n",
      "Completed up until index: 160\n",
      "Completed up until index: 180\n",
      "Completed up until index: 200\n",
      "Completed up until index: 220\n",
      "Completed up until index: 240\n",
      "Completed up until index: 260\n",
      "Completed up until index: 280\n",
      "Completed up until index: 300\n",
      "Completed up until index: 320\n",
      "Now handling date: 2017-08-19.csv\n",
      "Number of new observations added to open_aq_locations: 283\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Completed up until index: 60\n",
      "Completed up until index: 80\n",
      "Completed up until index: 100\n",
      "Completed up until index: 120\n",
      "Completed up until index: 140\n",
      "Completed up until index: 160\n",
      "Completed up until index: 180\n",
      "Completed up until index: 200\n",
      "Completed up until index: 220\n",
      "Completed up until index: 240\n",
      "Completed up until index: 260\n",
      "Completed up until index: 280\n",
      "Completed up until index: 300\n",
      "Now handling date: 2017-08-20.csv\n",
      "Number of new observations added to open_aq_locations: 277\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Completed up until index: 60\n",
      "Completed up until index: 80\n",
      "Completed up until index: 100\n",
      "Completed up until index: 120\n",
      "Completed up until index: 140\n",
      "Completed up until index: 160\n",
      "Completed up until index: 180\n",
      "Completed up until index: 200\n",
      "Completed up until index: 220\n",
      "Completed up until index: 240\n",
      "Completed up until index: 260\n",
      "Completed up until index: 280\n",
      "Now handling date: 2017-08-21.csv\n",
      "Number of new observations added to open_aq_locations: 259\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Completed up until index: 60\n",
      "Completed up until index: 80\n",
      "Completed up until index: 100\n",
      "Completed up until index: 120\n",
      "Completed up until index: 140\n",
      "Completed up until index: 160\n",
      "Completed up until index: 180\n",
      "Completed up until index: 200\n",
      "Completed up until index: 220\n",
      "Completed up until index: 240\n",
      "Completed up until index: 260\n",
      "Now handling date: 2017-08-22.csv\n",
      "Number of new observations added to open_aq_locations: 203\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Completed up until index: 60\n",
      "Completed up until index: 80\n",
      "Completed up until index: 100\n",
      "Completed up until index: 120\n",
      "Completed up until index: 140\n",
      "Completed up until index: 160\n",
      "Completed up until index: 180\n",
      "Completed up until index: 200\n",
      "Completed up until index: 220\n",
      "Now handling date: 2017-08-23.csv\n",
      "Number of new observations added to open_aq_locations: 209\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Completed up until index: 60\n",
      "Completed up until index: 80\n",
      "Completed up until index: 100\n",
      "Completed up until index: 120\n",
      "Completed up until index: 140\n",
      "Completed up until index: 160\n",
      "Completed up until index: 180\n",
      "Completed up until index: 200\n",
      "Completed up until index: 220\n",
      "Now handling date: 2017-08-24.csv\n",
      "Number of new observations added to open_aq_locations: 186\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Completed up until index: 60\n",
      "Completed up until index: 80\n",
      "Completed up until index: 100\n",
      "Completed up until index: 120\n",
      "Completed up until index: 140\n",
      "Completed up until index: 160\n",
      "Completed up until index: 180\n",
      "Completed up until index: 200\n",
      "Now handling date: 2017-08-25.csv\n",
      "Number of new observations added to open_aq_locations: 145\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Completed up until index: 60\n",
      "Completed up until index: 80\n",
      "Completed up until index: 100\n",
      "Completed up until index: 120\n",
      "Completed up until index: 140\n",
      "Completed up until index: 160\n",
      "Now handling date: 2017-08-26.csv\n",
      "Number of new observations added to open_aq_locations: 138\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Completed up until index: 60\n",
      "Completed up until index: 80\n",
      "Completed up until index: 100\n",
      "Completed up until index: 120\n",
      "Completed up until index: 140\n",
      "Now handling date: 2017-08-27.csv\n",
      "Number of new observations added to open_aq_locations: 129\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Completed up until index: 60\n",
      "Completed up until index: 80\n",
      "Completed up until index: 100\n",
      "Completed up until index: 120\n",
      "Completed up until index: 140\n",
      "Now handling date: 2017-08-28.csv\n",
      "Number of new observations added to open_aq_locations: 117\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Completed up until index: 60\n",
      "Completed up until index: 80\n",
      "Completed up until index: 100\n",
      "Completed up until index: 120\n",
      "Now handling date: 2017-08-29.csv\n",
      "Number of new observations added to open_aq_locations: 110\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Completed up until index: 60\n",
      "Completed up until index: 80\n",
      "Completed up until index: 100\n",
      "Completed up until index: 120\n",
      "Now handling date: 2017-08-30.csv\n",
      "Number of new observations added to open_aq_locations: 149\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Completed up until index: 60\n",
      "Completed up until index: 80\n",
      "Completed up until index: 100\n",
      "Completed up until index: 120\n",
      "Completed up until index: 140\n",
      "Completed up until index: 160\n",
      "Now handling date: 2017-08-31.csv\n",
      "Number of new observations added to open_aq_locations: 101\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Completed up until index: 60\n",
      "Completed up until index: 80\n",
      "Completed up until index: 100\n",
      "Completed up until index: 120\n",
      "Now handling date: 2017-09-01.csv\n",
      "Number of new observations added to open_aq_locations: 86\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Completed up until index: 60\n",
      "Completed up until index: 80\n",
      "Completed up until index: 100\n",
      "Now handling date: 2017-09-02.csv\n",
      "Number of new observations added to open_aq_locations: 78\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Completed up until index: 60\n",
      "Completed up until index: 80\n",
      "Now handling date: 2017-09-03.csv\n",
      "Number of new observations added to open_aq_locations: 80\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Completed up until index: 60\n",
      "Completed up until index: 80\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2017-09-04.csv\n",
      "Number of new observations added to open_aq_locations: 77\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Completed up until index: 60\n",
      "Completed up until index: 80\n",
      "Now handling date: 2017-09-05.csv\n",
      "Number of new observations added to open_aq_locations: 72\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Completed up until index: 60\n",
      "Completed up until index: 80\n",
      "Now handling date: 2017-09-06.csv\n",
      "Number of new observations added to open_aq_locations: 79\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Completed up until index: 60\n",
      "Completed up until index: 80\n",
      "Now handling date: 2017-09-07.csv\n",
      "Number of new observations added to open_aq_locations: 48\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Completed up until index: 60\n",
      "Now handling date: 2017-09-08.csv\n",
      "Number of new observations added to open_aq_locations: 65\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Completed up until index: 60\n",
      "Completed up until index: 80\n",
      "Now handling date: 2017-09-09.csv\n",
      "Number of new observations added to open_aq_locations: 64\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Completed up until index: 60\n",
      "Completed up until index: 80\n",
      "Now handling date: 2017-09-10.csv\n",
      "Number of new observations added to open_aq_locations: 68\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Completed up until index: 60\n",
      "Completed up until index: 80\n",
      "Now handling date: 2017-09-11.csv\n",
      "Number of new observations added to open_aq_locations: 76\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Completed up until index: 60\n",
      "Completed up until index: 80\n",
      "Now handling date: 2017-09-12.csv\n",
      "Number of new observations added to open_aq_locations: 102\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Completed up until index: 60\n",
      "Completed up until index: 80\n",
      "Completed up until index: 100\n",
      "Completed up until index: 120\n",
      "Now handling date: 2017-09-13.csv\n",
      "Number of new observations added to open_aq_locations: 98\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Completed up until index: 60\n",
      "Completed up until index: 80\n",
      "Completed up until index: 100\n",
      "Now handling date: 2017-09-14.csv\n",
      "Number of new observations added to open_aq_locations: 213\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Completed up until index: 60\n",
      "Completed up until index: 80\n",
      "Completed up until index: 100\n",
      "Completed up until index: 120\n",
      "Completed up until index: 140\n",
      "Completed up until index: 160\n",
      "Completed up until index: 180\n",
      "Completed up until index: 200\n",
      "Completed up until index: 220\n",
      "Now handling date: 2017-09-15.csv\n",
      "Number of new observations added to open_aq_locations: 60\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Completed up until index: 60\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2017-09-16.csv\n",
      "Number of new observations added to open_aq_locations: 54\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Completed up until index: 60\n",
      "Now handling date: 2017-09-17.csv\n",
      "Number of new observations added to open_aq_locations: 44\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Completed up until index: 60\n",
      "Now handling date: 2017-09-18.csv\n",
      "Number of new observations added to open_aq_locations: 99\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Completed up until index: 60\n",
      "Completed up until index: 80\n",
      "Completed up until index: 100\n",
      "Now handling date: 2017-09-19.csv\n",
      "Number of new observations added to open_aq_locations: 47\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Completed up until index: 60\n",
      "Now handling date: 2017-09-20.csv\n",
      "Number of new observations added to open_aq_locations: 56\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Completed up until index: 60\n",
      "Now handling date: 2017-09-21.csv\n",
      "Number of new observations added to open_aq_locations: 89\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Completed up until index: 60\n",
      "Completed up until index: 80\n",
      "Completed up until index: 100\n",
      "Now handling date: 2017-09-22.csv\n",
      "Number of new observations added to open_aq_locations: 63\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Completed up until index: 60\n",
      "Completed up until index: 80\n",
      "Now handling date: 2017-09-23.csv\n",
      "Number of new observations added to open_aq_locations: 41\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Completed up until index: 60\n",
      "Now handling date: 2017-09-24.csv\n",
      "Number of new observations added to open_aq_locations: 43\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Completed up until index: 60\n",
      "Now handling date: 2017-09-25.csv\n",
      "Number of new observations added to open_aq_locations: 38\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Now handling date: 2017-09-26.csv\n",
      "Number of new observations added to open_aq_locations: 20\n",
      "Completed up until index: 20\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2017-09-27.csv\n",
      "Number of new observations added to open_aq_locations: 31\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Now handling date: 2017-09-28.csv\n",
      "Number of new observations added to open_aq_locations: 16\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-09-29.csv\n",
      "Number of new observations added to open_aq_locations: 23\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Now handling date: 2017-09-30.csv\n",
      "Number of new observations added to open_aq_locations: 31\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Now handling date: 2017-10-01.csv\n",
      "Number of new observations added to open_aq_locations: 46\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Completed up until index: 60\n",
      "Now handling date: 2017-10-02.csv\n",
      "Number of new observations added to open_aq_locations: 32\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Now handling date: 2017-10-03.csv\n",
      "Number of new observations added to open_aq_locations: 25\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Now handling date: 2017-10-04.csv\n",
      "Number of new observations added to open_aq_locations: 24\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Now handling date: 2017-10-05.csv\n",
      "Number of new observations added to open_aq_locations: 27\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Now handling date: 2017-10-06.csv\n",
      "Number of new observations added to open_aq_locations: 15\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-10-07.csv\n",
      "Number of new observations added to open_aq_locations: 22\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Now handling date: 2017-10-08.csv\n",
      "Number of new observations added to open_aq_locations: 16\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-10-09.csv\n",
      "Number of new observations added to open_aq_locations: 11\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-10-10.csv\n",
      "Number of new observations added to open_aq_locations: 21\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Now handling date: 2017-10-11.csv\n",
      "Number of new observations added to open_aq_locations: 19\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-10-12.csv\n",
      "Number of new observations added to open_aq_locations: 25\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Now handling date: 2017-10-13.csv\n",
      "Number of new observations added to open_aq_locations: 14\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-10-14.csv\n",
      "Number of new observations added to open_aq_locations: 12\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-10-15.csv\n",
      "Number of new observations added to open_aq_locations: 16\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-10-16.csv\n",
      "Number of new observations added to open_aq_locations: 15\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-10-17.csv\n",
      "Number of new observations added to open_aq_locations: 24\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Now handling date: 2017-10-18.csv\n",
      "Number of new observations added to open_aq_locations: 21\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Now handling date: 2017-10-19.csv\n",
      "Number of new observations added to open_aq_locations: 26\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Now handling date: 2017-10-20.csv\n",
      "Number of new observations added to open_aq_locations: 16\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-10-21.csv\n",
      "Number of new observations added to open_aq_locations: 19\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-10-22.csv\n",
      "Number of new observations added to open_aq_locations: 13\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-10-23.csv\n",
      "Number of new observations added to open_aq_locations: 10\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-10-24.csv\n",
      "Number of new observations added to open_aq_locations: 26\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Now handling date: 2017-10-25.csv\n",
      "Number of new observations added to open_aq_locations: 26\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Now handling date: 2017-10-26.csv\n",
      "Number of new observations added to open_aq_locations: 5\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-10-27.csv\n",
      "Number of new observations added to open_aq_locations: 15\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-10-28.csv\n",
      "Number of new observations added to open_aq_locations: 28\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Now handling date: 2017-10-29.csv\n",
      "Number of new observations added to open_aq_locations: 28\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Now handling date: 2017-10-30.csv\n",
      "Number of new observations added to open_aq_locations: 24\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Now handling date: 2017-10-31.csv\n",
      "Number of new observations added to open_aq_locations: 5\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-11-01.csv\n",
      "Number of new observations added to open_aq_locations: 65\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Completed up until index: 60\n",
      "Completed up until index: 80\n",
      "Now handling date: 2017-11-02.csv\n",
      "Number of new observations added to open_aq_locations: 16\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-11-03.csv\n",
      "Number of new observations added to open_aq_locations: 10\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-11-04.csv\n",
      "Number of new observations added to open_aq_locations: 10\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-11-05.csv\n",
      "Number of new observations added to open_aq_locations: 11\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-11-06.csv\n",
      "Number of new observations added to open_aq_locations: 13\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-11-07.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-11-08.csv\n",
      "Number of new observations added to open_aq_locations: 11\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-11-09.csv\n",
      "Number of new observations added to open_aq_locations: 12\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-11-10.csv\n",
      "Number of new observations added to open_aq_locations: 11\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-11-11.csv\n",
      "Number of new observations added to open_aq_locations: 15\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-11-12.csv\n",
      "Number of new observations added to open_aq_locations: 28\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Now handling date: 2017-11-13.csv\n",
      "Number of new observations added to open_aq_locations: 26\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Now handling date: 2017-11-14.csv\n",
      "Number of new observations added to open_aq_locations: 25\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Now handling date: 2017-11-15.csv\n",
      "Number of new observations added to open_aq_locations: 28\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Now handling date: 2017-11-16.csv\n",
      "Number of new observations added to open_aq_locations: 24\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Now handling date: 2017-11-17.csv\n",
      "Number of new observations added to open_aq_locations: 10\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-11-18.csv\n",
      "Number of new observations added to open_aq_locations: 24\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Now handling date: 2017-11-19.csv\n",
      "Number of new observations added to open_aq_locations: 9\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-11-20.csv\n",
      "Number of new observations added to open_aq_locations: 40\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2017-11-21.csv\n",
      "Number of new observations added to open_aq_locations: 22\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Now handling date: 2017-11-22.csv\n",
      "Number of new observations added to open_aq_locations: 25\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Now handling date: 2017-11-23.csv\n",
      "Number of new observations added to open_aq_locations: 22\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Now handling date: 2017-11-24.csv\n",
      "Number of new observations added to open_aq_locations: 24\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Now handling date: 2017-11-25.csv\n",
      "Number of new observations added to open_aq_locations: 19\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-11-26.csv\n",
      "Number of new observations added to open_aq_locations: 15\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-11-27.csv\n",
      "Number of new observations added to open_aq_locations: 11\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-11-28.csv\n",
      "Number of new observations added to open_aq_locations: 11\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-11-29.csv\n",
      "Number of new observations added to open_aq_locations: 22\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Now handling date: 2017-11-30.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-12-01.csv\n",
      "Number of new observations added to open_aq_locations: 48\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Completed up until index: 60\n",
      "Now handling date: 2017-12-02.csv\n",
      "Number of new observations added to open_aq_locations: 29\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Now handling date: 2017-12-03.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-12-04.csv\n",
      "Number of new observations added to open_aq_locations: 28\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Now handling date: 2017-12-05.csv\n",
      "Number of new observations added to open_aq_locations: 18\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-12-06.csv\n",
      "Number of new observations added to open_aq_locations: 13\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-12-07.csv\n",
      "Number of new observations added to open_aq_locations: 9\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-12-08.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2017-12-09.csv\n",
      "Number of new observations added to open_aq_locations: 16\n",
      "Completed up until index: 20\n",
      "Now handling date: 2017-12-10.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# 310 comes from the code snippet below, to restart code and add in date to output of each loop\n",
    "for csv in keys[597:]:\n",
    "    if csv[-3:] == \"csv\":\n",
    "        print(\"Now handling date:\", csv)\n",
    "        url = \"https://openaq-data.s3.amazonaws.com/\"+csv\n",
    "        data = pd.read_csv(url)\n",
    "        \n",
    "        kwargs = {\n",
    "            \"data_df\":data,\n",
    "            \"target_table_name\":\"open_aq_locations\",\n",
    "            \"cols_and_types\":cols_and_types_locations,\n",
    "            \"cols_with_apostrophes\":[\"location\", \"city\",\"country\"],\n",
    "            \"float_cols_to_round\":[\"latitude\", \"longitude\"],\n",
    "            \"precision\":6\n",
    "        }\n",
    "\n",
    "        update_table_without_duplicates(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([598]),)"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I wanted to add in a date display to the loop above\n",
    "# Used the code below to figure where I had stopped previously\n",
    "np.where(np.array(keys)==csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read open_aq_locations table from Carto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of duplicates in the table: 657\n",
      "\n",
      "A list of all locations ever reporting to the OpenAQ network:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Escuela E-10</td>\n",
       "      <td>Tocopilla</td>\n",
       "      <td>CL</td>\n",
       "      <td>-22.085519</td>\n",
       "      <td>-70.188683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chiu Chiu</td>\n",
       "      <td>Calama</td>\n",
       "      <td>CL</td>\n",
       "      <td>-22.342264</td>\n",
       "      <td>-68.650897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Santa Margarita</td>\n",
       "      <td>Catemu</td>\n",
       "      <td>CL</td>\n",
       "      <td>-32.776573</td>\n",
       "      <td>-70.938144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nueva Libertad</td>\n",
       "      <td>Talcahuano</td>\n",
       "      <td>CL</td>\n",
       "      <td>-36.735998</td>\n",
       "      <td>-73.118693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lo Campo</td>\n",
       "      <td>Panquehue</td>\n",
       "      <td>CL</td>\n",
       "      <td>-32.797715</td>\n",
       "      <td>-70.898037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Coronel Sur</td>\n",
       "      <td>Coronel</td>\n",
       "      <td>CL</td>\n",
       "      <td>-37.031702</td>\n",
       "      <td>-73.138689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Catemu</td>\n",
       "      <td>Catemu</td>\n",
       "      <td>CL</td>\n",
       "      <td>-32.779208</td>\n",
       "      <td>-70.959114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Calabozo</td>\n",
       "      <td>Coronel</td>\n",
       "      <td>CL</td>\n",
       "      <td>-36.996431</td>\n",
       "      <td>-73.115805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Romeral</td>\n",
       "      <td>Hijuelas</td>\n",
       "      <td>CL</td>\n",
       "      <td>-32.823956</td>\n",
       "      <td>-71.006441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lilla Essingen (E4/E20)</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>SE</td>\n",
       "      <td>59.325519</td>\n",
       "      <td>18.003961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>E4/E20 Lilla Essingen</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>SE</td>\n",
       "      <td>59.325519</td>\n",
       "      <td>18.003961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>E4 Sollentuna Häggvik</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>SE</td>\n",
       "      <td>59.443539</td>\n",
       "      <td>17.922361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Hågelbyleden Botkyrka</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>SE</td>\n",
       "      <td>59.237058</td>\n",
       "      <td>17.838332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Sveavägen</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>SE</td>\n",
       "      <td>59.345161</td>\n",
       "      <td>18.054282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Estación Centro</td>\n",
       "      <td>Calama</td>\n",
       "      <td>CL</td>\n",
       "      <td>-22.462145</td>\n",
       "      <td>-68.928062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Gävle Södra Kungsgatan</td>\n",
       "      <td>Gävle</td>\n",
       "      <td>SE</td>\n",
       "      <td>60.671552</td>\n",
       "      <td>17.146915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Hornsgatan</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>SE</td>\n",
       "      <td>59.317132</td>\n",
       "      <td>18.048787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Folkungagatan</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>SE</td>\n",
       "      <td>59.314624</td>\n",
       "      <td>18.075856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Norrlandsgatan</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>SE</td>\n",
       "      <td>59.336356</td>\n",
       "      <td>18.070626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Södertälje Turingegatan</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>SE</td>\n",
       "      <td>59.198124</td>\n",
       "      <td>17.621087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Uppsala Kungsgatan</td>\n",
       "      <td>Uppsala</td>\n",
       "      <td>SE</td>\n",
       "      <td>59.859530</td>\n",
       "      <td>17.642484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Complejo Deportivo 23 de Marzo</td>\n",
       "      <td>Calama</td>\n",
       "      <td>CL</td>\n",
       "      <td>-22.460271</td>\n",
       "      <td>-68.937707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Colegio Pedro Vergara Keller</td>\n",
       "      <td>Calama</td>\n",
       "      <td>CL</td>\n",
       "      <td>-22.442839</td>\n",
       "      <td>-68.932546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Armutlu-MTHM</td>\n",
       "      <td>Yalova</td>\n",
       "      <td>TR</td>\n",
       "      <td>40.529350</td>\n",
       "      <td>28.784590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Kültür Park-MTHM</td>\n",
       "      <td>Bursa</td>\n",
       "      <td>TR</td>\n",
       "      <td>40.195720</td>\n",
       "      <td>29.045880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Sultanbeyli-MTHM</td>\n",
       "      <td>İstanbul</td>\n",
       "      <td>TR</td>\n",
       "      <td>40.984470</td>\n",
       "      <td>29.268810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Çerkezköy-MTHM</td>\n",
       "      <td>Tekirdağ</td>\n",
       "      <td>TR</td>\n",
       "      <td>41.318350</td>\n",
       "      <td>27.980180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Erdek-MTHM</td>\n",
       "      <td>Balıkesir</td>\n",
       "      <td>TR</td>\n",
       "      <td>40.489720</td>\n",
       "      <td>27.978610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Beyazıt Cad.-MTHM</td>\n",
       "      <td>Bursa</td>\n",
       "      <td>TR</td>\n",
       "      <td>40.185650</td>\n",
       "      <td>29.080490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Uludağ Üniv.-MTHM</td>\n",
       "      <td>Bursa</td>\n",
       "      <td>TR</td>\n",
       "      <td>40.223370</td>\n",
       "      <td>28.871540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26367</th>\n",
       "      <td>תחנה:אחוזה</td>\n",
       "      <td>עמק יזרעאל</td>\n",
       "      <td>IL</td>\n",
       "      <td>32.644080</td>\n",
       "      <td>35.351740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26368</th>\n",
       "      <td>תחנה:יד אבנר</td>\n",
       "      <td>גוש דן</td>\n",
       "      <td>IL</td>\n",
       "      <td>32.093380</td>\n",
       "      <td>34.790130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26369</th>\n",
       "      <td>תחנה:כ.חסידים</td>\n",
       "      <td>גוש דן</td>\n",
       "      <td>IL</td>\n",
       "      <td>31.987899</td>\n",
       "      <td>34.757384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26370</th>\n",
       "      <td>תחנה:תחנה ניידת ברכבת 1(וולפסון)</td>\n",
       "      <td>מישור החוף הדרומי</td>\n",
       "      <td>IL</td>\n",
       "      <td>31.686100</td>\n",
       "      <td>34.636180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26371</th>\n",
       "      <td>תחנה:יד לבנים</td>\n",
       "      <td>גוש דן</td>\n",
       "      <td>IL</td>\n",
       "      <td>31.987899</td>\n",
       "      <td>34.757384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26372</th>\n",
       "      <td>תחנה:ניידת6</td>\n",
       "      <td>תחנות ניידות</td>\n",
       "      <td>IL</td>\n",
       "      <td>32.100139</td>\n",
       "      <td>34.839027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26373</th>\n",
       "      <td>תחנה:רכבת השלום</td>\n",
       "      <td>שרון</td>\n",
       "      <td>IL</td>\n",
       "      <td>32.476990</td>\n",
       "      <td>35.086000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26374</th>\n",
       "      <td>תחנה:אשלים</td>\n",
       "      <td>מישור החוף הדרומי</td>\n",
       "      <td>IL</td>\n",
       "      <td>31.819420</td>\n",
       "      <td>34.693460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26375</th>\n",
       "      <td>תחנה:ק.אתא</td>\n",
       "      <td>מישור החוף הדרומי</td>\n",
       "      <td>IL</td>\n",
       "      <td>31.818470</td>\n",
       "      <td>34.669110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26376</th>\n",
       "      <td>תחנה:רכבת השלום</td>\n",
       "      <td>שרון</td>\n",
       "      <td>IL</td>\n",
       "      <td>32.632440</td>\n",
       "      <td>35.065650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26377</th>\n",
       "      <td>תחנה:ק.טבעון</td>\n",
       "      <td>גוש דן</td>\n",
       "      <td>IL</td>\n",
       "      <td>31.987899</td>\n",
       "      <td>34.757384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26378</th>\n",
       "      <td>תחנה:אליכין</td>\n",
       "      <td>גוש דן</td>\n",
       "      <td>IL</td>\n",
       "      <td>32.091350</td>\n",
       "      <td>34.825990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26379</th>\n",
       "      <td>תחנה:אילת 6</td>\n",
       "      <td>שרון</td>\n",
       "      <td>IL</td>\n",
       "      <td>32.408560</td>\n",
       "      <td>34.918240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26380</th>\n",
       "      <td>תחנה:מגל</td>\n",
       "      <td>גוש דן</td>\n",
       "      <td>IL</td>\n",
       "      <td>31.987899</td>\n",
       "      <td>34.757384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26381</th>\n",
       "      <td>תחנה:רכבת השלום</td>\n",
       "      <td>מישור החוף הדרומי</td>\n",
       "      <td>IL</td>\n",
       "      <td>31.782860</td>\n",
       "      <td>34.706200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26382</th>\n",
       "      <td>תחנה:רכבת השלום</td>\n",
       "      <td>גוש דן</td>\n",
       "      <td>IL</td>\n",
       "      <td>32.131722</td>\n",
       "      <td>34.831939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26383</th>\n",
       "      <td>תחנה:ניידת6</td>\n",
       "      <td>שרון</td>\n",
       "      <td>IL</td>\n",
       "      <td>32.441110</td>\n",
       "      <td>34.960670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26384</th>\n",
       "      <td>תחנה:הדר</td>\n",
       "      <td>גוש דן</td>\n",
       "      <td>IL</td>\n",
       "      <td>32.119000</td>\n",
       "      <td>34.802500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26385</th>\n",
       "      <td>תחנה:תחנה ניידת ברכבת 1(וולפסון)</td>\n",
       "      <td>חיפה וקריות</td>\n",
       "      <td>IL</td>\n",
       "      <td>32.851820</td>\n",
       "      <td>35.078730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26386</th>\n",
       "      <td>תחנה:תחנה ניידת ברכבת 1(וולפסון)</td>\n",
       "      <td>מישור החוף הדרומי</td>\n",
       "      <td>IL</td>\n",
       "      <td>31.606330</td>\n",
       "      <td>34.760700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26387</th>\n",
       "      <td>תחנה:כ.מהרל</td>\n",
       "      <td>גוש דן</td>\n",
       "      <td>IL</td>\n",
       "      <td>31.987899</td>\n",
       "      <td>34.757384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26388</th>\n",
       "      <td>תחנה:לוט</td>\n",
       "      <td>מישור החוף הדרומי</td>\n",
       "      <td>IL</td>\n",
       "      <td>31.818470</td>\n",
       "      <td>34.669110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26389</th>\n",
       "      <td>תחנה:תחנה ניידת ברכבת 1(וולפסון)</td>\n",
       "      <td>מישור החוף הדרומי</td>\n",
       "      <td>IL</td>\n",
       "      <td>31.684660</td>\n",
       "      <td>34.881790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26390</th>\n",
       "      <td>תחנה:נ.שאנן</td>\n",
       "      <td>חיפה וקריות</td>\n",
       "      <td>IL</td>\n",
       "      <td>32.721800</td>\n",
       "      <td>35.129400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26391</th>\n",
       "      <td>תחנה:גן דרום</td>\n",
       "      <td>גוש דן</td>\n",
       "      <td>IL</td>\n",
       "      <td>32.107910</td>\n",
       "      <td>34.789500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26392</th>\n",
       "      <td>תחנה:הדר</td>\n",
       "      <td>מישור החוף הדרומי</td>\n",
       "      <td>IL</td>\n",
       "      <td>31.826520</td>\n",
       "      <td>34.684280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26393</th>\n",
       "      <td>תחנה:רוממה</td>\n",
       "      <td>גוש דן</td>\n",
       "      <td>IL</td>\n",
       "      <td>31.987899</td>\n",
       "      <td>34.757384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26394</th>\n",
       "      <td>Pratu Chai, Phra Nakhon Si Ayutthayal</td>\n",
       "      <td>Ayutthaya</td>\n",
       "      <td>TH</td>\n",
       "      <td>14.349367</td>\n",
       "      <td>100.568535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26395</th>\n",
       "      <td>La Florida</td>\n",
       "      <td>Talca</td>\n",
       "      <td>CL</td>\n",
       "      <td>-35.435142</td>\n",
       "      <td>-71.678261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26396</th>\n",
       "      <td>CZ0THAR</td>\n",
       "      <td>Moravskoslezský</td>\n",
       "      <td>CZ</td>\n",
       "      <td>49.791005</td>\n",
       "      <td>18.406839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26397 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    location               city country  \\\n",
       "0                               Escuela E-10          Tocopilla      CL   \n",
       "1                                  Chiu Chiu             Calama      CL   \n",
       "2                            Santa Margarita             Catemu      CL   \n",
       "3                             Nueva Libertad         Talcahuano      CL   \n",
       "4                                   Lo Campo          Panquehue      CL   \n",
       "5                                Coronel Sur            Coronel      CL   \n",
       "6                                     Catemu             Catemu      CL   \n",
       "7                                   Calabozo            Coronel      CL   \n",
       "8                                    Romeral           Hijuelas      CL   \n",
       "9                    Lilla Essingen (E4/E20)          Stockholm      SE   \n",
       "10                     E4/E20 Lilla Essingen          Stockholm      SE   \n",
       "11                     E4 Sollentuna Häggvik          Stockholm      SE   \n",
       "12                     Hågelbyleden Botkyrka          Stockholm      SE   \n",
       "13                                 Sveavägen          Stockholm      SE   \n",
       "14                           Estación Centro             Calama      CL   \n",
       "15                    Gävle Södra Kungsgatan              Gävle      SE   \n",
       "16                                Hornsgatan          Stockholm      SE   \n",
       "17                             Folkungagatan          Stockholm      SE   \n",
       "18                            Norrlandsgatan          Stockholm      SE   \n",
       "19                   Södertälje Turingegatan          Stockholm      SE   \n",
       "20                        Uppsala Kungsgatan            Uppsala      SE   \n",
       "21            Complejo Deportivo 23 de Marzo             Calama      CL   \n",
       "22              Colegio Pedro Vergara Keller             Calama      CL   \n",
       "23                              Armutlu-MTHM             Yalova      TR   \n",
       "24                          Kültür Park-MTHM              Bursa      TR   \n",
       "25                          Sultanbeyli-MTHM           İstanbul      TR   \n",
       "26                            Çerkezköy-MTHM           Tekirdağ      TR   \n",
       "27                                Erdek-MTHM          Balıkesir      TR   \n",
       "28                         Beyazıt Cad.-MTHM              Bursa      TR   \n",
       "29                         Uludağ Üniv.-MTHM              Bursa      TR   \n",
       "...                                      ...                ...     ...   \n",
       "26367                             תחנה:אחוזה         עמק יזרעאל      IL   \n",
       "26368                           תחנה:יד אבנר             גוש דן      IL   \n",
       "26369                          תחנה:כ.חסידים             גוש דן      IL   \n",
       "26370       תחנה:תחנה ניידת ברכבת 1(וולפסון)  מישור החוף הדרומי      IL   \n",
       "26371                          תחנה:יד לבנים             גוש דן      IL   \n",
       "26372                            תחנה:ניידת6       תחנות ניידות      IL   \n",
       "26373                        תחנה:רכבת השלום               שרון      IL   \n",
       "26374                             תחנה:אשלים  מישור החוף הדרומי      IL   \n",
       "26375                             תחנה:ק.אתא  מישור החוף הדרומי      IL   \n",
       "26376                        תחנה:רכבת השלום               שרון      IL   \n",
       "26377                           תחנה:ק.טבעון             גוש דן      IL   \n",
       "26378                            תחנה:אליכין             גוש דן      IL   \n",
       "26379                            תחנה:אילת 6               שרון      IL   \n",
       "26380                               תחנה:מגל             גוש דן      IL   \n",
       "26381                        תחנה:רכבת השלום  מישור החוף הדרומי      IL   \n",
       "26382                        תחנה:רכבת השלום             גוש דן      IL   \n",
       "26383                            תחנה:ניידת6               שרון      IL   \n",
       "26384                               תחנה:הדר             גוש דן      IL   \n",
       "26385       תחנה:תחנה ניידת ברכבת 1(וולפסון)        חיפה וקריות      IL   \n",
       "26386       תחנה:תחנה ניידת ברכבת 1(וולפסון)  מישור החוף הדרומי      IL   \n",
       "26387                            תחנה:כ.מהרל             גוש דן      IL   \n",
       "26388                               תחנה:לוט  מישור החוף הדרומי      IL   \n",
       "26389       תחנה:תחנה ניידת ברכבת 1(וולפסון)  מישור החוף הדרומי      IL   \n",
       "26390                            תחנה:נ.שאנן        חיפה וקריות      IL   \n",
       "26391                           תחנה:גן דרום             גוש דן      IL   \n",
       "26392                               תחנה:הדר  מישור החוף הדרומי      IL   \n",
       "26393                             תחנה:רוממה             גוש דן      IL   \n",
       "26394  Pratu Chai, Phra Nakhon Si Ayutthayal          Ayutthaya      TH   \n",
       "26395                             La Florida              Talca      CL   \n",
       "26396                                CZ0THAR    Moravskoslezský      CZ   \n",
       "\n",
       "        latitude   longitude  \n",
       "0     -22.085519  -70.188683  \n",
       "1     -22.342264  -68.650897  \n",
       "2     -32.776573  -70.938144  \n",
       "3     -36.735998  -73.118693  \n",
       "4     -32.797715  -70.898037  \n",
       "5     -37.031702  -73.138689  \n",
       "6     -32.779208  -70.959114  \n",
       "7     -36.996431  -73.115805  \n",
       "8     -32.823956  -71.006441  \n",
       "9      59.325519   18.003961  \n",
       "10     59.325519   18.003961  \n",
       "11     59.443539   17.922361  \n",
       "12     59.237058   17.838332  \n",
       "13     59.345161   18.054282  \n",
       "14    -22.462145  -68.928062  \n",
       "15     60.671552   17.146915  \n",
       "16     59.317132   18.048787  \n",
       "17     59.314624   18.075856  \n",
       "18     59.336356   18.070626  \n",
       "19     59.198124   17.621087  \n",
       "20     59.859530   17.642484  \n",
       "21    -22.460271  -68.937707  \n",
       "22    -22.442839  -68.932546  \n",
       "23     40.529350   28.784590  \n",
       "24     40.195720   29.045880  \n",
       "25     40.984470   29.268810  \n",
       "26     41.318350   27.980180  \n",
       "27     40.489720   27.978610  \n",
       "28     40.185650   29.080490  \n",
       "29     40.223370   28.871540  \n",
       "...          ...         ...  \n",
       "26367  32.644080   35.351740  \n",
       "26368  32.093380   34.790130  \n",
       "26369  31.987899   34.757384  \n",
       "26370  31.686100   34.636180  \n",
       "26371  31.987899   34.757384  \n",
       "26372  32.100139   34.839027  \n",
       "26373  32.476990   35.086000  \n",
       "26374  31.819420   34.693460  \n",
       "26375  31.818470   34.669110  \n",
       "26376  32.632440   35.065650  \n",
       "26377  31.987899   34.757384  \n",
       "26378  32.091350   34.825990  \n",
       "26379  32.408560   34.918240  \n",
       "26380  31.987899   34.757384  \n",
       "26381  31.782860   34.706200  \n",
       "26382  32.131722   34.831939  \n",
       "26383  32.441110   34.960670  \n",
       "26384  32.119000   34.802500  \n",
       "26385  32.851820   35.078730  \n",
       "26386  31.606330   34.760700  \n",
       "26387  31.987899   34.757384  \n",
       "26388  31.818470   34.669110  \n",
       "26389  31.684660   34.881790  \n",
       "26390  32.721800   35.129400  \n",
       "26391  32.107910   34.789500  \n",
       "26392  31.826520   34.684280  \n",
       "26393  31.987899   34.757384  \n",
       "26394  14.349367  100.568535  \n",
       "26395 -35.435142  -71.678261  \n",
       "26396  49.791005   18.406839  \n",
       "\n",
       "[26397 rows x 5 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = select_from_table(\"open_aq_locations\")\n",
    "column_order = [\"location\", \"city\", \"country\", \"latitude\", \"longitude\"]\n",
    "all_open_aq_locations = pd.DataFrame(res[\"rows\"])[column_order]\n",
    "\n",
    "print(\"\\nNumber of duplicates in the table:\", all_open_aq_locations.duplicated().sum())\n",
    "\n",
    "print(\"\\nA list of all locations ever reporting to the OpenAQ network:\")\n",
    "all_open_aq_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7810</th>\n",
       "      <td>nan</td>\n",
       "      <td>Miami-Fort Lauderdale-Miami Beach</td>\n",
       "      <td>US</td>\n",
       "      <td>26.593808</td>\n",
       "      <td>-80.058917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7902</th>\n",
       "      <td>nan</td>\n",
       "      <td>Miami-Fort Lauderdale-Miami Beach</td>\n",
       "      <td>US</td>\n",
       "      <td>26.593808</td>\n",
       "      <td>-80.058917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7905</th>\n",
       "      <td>nan</td>\n",
       "      <td>Miami-Fort Lauderdale-Miami Beach</td>\n",
       "      <td>US</td>\n",
       "      <td>26.593808</td>\n",
       "      <td>-80.058917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7911</th>\n",
       "      <td>nan</td>\n",
       "      <td>Miami-Fort Lauderdale-Miami Beach</td>\n",
       "      <td>US</td>\n",
       "      <td>26.593808</td>\n",
       "      <td>-80.058917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7929</th>\n",
       "      <td>nan</td>\n",
       "      <td>Miami-Fort Lauderdale-Miami Beach</td>\n",
       "      <td>US</td>\n",
       "      <td>26.593808</td>\n",
       "      <td>-80.058917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7931</th>\n",
       "      <td>nan</td>\n",
       "      <td>Miami-Fort Lauderdale-Miami Beach</td>\n",
       "      <td>US</td>\n",
       "      <td>26.593808</td>\n",
       "      <td>-80.058917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7934</th>\n",
       "      <td>nan</td>\n",
       "      <td>Miami-Fort Lauderdale-Miami Beach</td>\n",
       "      <td>US</td>\n",
       "      <td>26.593808</td>\n",
       "      <td>-80.058917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7942</th>\n",
       "      <td>nan</td>\n",
       "      <td>Miami-Fort Lauderdale-Miami Beach</td>\n",
       "      <td>US</td>\n",
       "      <td>26.593808</td>\n",
       "      <td>-80.058917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7945</th>\n",
       "      <td>nan</td>\n",
       "      <td>Miami-Fort Lauderdale-Miami Beach</td>\n",
       "      <td>US</td>\n",
       "      <td>26.593808</td>\n",
       "      <td>-80.058917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7947</th>\n",
       "      <td>nan</td>\n",
       "      <td>Miami-Fort Lauderdale-Miami Beach</td>\n",
       "      <td>US</td>\n",
       "      <td>26.593808</td>\n",
       "      <td>-80.058917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7949</th>\n",
       "      <td>nan</td>\n",
       "      <td>Miami-Fort Lauderdale-Miami Beach</td>\n",
       "      <td>US</td>\n",
       "      <td>26.593808</td>\n",
       "      <td>-80.058917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7950</th>\n",
       "      <td>nan</td>\n",
       "      <td>Miami-Fort Lauderdale-Miami Beach</td>\n",
       "      <td>US</td>\n",
       "      <td>26.593808</td>\n",
       "      <td>-80.058917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7961</th>\n",
       "      <td>nan</td>\n",
       "      <td>Miami-Fort Lauderdale-Miami Beach</td>\n",
       "      <td>US</td>\n",
       "      <td>26.593808</td>\n",
       "      <td>-80.058917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7970</th>\n",
       "      <td>nan</td>\n",
       "      <td>Miami-Fort Lauderdale-Miami Beach</td>\n",
       "      <td>US</td>\n",
       "      <td>26.593808</td>\n",
       "      <td>-80.058917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7986</th>\n",
       "      <td>nan</td>\n",
       "      <td>Miami-Fort Lauderdale-Miami Beach</td>\n",
       "      <td>US</td>\n",
       "      <td>26.593808</td>\n",
       "      <td>-80.058917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7994</th>\n",
       "      <td>nan</td>\n",
       "      <td>Miami-Fort Lauderdale-Miami Beach</td>\n",
       "      <td>US</td>\n",
       "      <td>26.593808</td>\n",
       "      <td>-80.058917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>nan</td>\n",
       "      <td>Miami-Fort Lauderdale-Miami Beach</td>\n",
       "      <td>US</td>\n",
       "      <td>26.593808</td>\n",
       "      <td>-80.058917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>nan</td>\n",
       "      <td>Miami-Fort Lauderdale-Miami Beach</td>\n",
       "      <td>US</td>\n",
       "      <td>26.593808</td>\n",
       "      <td>-80.058917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>nan</td>\n",
       "      <td>Miami-Fort Lauderdale-Miami Beach</td>\n",
       "      <td>US</td>\n",
       "      <td>26.593808</td>\n",
       "      <td>-80.058917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8001</th>\n",
       "      <td>nan</td>\n",
       "      <td>Miami-Fort Lauderdale-Miami Beach</td>\n",
       "      <td>US</td>\n",
       "      <td>26.593808</td>\n",
       "      <td>-80.058917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8011</th>\n",
       "      <td>nan</td>\n",
       "      <td>Miami-Fort Lauderdale-Miami Beach</td>\n",
       "      <td>US</td>\n",
       "      <td>26.593808</td>\n",
       "      <td>-80.058917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8034</th>\n",
       "      <td>nan</td>\n",
       "      <td>Miami-Fort Lauderdale-Miami Beach</td>\n",
       "      <td>US</td>\n",
       "      <td>26.593808</td>\n",
       "      <td>-80.058917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8046</th>\n",
       "      <td>nan</td>\n",
       "      <td>Miami-Fort Lauderdale-Miami Beach</td>\n",
       "      <td>US</td>\n",
       "      <td>26.593808</td>\n",
       "      <td>-80.058917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8101</th>\n",
       "      <td>nan</td>\n",
       "      <td>Miami-Fort Lauderdale-Miami Beach</td>\n",
       "      <td>US</td>\n",
       "      <td>26.593808</td>\n",
       "      <td>-80.058917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8102</th>\n",
       "      <td>nan</td>\n",
       "      <td>Miami-Fort Lauderdale-Miami Beach</td>\n",
       "      <td>US</td>\n",
       "      <td>26.593808</td>\n",
       "      <td>-80.058917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8104</th>\n",
       "      <td>nan</td>\n",
       "      <td>Miami-Fort Lauderdale-Miami Beach</td>\n",
       "      <td>US</td>\n",
       "      <td>26.593808</td>\n",
       "      <td>-80.058917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8131</th>\n",
       "      <td>nan</td>\n",
       "      <td>Miami-Fort Lauderdale-Miami Beach</td>\n",
       "      <td>US</td>\n",
       "      <td>26.593808</td>\n",
       "      <td>-80.058917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8149</th>\n",
       "      <td>nan</td>\n",
       "      <td>Miami-Fort Lauderdale-Miami Beach</td>\n",
       "      <td>US</td>\n",
       "      <td>26.593808</td>\n",
       "      <td>-80.058917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8152</th>\n",
       "      <td>nan</td>\n",
       "      <td>Miami-Fort Lauderdale-Miami Beach</td>\n",
       "      <td>US</td>\n",
       "      <td>26.593808</td>\n",
       "      <td>-80.058917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8155</th>\n",
       "      <td>nan</td>\n",
       "      <td>Miami-Fort Lauderdale-Miami Beach</td>\n",
       "      <td>US</td>\n",
       "      <td>26.593808</td>\n",
       "      <td>-80.058917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11858</th>\n",
       "      <td>nan</td>\n",
       "      <td>PINELLAS</td>\n",
       "      <td>US</td>\n",
       "      <td>27.834409</td>\n",
       "      <td>-82.665251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11860</th>\n",
       "      <td>nan</td>\n",
       "      <td>PINELLAS</td>\n",
       "      <td>US</td>\n",
       "      <td>27.834409</td>\n",
       "      <td>-82.665251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11861</th>\n",
       "      <td>nan</td>\n",
       "      <td>PINELLAS</td>\n",
       "      <td>US</td>\n",
       "      <td>27.834409</td>\n",
       "      <td>-82.665251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11864</th>\n",
       "      <td>nan</td>\n",
       "      <td>PINELLAS</td>\n",
       "      <td>US</td>\n",
       "      <td>27.834409</td>\n",
       "      <td>-82.665251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11865</th>\n",
       "      <td>nan</td>\n",
       "      <td>PINELLAS</td>\n",
       "      <td>US</td>\n",
       "      <td>27.834409</td>\n",
       "      <td>-82.665251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11866</th>\n",
       "      <td>nan</td>\n",
       "      <td>PINELLAS</td>\n",
       "      <td>US</td>\n",
       "      <td>27.834409</td>\n",
       "      <td>-82.665251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11869</th>\n",
       "      <td>nan</td>\n",
       "      <td>PINELLAS</td>\n",
       "      <td>US</td>\n",
       "      <td>27.834409</td>\n",
       "      <td>-82.665251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11870</th>\n",
       "      <td>nan</td>\n",
       "      <td>PINELLAS</td>\n",
       "      <td>US</td>\n",
       "      <td>27.834409</td>\n",
       "      <td>-82.665251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11873</th>\n",
       "      <td>nan</td>\n",
       "      <td>PINELLAS</td>\n",
       "      <td>US</td>\n",
       "      <td>27.834409</td>\n",
       "      <td>-82.665251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11874</th>\n",
       "      <td>nan</td>\n",
       "      <td>PINELLAS</td>\n",
       "      <td>US</td>\n",
       "      <td>27.834409</td>\n",
       "      <td>-82.665251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11875</th>\n",
       "      <td>nan</td>\n",
       "      <td>PINELLAS</td>\n",
       "      <td>US</td>\n",
       "      <td>27.834409</td>\n",
       "      <td>-82.665251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11876</th>\n",
       "      <td>nan</td>\n",
       "      <td>PINELLAS</td>\n",
       "      <td>US</td>\n",
       "      <td>27.834409</td>\n",
       "      <td>-82.665251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11878</th>\n",
       "      <td>nan</td>\n",
       "      <td>PINELLAS</td>\n",
       "      <td>US</td>\n",
       "      <td>27.834409</td>\n",
       "      <td>-82.665251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11881</th>\n",
       "      <td>nan</td>\n",
       "      <td>PINELLAS</td>\n",
       "      <td>US</td>\n",
       "      <td>27.834409</td>\n",
       "      <td>-82.665251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11882</th>\n",
       "      <td>nan</td>\n",
       "      <td>PINELLAS</td>\n",
       "      <td>US</td>\n",
       "      <td>27.834409</td>\n",
       "      <td>-82.665251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11883</th>\n",
       "      <td>nan</td>\n",
       "      <td>PINELLAS</td>\n",
       "      <td>US</td>\n",
       "      <td>27.834409</td>\n",
       "      <td>-82.665251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11885</th>\n",
       "      <td>nan</td>\n",
       "      <td>PINELLAS</td>\n",
       "      <td>US</td>\n",
       "      <td>27.834409</td>\n",
       "      <td>-82.665251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11889</th>\n",
       "      <td>nan</td>\n",
       "      <td>PINELLAS</td>\n",
       "      <td>US</td>\n",
       "      <td>27.834409</td>\n",
       "      <td>-82.665251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11890</th>\n",
       "      <td>nan</td>\n",
       "      <td>PINELLAS</td>\n",
       "      <td>US</td>\n",
       "      <td>27.834409</td>\n",
       "      <td>-82.665251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11891</th>\n",
       "      <td>nan</td>\n",
       "      <td>PINELLAS</td>\n",
       "      <td>US</td>\n",
       "      <td>27.834409</td>\n",
       "      <td>-82.665251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11892</th>\n",
       "      <td>nan</td>\n",
       "      <td>PINELLAS</td>\n",
       "      <td>US</td>\n",
       "      <td>27.834409</td>\n",
       "      <td>-82.665251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11894</th>\n",
       "      <td>nan</td>\n",
       "      <td>PINELLAS</td>\n",
       "      <td>US</td>\n",
       "      <td>27.834409</td>\n",
       "      <td>-82.665251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11897</th>\n",
       "      <td>nan</td>\n",
       "      <td>PINELLAS</td>\n",
       "      <td>US</td>\n",
       "      <td>27.834409</td>\n",
       "      <td>-82.665251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11899</th>\n",
       "      <td>nan</td>\n",
       "      <td>PINELLAS</td>\n",
       "      <td>US</td>\n",
       "      <td>27.834409</td>\n",
       "      <td>-82.665251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11900</th>\n",
       "      <td>nan</td>\n",
       "      <td>PINELLAS</td>\n",
       "      <td>US</td>\n",
       "      <td>27.834409</td>\n",
       "      <td>-82.665251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11901</th>\n",
       "      <td>nan</td>\n",
       "      <td>PINELLAS</td>\n",
       "      <td>US</td>\n",
       "      <td>27.834409</td>\n",
       "      <td>-82.665251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11902</th>\n",
       "      <td>nan</td>\n",
       "      <td>PINELLAS</td>\n",
       "      <td>US</td>\n",
       "      <td>27.834409</td>\n",
       "      <td>-82.665251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11904</th>\n",
       "      <td>nan</td>\n",
       "      <td>PINELLAS</td>\n",
       "      <td>US</td>\n",
       "      <td>27.834409</td>\n",
       "      <td>-82.665251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25154</th>\n",
       "      <td>nan</td>\n",
       "      <td>JERSEY</td>\n",
       "      <td>US</td>\n",
       "      <td>39.110539</td>\n",
       "      <td>-90.344374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25181</th>\n",
       "      <td>nan</td>\n",
       "      <td>JERSEY</td>\n",
       "      <td>US</td>\n",
       "      <td>39.110539</td>\n",
       "      <td>-90.344374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>657 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      location                               city country   latitude  \\\n",
       "7810       nan  Miami-Fort Lauderdale-Miami Beach      US  26.593808   \n",
       "7902       nan  Miami-Fort Lauderdale-Miami Beach      US  26.593808   \n",
       "7905       nan  Miami-Fort Lauderdale-Miami Beach      US  26.593808   \n",
       "7911       nan  Miami-Fort Lauderdale-Miami Beach      US  26.593808   \n",
       "7929       nan  Miami-Fort Lauderdale-Miami Beach      US  26.593808   \n",
       "7931       nan  Miami-Fort Lauderdale-Miami Beach      US  26.593808   \n",
       "7934       nan  Miami-Fort Lauderdale-Miami Beach      US  26.593808   \n",
       "7942       nan  Miami-Fort Lauderdale-Miami Beach      US  26.593808   \n",
       "7945       nan  Miami-Fort Lauderdale-Miami Beach      US  26.593808   \n",
       "7947       nan  Miami-Fort Lauderdale-Miami Beach      US  26.593808   \n",
       "7949       nan  Miami-Fort Lauderdale-Miami Beach      US  26.593808   \n",
       "7950       nan  Miami-Fort Lauderdale-Miami Beach      US  26.593808   \n",
       "7961       nan  Miami-Fort Lauderdale-Miami Beach      US  26.593808   \n",
       "7970       nan  Miami-Fort Lauderdale-Miami Beach      US  26.593808   \n",
       "7986       nan  Miami-Fort Lauderdale-Miami Beach      US  26.593808   \n",
       "7994       nan  Miami-Fort Lauderdale-Miami Beach      US  26.593808   \n",
       "7996       nan  Miami-Fort Lauderdale-Miami Beach      US  26.593808   \n",
       "7997       nan  Miami-Fort Lauderdale-Miami Beach      US  26.593808   \n",
       "7998       nan  Miami-Fort Lauderdale-Miami Beach      US  26.593808   \n",
       "8001       nan  Miami-Fort Lauderdale-Miami Beach      US  26.593808   \n",
       "8011       nan  Miami-Fort Lauderdale-Miami Beach      US  26.593808   \n",
       "8034       nan  Miami-Fort Lauderdale-Miami Beach      US  26.593808   \n",
       "8046       nan  Miami-Fort Lauderdale-Miami Beach      US  26.593808   \n",
       "8101       nan  Miami-Fort Lauderdale-Miami Beach      US  26.593808   \n",
       "8102       nan  Miami-Fort Lauderdale-Miami Beach      US  26.593808   \n",
       "8104       nan  Miami-Fort Lauderdale-Miami Beach      US  26.593808   \n",
       "8131       nan  Miami-Fort Lauderdale-Miami Beach      US  26.593808   \n",
       "8149       nan  Miami-Fort Lauderdale-Miami Beach      US  26.593808   \n",
       "8152       nan  Miami-Fort Lauderdale-Miami Beach      US  26.593808   \n",
       "8155       nan  Miami-Fort Lauderdale-Miami Beach      US  26.593808   \n",
       "...        ...                                ...     ...        ...   \n",
       "11858      nan                           PINELLAS      US  27.834409   \n",
       "11860      nan                           PINELLAS      US  27.834409   \n",
       "11861      nan                           PINELLAS      US  27.834409   \n",
       "11864      nan                           PINELLAS      US  27.834409   \n",
       "11865      nan                           PINELLAS      US  27.834409   \n",
       "11866      nan                           PINELLAS      US  27.834409   \n",
       "11869      nan                           PINELLAS      US  27.834409   \n",
       "11870      nan                           PINELLAS      US  27.834409   \n",
       "11873      nan                           PINELLAS      US  27.834409   \n",
       "11874      nan                           PINELLAS      US  27.834409   \n",
       "11875      nan                           PINELLAS      US  27.834409   \n",
       "11876      nan                           PINELLAS      US  27.834409   \n",
       "11878      nan                           PINELLAS      US  27.834409   \n",
       "11881      nan                           PINELLAS      US  27.834409   \n",
       "11882      nan                           PINELLAS      US  27.834409   \n",
       "11883      nan                           PINELLAS      US  27.834409   \n",
       "11885      nan                           PINELLAS      US  27.834409   \n",
       "11889      nan                           PINELLAS      US  27.834409   \n",
       "11890      nan                           PINELLAS      US  27.834409   \n",
       "11891      nan                           PINELLAS      US  27.834409   \n",
       "11892      nan                           PINELLAS      US  27.834409   \n",
       "11894      nan                           PINELLAS      US  27.834409   \n",
       "11897      nan                           PINELLAS      US  27.834409   \n",
       "11899      nan                           PINELLAS      US  27.834409   \n",
       "11900      nan                           PINELLAS      US  27.834409   \n",
       "11901      nan                           PINELLAS      US  27.834409   \n",
       "11902      nan                           PINELLAS      US  27.834409   \n",
       "11904      nan                           PINELLAS      US  27.834409   \n",
       "25154      nan                             JERSEY      US  39.110539   \n",
       "25181      nan                             JERSEY      US  39.110539   \n",
       "\n",
       "       longitude  \n",
       "7810  -80.058917  \n",
       "7902  -80.058917  \n",
       "7905  -80.058917  \n",
       "7911  -80.058917  \n",
       "7929  -80.058917  \n",
       "7931  -80.058917  \n",
       "7934  -80.058917  \n",
       "7942  -80.058917  \n",
       "7945  -80.058917  \n",
       "7947  -80.058917  \n",
       "7949  -80.058917  \n",
       "7950  -80.058917  \n",
       "7961  -80.058917  \n",
       "7970  -80.058917  \n",
       "7986  -80.058917  \n",
       "7994  -80.058917  \n",
       "7996  -80.058917  \n",
       "7997  -80.058917  \n",
       "7998  -80.058917  \n",
       "8001  -80.058917  \n",
       "8011  -80.058917  \n",
       "8034  -80.058917  \n",
       "8046  -80.058917  \n",
       "8101  -80.058917  \n",
       "8102  -80.058917  \n",
       "8104  -80.058917  \n",
       "8131  -80.058917  \n",
       "8149  -80.058917  \n",
       "8152  -80.058917  \n",
       "8155  -80.058917  \n",
       "...          ...  \n",
       "11858 -82.665251  \n",
       "11860 -82.665251  \n",
       "11861 -82.665251  \n",
       "11864 -82.665251  \n",
       "11865 -82.665251  \n",
       "11866 -82.665251  \n",
       "11869 -82.665251  \n",
       "11870 -82.665251  \n",
       "11873 -82.665251  \n",
       "11874 -82.665251  \n",
       "11875 -82.665251  \n",
       "11876 -82.665251  \n",
       "11878 -82.665251  \n",
       "11881 -82.665251  \n",
       "11882 -82.665251  \n",
       "11883 -82.665251  \n",
       "11885 -82.665251  \n",
       "11889 -82.665251  \n",
       "11890 -82.665251  \n",
       "11891 -82.665251  \n",
       "11892 -82.665251  \n",
       "11894 -82.665251  \n",
       "11897 -82.665251  \n",
       "11899 -82.665251  \n",
       "11900 -82.665251  \n",
       "11901 -82.665251  \n",
       "11902 -82.665251  \n",
       "11904 -82.665251  \n",
       "25154 -90.344374  \n",
       "25181 -90.344374  \n",
       "\n",
       "[657 rows x 5 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duped_locations = all_open_aq_locations[all_open_aq_locations.duplicated()]\n",
    "duped_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "duped_locations = duped_locations.drop_duplicates(keep=\"first\")\n",
    "print(duped_locations)\n",
    "\n",
    "shared = pd.merge(duped_locations, duped_locations, on=list(duped_locations.columns), how=\"inner\")\n",
    "shared[\"key\"] = \"x\"\n",
    "print(shared)\n",
    "temp_df = pd.merge(duped_locations, shared, on=list(duped_locations.columns), how=\"left\")\n",
    "new_obs = temp_df[temp_df[\"key\"].isnull()].drop(\"key\", axis=1)\n",
    "new_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read open_aq_history table from Carto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = select_from_table(\"open_aq_history\", \n",
    "                        datetime_column=\"lastUpdated\", \n",
    "                        datetime_cutoff=\"2 days\", \n",
    "                        want_data_since_cutoff=True)\n",
    "\n",
    "#column_order = [\"location\", \"city\", \"country\", \"latitude\", \"longitude\"]\n",
    "all_open_aq_history = pd.DataFrame(res[\"rows\"]) #[column_order]\n",
    "\n",
    "print(\"\\nNumber of duplicates in the table:\", all_open_aq_history.duplicated().sum())\n",
    "\n",
    "print(\"\\nA list of all locations ever reporting to the OpenAQ network:\")\n",
    "all_open_aq_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenAQ API Documentation: https://docs.openaq.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cities\n",
    "url = \"https://api.openaq.org/v1/cities\"\n",
    "# Countries\n",
    "url = \"https://api.openaq.org/v1/countries\"\n",
    "# Fetches\n",
    "url = \"https://api.openaq.org/v1/fetches\"\n",
    "# Latest\n",
    "url = \"https://api.openaq.org/v1/latest\"\n",
    "# Locations\n",
    "url = \"https://api.openaq.org/v1/locations\"\n",
    "# Measurements\n",
    "url = \"https://api.openaq.org/v1/measurements\"\n",
    "# Parameters\n",
    "url = \"https://api.openaq.org/v1/parameters\"\n",
    "# Sources\n",
    "url = \"https://api.openaq.org/v1/sources\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read from the OpenAQ API for most recent updates - check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Pull in newest observations from OpenAQ API\n",
    "url = \"https://api.openaq.org/v1/latest\"\n",
    "# There is a limit from OpenAQ of 10,000 rows per API call\n",
    "params = {\n",
    "    \"limit\":10000\n",
    "}\n",
    "\n",
    "res = req.get(url, params=params)\n",
    "data = res.json()[\"results\"]\n",
    "\n",
    "latest_data = pd.io.json.json_normalize(data, ['measurements'],[['coordinates', 'latitude'], ['coordinates', 'longitude'],'location', 'city', 'country'],  \n",
    "                                          errors='ignore')\n",
    "\n",
    "## Check existing record for possible duplicates from past readings\n",
    "\n",
    "## TO DO: Format this for the UTC format the Carto table will use\n",
    "look_back = \"1 day\"\n",
    "table_name = \"open_aq_history\"\n",
    "select_all_in_time_range_sql = \"\"\"\n",
    "SELECT * FROM {table_name} WHERE lastUpdated < {check_length}\n",
    "\"\"\".format(table_name=table_name, check_length=look_back)\n",
    "\n",
    "res = sql_api(select_all_in_time_range_sql)\n",
    "data = pd.DataFrame(res[\"rows\"])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## TO DO: kwargs and update_table_without_duplicates(**kwargs)\n",
    "# Goal: update the long-running history of all observations\n",
    "\n",
    "# Update list of observed locations in case new ones were introduced since last update\n",
    "\n",
    "latest_locations = latest_data[[\"location\", \"city\", \"country\", \"coordinates.latitude\", \"coordinates.longitude\"]]\n",
    "\n",
    "kwargs = {\n",
    "            \"data_df\":latest_locations,\n",
    "            \"target_table_name\":\"open_aq_locations\",\n",
    "            \"cols_and_types\":cols_and_types_locations,\n",
    "            \"cols_with_apostrophes\":[\"location\", \"city\",\"country\"],\n",
    "            \"float_cols_to_roundfloat_cols\":[\"latitude\", \"longitude\"],\n",
    "            \"precision\":6\n",
    "        }\n",
    "\n",
    "update_table_without_duplicates(**kwargs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SQL statement that will join the location Unique ID to the newly observed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## TO DO\n",
    "\n",
    "## Write this! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "look_back_length = None\n",
    "#look_back_length = [\"a\", \"b\"]\n",
    "if look_back:\n",
    "    print('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7271, 5)"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = list(cols_and_types_locations.keys())\n",
    "target_table_name = \"open_aq_locations\"\n",
    "select_all_sql = \"\"\"\n",
    "SELECT * FROM {table_name}\n",
    "\"\"\".format(table_name=target_table_name)\n",
    "res = sql_api(select_all_sql)\n",
    "target_table = pd.DataFrame(res[\"rows\"], columns=column_names)\n",
    "target_table = fix_precision_of_floats(target_table, [\"latitude\", \"longitude\"], 6)\n",
    "target_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7271, 5)"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = dec8\n",
    "obs = data_df[column_names]\n",
    "obs = obs.drop_duplicates(keep=\"first\")\n",
    "obs = keep_geolocated(obs)\n",
    "obs = fix_precision_of_floats(obs, [\"latitude\", \"longitude\"], 6)\n",
    "obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Escuela E-10</td>\n",
       "      <td>Tocopilla</td>\n",
       "      <td>CL</td>\n",
       "      <td>-22.085519</td>\n",
       "      <td>-70.188683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Chiu Chiu</td>\n",
       "      <td>Calama</td>\n",
       "      <td>CL</td>\n",
       "      <td>-22.342264</td>\n",
       "      <td>-68.650897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Santa Margarita</td>\n",
       "      <td>Catemu</td>\n",
       "      <td>CL</td>\n",
       "      <td>-32.776573</td>\n",
       "      <td>-70.938144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Nueva Libertad</td>\n",
       "      <td>Talcahuano</td>\n",
       "      <td>CL</td>\n",
       "      <td>-36.735998</td>\n",
       "      <td>-73.118693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Lo Campo</td>\n",
       "      <td>Panquehue</td>\n",
       "      <td>CL</td>\n",
       "      <td>-32.797715</td>\n",
       "      <td>-70.898037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Coronel Sur</td>\n",
       "      <td>Coronel</td>\n",
       "      <td>CL</td>\n",
       "      <td>-37.031702</td>\n",
       "      <td>-73.138689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Catemu</td>\n",
       "      <td>Catemu</td>\n",
       "      <td>CL</td>\n",
       "      <td>-32.779208</td>\n",
       "      <td>-70.959114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Calabozo</td>\n",
       "      <td>Coronel</td>\n",
       "      <td>CL</td>\n",
       "      <td>-36.996431</td>\n",
       "      <td>-73.115805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Romeral</td>\n",
       "      <td>Hijuelas</td>\n",
       "      <td>CL</td>\n",
       "      <td>-32.823956</td>\n",
       "      <td>-71.006441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Lilla Essingen (E4/E20)</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>SE</td>\n",
       "      <td>59.325519</td>\n",
       "      <td>18.003961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   location        city country   latitude  longitude\n",
       "0              Escuela E-10   Tocopilla      CL -22.085519 -70.188683\n",
       "7                 Chiu Chiu      Calama      CL -22.342264 -68.650897\n",
       "8           Santa Margarita      Catemu      CL -32.776573 -70.938144\n",
       "9            Nueva Libertad  Talcahuano      CL -36.735998 -73.118693\n",
       "10                 Lo Campo   Panquehue      CL -32.797715 -70.898037\n",
       "11              Coronel Sur     Coronel      CL -37.031702 -73.138689\n",
       "12                   Catemu      Catemu      CL -32.779208 -70.959114\n",
       "13                 Calabozo     Coronel      CL -36.996431 -73.115805\n",
       "14                  Romeral    Hijuelas      CL -32.823956 -71.006441\n",
       "15  Lilla Essingen (E4/E20)   Stockholm      SE  59.325519  18.003961"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "location     Escuela E-10\n",
       "city            Tocopilla\n",
       "country                CL\n",
       "latitude         -22.0855\n",
       "longitude        -70.1887\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_table.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "location     Escuela E-10\n",
       "city            Tocopilla\n",
       "country                CL\n",
       "latitude         -22.0855\n",
       "longitude        -70.1887\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_table.loc[0].equals(obs.loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7250, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Escuela E-10</td>\n",
       "      <td>Tocopilla</td>\n",
       "      <td>CL</td>\n",
       "      <td>-22.085519</td>\n",
       "      <td>-70.188683</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chiu Chiu</td>\n",
       "      <td>Calama</td>\n",
       "      <td>CL</td>\n",
       "      <td>-22.342264</td>\n",
       "      <td>-68.650897</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Santa Margarita</td>\n",
       "      <td>Catemu</td>\n",
       "      <td>CL</td>\n",
       "      <td>-32.776573</td>\n",
       "      <td>-70.938144</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nueva Libertad</td>\n",
       "      <td>Talcahuano</td>\n",
       "      <td>CL</td>\n",
       "      <td>-36.735998</td>\n",
       "      <td>-73.118693</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lo Campo</td>\n",
       "      <td>Panquehue</td>\n",
       "      <td>CL</td>\n",
       "      <td>-32.797715</td>\n",
       "      <td>-70.898037</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Coronel Sur</td>\n",
       "      <td>Coronel</td>\n",
       "      <td>CL</td>\n",
       "      <td>-37.031702</td>\n",
       "      <td>-73.138689</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Catemu</td>\n",
       "      <td>Catemu</td>\n",
       "      <td>CL</td>\n",
       "      <td>-32.779208</td>\n",
       "      <td>-70.959114</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Calabozo</td>\n",
       "      <td>Coronel</td>\n",
       "      <td>CL</td>\n",
       "      <td>-36.996431</td>\n",
       "      <td>-73.115805</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Romeral</td>\n",
       "      <td>Hijuelas</td>\n",
       "      <td>CL</td>\n",
       "      <td>-32.823956</td>\n",
       "      <td>-71.006441</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lilla Essingen (E4/E20)</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>SE</td>\n",
       "      <td>59.325519</td>\n",
       "      <td>18.003961</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  location        city country   latitude  longitude key\n",
       "0             Escuela E-10   Tocopilla      CL -22.085519 -70.188683   x\n",
       "1                Chiu Chiu      Calama      CL -22.342264 -68.650897   x\n",
       "2          Santa Margarita      Catemu      CL -32.776573 -70.938144   x\n",
       "3           Nueva Libertad  Talcahuano      CL -36.735998 -73.118693   x\n",
       "4                 Lo Campo   Panquehue      CL -32.797715 -70.898037   x\n",
       "5              Coronel Sur     Coronel      CL -37.031702 -73.138689   x\n",
       "6                   Catemu      Catemu      CL -32.779208 -70.959114   x\n",
       "7                 Calabozo     Coronel      CL -36.996431 -73.115805   x\n",
       "8                  Romeral    Hijuelas      CL -32.823956 -71.006441   x\n",
       "9  Lilla Essingen (E4/E20)   Stockholm      SE  59.325519  18.003961   x"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shared = target_table.merge(obs, on=column_names, how=\"inner\")\n",
    "shared[\"key\"] = \"x\"\n",
    "print(shared.shape)\n",
    "shared.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>MT00004</td>\n",
       "      <td>Zejtun (Citta' Beland)</td>\n",
       "      <td>MT</td>\n",
       "      <td>35.852291</td>\n",
       "      <td>14.538986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>Parque O'Higgins</td>\n",
       "      <td>Santiago</td>\n",
       "      <td>CL</td>\n",
       "      <td>-33.464142</td>\n",
       "      <td>-70.660797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>Bristol St Paul's</td>\n",
       "      <td>Bristol</td>\n",
       "      <td>GB</td>\n",
       "      <td>51.462839</td>\n",
       "      <td>-2.584482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>Belfast Stockman's Lane</td>\n",
       "      <td>Belfast</td>\n",
       "      <td>GB</td>\n",
       "      <td>54.572586</td>\n",
       "      <td>-5.974944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>Derby St Alkmund's Way</td>\n",
       "      <td>Derby</td>\n",
       "      <td>GB</td>\n",
       "      <td>52.922983</td>\n",
       "      <td>-1.469507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067</th>\n",
       "      <td>Fisherman's Landing</td>\n",
       "      <td>Gladstone</td>\n",
       "      <td>AU</td>\n",
       "      <td>-23.793700</td>\n",
       "      <td>151.160100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>St. John's</td>\n",
       "      <td>NEWFOUNDLAND</td>\n",
       "      <td>CA</td>\n",
       "      <td>47.652800</td>\n",
       "      <td>-52.816700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1381</th>\n",
       "      <td>Lancaster</td>\n",
       "      <td>Coeur d'Alene</td>\n",
       "      <td>US</td>\n",
       "      <td>47.788900</td>\n",
       "      <td>-116.804400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1561</th>\n",
       "      <td>Children's Park Site</td>\n",
       "      <td>Tucson</td>\n",
       "      <td>US</td>\n",
       "      <td>32.295300</td>\n",
       "      <td>-110.982200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2788</th>\n",
       "      <td>FR04158</td>\n",
       "      <td>Val-d'Oise</td>\n",
       "      <td>FR</td>\n",
       "      <td>49.063086</td>\n",
       "      <td>1.866381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2798</th>\n",
       "      <td>FR26002</td>\n",
       "      <td>Côte-d'Or</td>\n",
       "      <td>FR</td>\n",
       "      <td>47.304164</td>\n",
       "      <td>5.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2826</th>\n",
       "      <td>FR04023</td>\n",
       "      <td>Val-d'Oise</td>\n",
       "      <td>FR</td>\n",
       "      <td>49.046389</td>\n",
       "      <td>2.043056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2904</th>\n",
       "      <td>FR04051</td>\n",
       "      <td>Val-d'Oise</td>\n",
       "      <td>FR</td>\n",
       "      <td>48.951389</td>\n",
       "      <td>2.223611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3155</th>\n",
       "      <td>FR04024</td>\n",
       "      <td>Val-d'Oise</td>\n",
       "      <td>FR</td>\n",
       "      <td>48.990831</td>\n",
       "      <td>2.444722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3164</th>\n",
       "      <td>FR26035</td>\n",
       "      <td>Côte-d'Or</td>\n",
       "      <td>FR</td>\n",
       "      <td>47.137225</td>\n",
       "      <td>4.950578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3257</th>\n",
       "      <td>FR26014</td>\n",
       "      <td>Côte-d'Or</td>\n",
       "      <td>FR</td>\n",
       "      <td>47.340278</td>\n",
       "      <td>5.058333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3301</th>\n",
       "      <td>FR26010</td>\n",
       "      <td>Côte-d'Or</td>\n",
       "      <td>FR</td>\n",
       "      <td>47.345553</td>\n",
       "      <td>5.002222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3551</th>\n",
       "      <td>FR04048</td>\n",
       "      <td>Val-d'Oise</td>\n",
       "      <td>FR</td>\n",
       "      <td>49.100278</td>\n",
       "      <td>2.343889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3555</th>\n",
       "      <td>FR26043</td>\n",
       "      <td>Côte-d'Or</td>\n",
       "      <td>FR</td>\n",
       "      <td>47.315472</td>\n",
       "      <td>5.037429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3560</th>\n",
       "      <td>FR26005</td>\n",
       "      <td>Côte-d'Or</td>\n",
       "      <td>FR</td>\n",
       "      <td>47.308056</td>\n",
       "      <td>5.066111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3599</th>\n",
       "      <td>FR19061</td>\n",
       "      <td>Côtes-d'Armor</td>\n",
       "      <td>FR</td>\n",
       "      <td>48.516669</td>\n",
       "      <td>-2.750000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     location                    city country   latitude  \\\n",
       "76                    MT00004  Zejtun (Citta' Beland)      MT  35.852291   \n",
       "549          Parque O'Higgins                Santiago      CL -33.464142   \n",
       "638         Bristol St Paul's                 Bristol      GB  51.462839   \n",
       "689   Belfast Stockman's Lane                 Belfast      GB  54.572586   \n",
       "700    Derby St Alkmund's Way                   Derby      GB  52.922983   \n",
       "1067      Fisherman's Landing               Gladstone      AU -23.793700   \n",
       "1238               St. John's            NEWFOUNDLAND      CA  47.652800   \n",
       "1381                Lancaster           Coeur d'Alene      US  47.788900   \n",
       "1561     Children's Park Site                  Tucson      US  32.295300   \n",
       "2788                  FR04158              Val-d'Oise      FR  49.063086   \n",
       "2798                  FR26002               Côte-d'Or      FR  47.304164   \n",
       "2826                  FR04023              Val-d'Oise      FR  49.046389   \n",
       "2904                  FR04051              Val-d'Oise      FR  48.951389   \n",
       "3155                  FR04024              Val-d'Oise      FR  48.990831   \n",
       "3164                  FR26035               Côte-d'Or      FR  47.137225   \n",
       "3257                  FR26014               Côte-d'Or      FR  47.340278   \n",
       "3301                  FR26010               Côte-d'Or      FR  47.345553   \n",
       "3551                  FR04048              Val-d'Oise      FR  49.100278   \n",
       "3555                  FR26043               Côte-d'Or      FR  47.315472   \n",
       "3560                  FR26005               Côte-d'Or      FR  47.308056   \n",
       "3599                  FR19061           Côtes-d'Armor      FR  48.516669   \n",
       "\n",
       "       longitude  \n",
       "76     14.538986  \n",
       "549   -70.660797  \n",
       "638    -2.584482  \n",
       "689    -5.974944  \n",
       "700    -1.469507  \n",
       "1067  151.160100  \n",
       "1238  -52.816700  \n",
       "1381 -116.804400  \n",
       "1561 -110.982200  \n",
       "2788    1.866381  \n",
       "2798    5.020000  \n",
       "2826    2.043056  \n",
       "2904    2.223611  \n",
       "3155    2.444722  \n",
       "3164    4.950578  \n",
       "3257    5.058333  \n",
       "3301    5.002222  \n",
       "3551    2.343889  \n",
       "3555    5.037429  \n",
       "3560    5.066111  \n",
       "3599   -2.750000  "
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df = pd.merge(obs, shared, on=column_names, how=\"left\")\n",
    "new_obs = temp_df[temp_df[\"key\"].isnull()].drop(\"key\", axis=1)\n",
    "#new_obs = new_obs.reset_index()[column_names]\n",
    "new_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of new observations added to open_aq_locations: 7271\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Completed up until index: 60\n",
      "Completed up until index: 80\n",
      "Completed up until index: 100\n",
      "Completed up until index: 120\n",
      "Completed up until index: 140\n",
      "Completed up until index: 160\n",
      "Completed up until index: 180\n",
      "Completed up until index: 200\n",
      "Completed up until index: 220\n",
      "Completed up until index: 240\n",
      "Completed up until index: 260\n",
      "Completed up until index: 280\n",
      "Completed up until index: 300\n",
      "Completed up until index: 320\n",
      "Completed up until index: 340\n",
      "Completed up until index: 360\n",
      "Completed up until index: 380\n",
      "Completed up until index: 400\n",
      "Completed up until index: 420\n",
      "Completed up until index: 440\n",
      "Completed up until index: 460\n",
      "Completed up until index: 480\n",
      "Completed up until index: 500\n",
      "Completed up until index: 520\n",
      "Completed up until index: 540\n",
      "Completed up until index: 560\n",
      "Completed up until index: 580\n",
      "Completed up until index: 600\n",
      "Completed up until index: 620\n",
      "Completed up until index: 640\n",
      "Completed up until index: 660\n",
      "Completed up until index: 680\n",
      "Completed up until index: 700\n",
      "Completed up until index: 720\n",
      "Completed up until index: 740\n",
      "Completed up until index: 760\n",
      "Completed up until index: 780\n",
      "Completed up until index: 800\n",
      "Completed up until index: 820\n",
      "Completed up until index: 840\n",
      "Completed up until index: 860\n",
      "Completed up until index: 880\n",
      "Completed up until index: 900\n",
      "Completed up until index: 920\n",
      "Completed up until index: 940\n",
      "Completed up until index: 960\n",
      "Completed up until index: 980\n",
      "Completed up until index: 1000\n",
      "Completed up until index: 1020\n",
      "Completed up until index: 1040\n",
      "Completed up until index: 1060\n",
      "Completed up until index: 1080\n",
      "Completed up until index: 1100\n",
      "Completed up until index: 1120\n",
      "Completed up until index: 1140\n",
      "Completed up until index: 1160\n",
      "Completed up until index: 1180\n",
      "Completed up until index: 1200\n",
      "Completed up until index: 1220\n",
      "Completed up until index: 1240\n",
      "Completed up until index: 1260\n",
      "Completed up until index: 1280\n",
      "Completed up until index: 1300\n",
      "Completed up until index: 1320\n",
      "Completed up until index: 1340\n",
      "Completed up until index: 1360\n",
      "Completed up until index: 1380\n",
      "Completed up until index: 1400\n",
      "Completed up until index: 1420\n",
      "Completed up until index: 1440\n",
      "Completed up until index: 1460\n",
      "Completed up until index: 1480\n",
      "Completed up until index: 1500\n",
      "Completed up until index: 1520\n",
      "Completed up until index: 1540\n",
      "Completed up until index: 1560\n",
      "Completed up until index: 1580\n",
      "Completed up until index: 1600\n",
      "Completed up until index: 1620\n",
      "Completed up until index: 1640\n",
      "Completed up until index: 1660\n",
      "Completed up until index: 1680\n",
      "Completed up until index: 1700\n",
      "Completed up until index: 1720\n",
      "Completed up until index: 1740\n",
      "Completed up until index: 1760\n",
      "Completed up until index: 1780\n",
      "Completed up until index: 1800\n",
      "Completed up until index: 1820\n",
      "Completed up until index: 1840\n",
      "Completed up until index: 1860\n",
      "Completed up until index: 1880\n",
      "Completed up until index: 1900\n",
      "Completed up until index: 1920\n",
      "Completed up until index: 1940\n",
      "Completed up until index: 1960\n",
      "Completed up until index: 1980\n",
      "Completed up until index: 2000\n",
      "Completed up until index: 2020\n",
      "Completed up until index: 2040\n",
      "Completed up until index: 2060\n",
      "Completed up until index: 2080\n",
      "Completed up until index: 2100\n",
      "Completed up until index: 2120\n",
      "Completed up until index: 2140\n",
      "Completed up until index: 2160\n",
      "Completed up until index: 2180\n",
      "Completed up until index: 2200\n",
      "Completed up until index: 2220\n",
      "Completed up until index: 2240\n",
      "Completed up until index: 2260\n",
      "Completed up until index: 2280\n",
      "Completed up until index: 2300\n",
      "Completed up until index: 2320\n",
      "Completed up until index: 2340\n",
      "Completed up until index: 2360\n",
      "Completed up until index: 2380\n",
      "Completed up until index: 2400\n",
      "Completed up until index: 2420\n",
      "Completed up until index: 2440\n",
      "Completed up until index: 2460\n",
      "Completed up until index: 2480\n",
      "Completed up until index: 2500\n",
      "Completed up until index: 2520\n",
      "Completed up until index: 2540\n",
      "Completed up until index: 2560\n",
      "Completed up until index: 2580\n",
      "Completed up until index: 2600\n",
      "Completed up until index: 2620\n",
      "Completed up until index: 2640\n",
      "Completed up until index: 2660\n",
      "Completed up until index: 2680\n",
      "Completed up until index: 2700\n",
      "Completed up until index: 2720\n",
      "Completed up until index: 2740\n",
      "Completed up until index: 2760\n",
      "Completed up until index: 2780\n",
      "Completed up until index: 2800\n",
      "Completed up until index: 2820\n",
      "Completed up until index: 2840\n",
      "Completed up until index: 2860\n",
      "Completed up until index: 2880\n",
      "Completed up until index: 2900\n",
      "Completed up until index: 2920\n",
      "Completed up until index: 2940\n",
      "Completed up until index: 2960\n",
      "Completed up until index: 2980\n",
      "Completed up until index: 3000\n",
      "Completed up until index: 3020\n",
      "Completed up until index: 3040\n",
      "Completed up until index: 3060\n",
      "Completed up until index: 3080\n",
      "Completed up until index: 3100\n",
      "Completed up until index: 3120\n",
      "Completed up until index: 3140\n",
      "Completed up until index: 3160\n",
      "Completed up until index: 3180\n",
      "Completed up until index: 3200\n",
      "Completed up until index: 3220\n",
      "Completed up until index: 3240\n",
      "Completed up until index: 3260\n",
      "Completed up until index: 3280\n",
      "Completed up until index: 3300\n",
      "Completed up until index: 3320\n",
      "Completed up until index: 3340\n",
      "Completed up until index: 3360\n",
      "Completed up until index: 3380\n",
      "Completed up until index: 3400\n",
      "Completed up until index: 3420\n",
      "Completed up until index: 3440\n",
      "Completed up until index: 3460\n",
      "Completed up until index: 3480\n",
      "Completed up until index: 3500\n",
      "Completed up until index: 3520\n",
      "Completed up until index: 3540\n",
      "Completed up until index: 3560\n",
      "Completed up until index: 3580\n",
      "Completed up until index: 3600\n",
      "Completed up until index: 3620\n",
      "Completed up until index: 3640\n",
      "Completed up until index: 3660\n",
      "Completed up until index: 3680\n",
      "Completed up until index: 3700\n",
      "Completed up until index: 3720\n",
      "Completed up until index: 3740\n",
      "Completed up until index: 3760\n",
      "Completed up until index: 3780\n",
      "Completed up until index: 3800\n",
      "Completed up until index: 3820\n",
      "Completed up until index: 3840\n",
      "Completed up until index: 3860\n",
      "Completed up until index: 3880\n",
      "Completed up until index: 3900\n",
      "Completed up until index: 3920\n",
      "Completed up until index: 3940\n",
      "Completed up until index: 3960\n",
      "Completed up until index: 3980\n",
      "Completed up until index: 4000\n",
      "Completed up until index: 4020\n",
      "Completed up until index: 4040\n",
      "Completed up until index: 4060\n",
      "Completed up until index: 4080\n",
      "Completed up until index: 4100\n",
      "Completed up until index: 4120\n",
      "Completed up until index: 4140\n",
      "Completed up until index: 4160\n",
      "Completed up until index: 4180\n",
      "Completed up until index: 4200\n",
      "Completed up until index: 4220\n",
      "Completed up until index: 4240\n",
      "Completed up until index: 4260\n",
      "Completed up until index: 4280\n",
      "Completed up until index: 4300\n",
      "Completed up until index: 4320\n",
      "Completed up until index: 4340\n",
      "Completed up until index: 4360\n",
      "Completed up until index: 4380\n",
      "Completed up until index: 4400\n",
      "Completed up until index: 4420\n",
      "Completed up until index: 4440\n",
      "Completed up until index: 4460\n",
      "Completed up until index: 4480\n",
      "Completed up until index: 4500\n",
      "Completed up until index: 4520\n",
      "Completed up until index: 4540\n",
      "Completed up until index: 4560\n",
      "Completed up until index: 4580\n",
      "Completed up until index: 4600\n",
      "Completed up until index: 4620\n",
      "Completed up until index: 4640\n",
      "Completed up until index: 4660\n",
      "Completed up until index: 4680\n",
      "Completed up until index: 4700\n",
      "Completed up until index: 4720\n",
      "Completed up until index: 4740\n",
      "Completed up until index: 4760\n",
      "Completed up until index: 4780\n",
      "Completed up until index: 4800\n",
      "Completed up until index: 4820\n",
      "Completed up until index: 4840\n",
      "Completed up until index: 4860\n",
      "Completed up until index: 4880\n",
      "Completed up until index: 4900\n",
      "Completed up until index: 4920\n",
      "Completed up until index: 4940\n",
      "Completed up until index: 4960\n",
      "Completed up until index: 4980\n",
      "Completed up until index: 5000\n",
      "Completed up until index: 5020\n",
      "Completed up until index: 5040\n",
      "Completed up until index: 5060\n",
      "Completed up until index: 5080\n",
      "Completed up until index: 5100\n",
      "Completed up until index: 5120\n",
      "Completed up until index: 5140\n",
      "Completed up until index: 5160\n",
      "Completed up until index: 5180\n",
      "Completed up until index: 5200\n",
      "Completed up until index: 5220\n",
      "Completed up until index: 5240\n",
      "Completed up until index: 5260\n",
      "Completed up until index: 5280\n",
      "Completed up until index: 5300\n",
      "Completed up until index: 5320\n",
      "Completed up until index: 5340\n",
      "Completed up until index: 5360\n",
      "Completed up until index: 5380\n",
      "Completed up until index: 5400\n",
      "Completed up until index: 5420\n",
      "Completed up until index: 5440\n",
      "Completed up until index: 5460\n",
      "Completed up until index: 5480\n",
      "Completed up until index: 5500\n",
      "Completed up until index: 5520\n",
      "Completed up until index: 5540\n",
      "Completed up until index: 5560\n",
      "Completed up until index: 5580\n",
      "Completed up until index: 5600\n",
      "Completed up until index: 5620\n",
      "Completed up until index: 5640\n",
      "Completed up until index: 5660\n",
      "Completed up until index: 5680\n",
      "Completed up until index: 5700\n",
      "Completed up until index: 5720\n",
      "Completed up until index: 5740\n",
      "Completed up until index: 5760\n",
      "Completed up until index: 5780\n",
      "Completed up until index: 5800\n",
      "Completed up until index: 5820\n",
      "Completed up until index: 5840\n",
      "Completed up until index: 5860\n",
      "Completed up until index: 5880\n",
      "Completed up until index: 5900\n",
      "Completed up until index: 5920\n",
      "Completed up until index: 5940\n",
      "Completed up until index: 5960\n",
      "Completed up until index: 5980\n",
      "Completed up until index: 6000\n",
      "Completed up until index: 6020\n",
      "Completed up until index: 6040\n",
      "Completed up until index: 6060\n",
      "Completed up until index: 6080\n",
      "Completed up until index: 6100\n",
      "Completed up until index: 6120\n",
      "Completed up until index: 6140\n",
      "Completed up until index: 6160\n",
      "Completed up until index: 6180\n",
      "Completed up until index: 6200\n",
      "Completed up until index: 6220\n",
      "Completed up until index: 6240\n",
      "Completed up until index: 6260\n",
      "Completed up until index: 6280\n",
      "Completed up until index: 6300\n",
      "Completed up until index: 6320\n",
      "Completed up until index: 6340\n",
      "Completed up until index: 6360\n",
      "Completed up until index: 6380\n",
      "Completed up until index: 6400\n",
      "Completed up until index: 6420\n",
      "Completed up until index: 6440\n",
      "Completed up until index: 6460\n",
      "Completed up until index: 6480\n",
      "Completed up until index: 6500\n",
      "Completed up until index: 6520\n",
      "Completed up until index: 6540\n",
      "Completed up until index: 6560\n",
      "Completed up until index: 6580\n",
      "Completed up until index: 6600\n",
      "Completed up until index: 6620\n",
      "Completed up until index: 6640\n",
      "Completed up until index: 6660\n",
      "Completed up until index: 6680\n",
      "Completed up until index: 6700\n",
      "Completed up until index: 6720\n",
      "Completed up until index: 6740\n",
      "Completed up until index: 6760\n",
      "Completed up until index: 6780\n",
      "Completed up until index: 6800\n",
      "Completed up until index: 6820\n",
      "Completed up until index: 6840\n",
      "Completed up until index: 6860\n",
      "Completed up until index: 6880\n",
      "Completed up until index: 6900\n",
      "Completed up until index: 6920\n",
      "Completed up until index: 6940\n",
      "Completed up until index: 6960\n",
      "Completed up until index: 6980\n",
      "Completed up until index: 7000\n",
      "Completed up until index: 7020\n",
      "Completed up until index: 7040\n",
      "Completed up until index: 7060\n",
      "Completed up until index: 7080\n",
      "Completed up until index: 7100\n",
      "Completed up until index: 7120\n",
      "Completed up until index: 7140\n",
      "Completed up until index: 7160\n",
      "Completed up until index: 7180\n",
      "Completed up until index: 7200\n",
      "Completed up until index: 7220\n",
      "Completed up until index: 7240\n",
      "Completed up until index: 7260\n",
      "Completed up until index: 7280\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of new observations added to\", target_table_name + \":\", new_obs.shape[0])\n",
    "cols_and_types =cols_and_types_locations\n",
    "cols_with_apostrophes = [\"location\", \"city\",\"country\"]\n",
    "update_in_batches(new_obs, 20, target_table_name, cols_and_types, cols_with_apostrophes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Miscellaneous helper tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Table for converting from two letter ISO to three letter ISO\n",
    "isos = pd.read_csv(\"/Users/nathansuberi/Desktop/Code Portfolio/ResourceWatchCode/Conversion_Standards/iso_conversions.csv\", sep=\"\\t\", header=None)\n",
    "isos.columns = [\"country\", \"iso2\", \"iso3\", \"num\"]\n",
    "iso2s = isos.set_index(\"iso2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check OpenAQ API 'locations' endpoint for acknowledged sensor locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "city            False\n",
      "latitude         True\n",
      "longitude        True\n",
      "iso3             True\n",
      "firstUpdated    False\n",
      "location        False\n",
      "sourceName      False\n",
      "dtype: bool\n",
      "number with no latitude 180\n",
      "number with no longitude 180\n",
      "number with no iso3 1\n",
      "Number of rows in OpenAQ locations database removed due to not having geo-coordinates: 180\n"
     ]
    }
   ],
   "source": [
    "# url = \"https://api.openaq.org/v1/locations\"\n",
    "\n",
    "# # There are a total of 8055 locations in the database so far, according to this query\n",
    "# # so this shouldn't miss any... but it may at some point\n",
    "\n",
    "# ### FRANCIS ###\n",
    "# # The 10000 limit on requests is a hard limit in their API... what to do if there are more than \n",
    "# # 10000 observations in the desired endpoint?\n",
    "# params = {\n",
    "#     \"limit\":10000\n",
    "# }\n",
    "\n",
    "# res = req.get(url, params=params)\n",
    "# data = res.json()[\"results\"]\n",
    "# locations = pd.io.json.json_normalize(data, errors='ignore')\n",
    "# locations.columns = [\"city\", \"latitude\", \"longitude\", \"count\", \"country\", \"firstUpdated\", \"lastUpdated\",\n",
    "#              \"location\", \"parameters\", \"sourceName\", \"sourceNames\"]\n",
    "# locations[\"iso3\"] = iso2s.loc[locations[\"country\"], \"iso3\"].values\n",
    "# # Note - not storing parameters because these could change over time and it would be a pain to update\n",
    "# locations = locations[[\"city\", \"latitude\", \"longitude\", \"iso3\", \"firstUpdated\", \"location\", \"sourceName\"]]\n",
    "\n",
    "# pre_clean = locations.shape[0]\n",
    "\n",
    "# # View columns that have null values\n",
    "# # https://stackoverflow.com/questions/14016247/python-find-integer-index-of-rows-with-nan-in-pandas\n",
    "# print(pd.isnull(locations).any())\n",
    "# print(\"number with no latitude\",sum(pd.isnull(locations[\"latitude\"])))\n",
    "# print(\"number with no longitude\",sum(pd.isnull(locations[\"longitude\"])))\n",
    "# print(\"number with no iso3\",sum(pd.isnull(locations[\"iso3\"])))\n",
    "\n",
    "# keep_geotagged = pd.notnull(locations[\"latitude\"]) & pd.notnull(locations[\"longitude\"]) \n",
    "\n",
    "# # Remove all points that don't have a lat-lon\n",
    "# locations = locations.loc[keep_geotagged]\n",
    "\n",
    "# # Convert any remaining nan into empty string\n",
    "# # http://pandas.pydata.org/pandas-docs/version/0.17.0/generated/pandas.DataFrame.fillna.html\n",
    "# locations = locations.fillna(value=\"\")\n",
    "\n",
    "# post_clean = locations.shape[0]\n",
    "# print(\"Number of rows in OpenAQ locations database removed due to not having geo-coordinates:\", pre_clean - post_clean)\n",
    "\n",
    "# ## Having issues with non-standard characters... how to deal with this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>iso3</th>\n",
       "      <th>firstUpdated</th>\n",
       "      <th>location</th>\n",
       "      <th>sourceName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ulaanbaatar</td>\n",
       "      <td>47.932907</td>\n",
       "      <td>106.921390</td>\n",
       "      <td>MNG</td>\n",
       "      <td>2015-09-01T00:00:00.000Z</td>\n",
       "      <td>100 ail</td>\n",
       "      <td>Agaar.mn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Omaha-Council Bluffs</td>\n",
       "      <td>41.322470</td>\n",
       "      <td>-95.937990</td>\n",
       "      <td>USA</td>\n",
       "      <td>2016-03-06T19:00:00.000Z</td>\n",
       "      <td>16th and Whitmore</td>\n",
       "      <td>AirNow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Farmington</td>\n",
       "      <td>36.809700</td>\n",
       "      <td>-107.651700</td>\n",
       "      <td>USA</td>\n",
       "      <td>2016-03-06T19:00:00.000Z</td>\n",
       "      <td>1NL Navajo Lake</td>\n",
       "      <td>AirNow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21 de mayo</td>\n",
       "      <td>-37.471184</td>\n",
       "      <td>-72.361465</td>\n",
       "      <td>CHL</td>\n",
       "      <td>2015-09-23T14:00:00.000Z</td>\n",
       "      <td>21 de mayo</td>\n",
       "      <td>Chile - SINCA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tucson</td>\n",
       "      <td>32.205000</td>\n",
       "      <td>-110.877200</td>\n",
       "      <td>USA</td>\n",
       "      <td>2016-03-06T19:00:00.000Z</td>\n",
       "      <td>22nd Street &amp; Craycr</td>\n",
       "      <td>AirNow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   city   latitude   longitude iso3              firstUpdated  \\\n",
       "0           Ulaanbaatar  47.932907  106.921390  MNG  2015-09-01T00:00:00.000Z   \n",
       "1  Omaha-Council Bluffs  41.322470  -95.937990  USA  2016-03-06T19:00:00.000Z   \n",
       "2            Farmington  36.809700 -107.651700  USA  2016-03-06T19:00:00.000Z   \n",
       "3            21 de mayo -37.471184  -72.361465  CHL  2015-09-23T14:00:00.000Z   \n",
       "4                Tucson  32.205000 -110.877200  USA  2016-03-06T19:00:00.000Z   \n",
       "\n",
       "               location     sourceName  \n",
       "0               100 ail       Agaar.mn  \n",
       "1     16th and Whitmore         AirNow  \n",
       "2       1NL Navajo Lake         AirNow  \n",
       "3            21 de mayo  Chile - SINCA  \n",
       "4  22nd Street & Craycr         AirNow  "
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Use coordinates instead of location\n",
    "# # OR use location, city, country\n",
    "# # Check documentation for unique id\n",
    "\n",
    "# locations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert these observed sensor locations into open_aq_locations Carto table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed up until index: 40\n",
      "Completed up until index: 60\n",
      "Completed up until index: 80\n",
      "Completed up until index: 100\n",
      "Completed up until index: 120\n",
      "Completed up until index: 140\n",
      "Completed up until index: 160\n",
      "Completed up until index: 180\n",
      "Completed up until index: 200\n",
      "Completed up until index: 220\n",
      "Completed up until index: 240\n",
      "Completed up until index: 260\n",
      "Completed up until index: 280\n",
      "Completed up until index: 300\n",
      "Completed up until index: 320\n",
      "Completed up until index: 340\n",
      "Completed up until index: 360\n",
      "Completed up until index: 380\n",
      "Completed up until index: 400\n",
      "Completed up until index: 420\n",
      "Completed up until index: 440\n",
      "Completed up until index: 460\n",
      "Completed up until index: 480\n",
      "Completed up until index: 500\n",
      "Completed up until index: 520\n",
      "Completed up until index: 540\n",
      "Completed up until index: 560\n",
      "Completed up until index: 580\n",
      "Completed up until index: 600\n",
      "Completed up until index: 620\n",
      "Completed up until index: 640\n",
      "Completed up until index: 660\n",
      "Completed up until index: 680\n",
      "Completed up until index: 700\n",
      "Completed up until index: 720\n",
      "Completed up until index: 740\n",
      "Completed up until index: 760\n",
      "Completed up until index: 780\n",
      "Completed up until index: 800\n",
      "Completed up until index: 820\n",
      "Completed up until index: 840\n",
      "Completed up until index: 860\n",
      "Completed up until index: 880\n",
      "Completed up until index: 900\n",
      "Completed up until index: 920\n",
      "Completed up until index: 940\n",
      "Completed up until index: 960\n",
      "Completed up until index: 980\n",
      "Completed up until index: 1000\n",
      "Completed up until index: 1020\n",
      "Completed up until index: 1040\n",
      "Completed up until index: 1060\n",
      "Completed up until index: 1080\n",
      "Completed up until index: 1100\n",
      "Completed up until index: 1120\n",
      "Completed up until index: 1140\n",
      "Completed up until index: 1160\n",
      "Completed up until index: 1180\n",
      "Completed up until index: 1200\n",
      "Completed up until index: 1220\n",
      "Completed up until index: 1240\n",
      "Completed up until index: 1260\n",
      "Completed up until index: 1280\n",
      "Completed up until index: 1300\n",
      "Completed up until index: 1320\n",
      "Completed up until index: 1340\n",
      "Completed up until index: 1360\n",
      "Completed up until index: 1380\n",
      "Completed up until index: 1400\n",
      "Completed up until index: 1420\n",
      "Completed up until index: 1440\n",
      "Completed up until index: 1460\n",
      "Completed up until index: 1480\n",
      "Completed up until index: 1500\n",
      "Completed up until index: 1520\n",
      "Completed up until index: 1540\n",
      "Completed up until index: 1560\n",
      "Completed up until index: 1580\n",
      "Completed up until index: 1600\n",
      "Completed up until index: 1620\n",
      "Completed up until index: 1640\n",
      "Completed up until index: 1660\n",
      "Completed up until index: 1680\n",
      "Completed up until index: 1700\n",
      "Completed up until index: 1720\n",
      "Completed up until index: 1740\n",
      "Completed up until index: 1760\n",
      "Completed up until index: 1780\n",
      "Completed up until index: 1800\n",
      "Completed up until index: 1820\n",
      "Completed up until index: 1840\n",
      "Completed up until index: 1860\n",
      "Completed up until index: 1880\n",
      "Completed up until index: 1900\n",
      "Completed up until index: 1920\n",
      "Completed up until index: 1940\n",
      "Completed up until index: 1960\n",
      "Completed up until index: 1980\n",
      "Completed up until index: 2000\n",
      "Completed up until index: 2020\n",
      "Completed up until index: 2040\n",
      "Completed up until index: 2060\n",
      "Completed up until index: 2080\n",
      "Completed up until index: 2100\n",
      "Completed up until index: 2120\n",
      "Completed up until index: 2140\n",
      "Completed up until index: 2160\n",
      "Completed up until index: 2180\n",
      "Completed up until index: 2200\n",
      "Completed up until index: 2220\n",
      "Completed up until index: 2240\n",
      "Completed up until index: 2260\n",
      "Completed up until index: 2280\n",
      "Completed up until index: 2300\n",
      "Completed up until index: 2320\n",
      "Completed up until index: 2340\n",
      "Completed up until index: 2360\n",
      "Completed up until index: 2380\n",
      "Completed up until index: 2400\n",
      "Completed up until index: 2420\n",
      "Completed up until index: 2440\n",
      "Completed up until index: 2460\n",
      "Completed up until index: 2480\n",
      "Completed up until index: 2500\n",
      "Completed up until index: 2520\n",
      "Completed up until index: 2540\n",
      "Completed up until index: 2560\n",
      "Completed up until index: 2580\n",
      "Completed up until index: 2600\n",
      "Completed up until index: 2620\n",
      "Completed up until index: 2640\n",
      "Completed up until index: 2660\n",
      "Completed up until index: 2680\n",
      "Completed up until index: 2700\n",
      "Completed up until index: 2720\n",
      "Completed up until index: 2740\n",
      "Completed up until index: 2760\n",
      "Completed up until index: 2780\n",
      "Completed up until index: 2800\n",
      "Completed up until index: 2820\n",
      "Completed up until index: 2840\n",
      "Completed up until index: 2860\n",
      "Completed up until index: 2880\n",
      "Completed up until index: 2900\n",
      "Completed up until index: 2920\n",
      "Completed up until index: 2940\n",
      "Completed up until index: 2960\n",
      "Completed up until index: 2980\n",
      "Completed up until index: 3000\n",
      "Completed up until index: 3020\n",
      "Completed up until index: 3040\n",
      "Completed up until index: 3060\n",
      "Completed up until index: 3080\n",
      "Completed up until index: 3100\n",
      "Completed up until index: 3120\n",
      "Completed up until index: 3140\n",
      "Completed up until index: 3160\n",
      "Completed up until index: 3180\n",
      "Completed up until index: 3200\n",
      "Completed up until index: 3220\n",
      "Completed up until index: 3240\n",
      "Completed up until index: 3260\n",
      "Completed up until index: 3280\n",
      "Completed up until index: 3300\n",
      "Completed up until index: 3320\n",
      "Completed up until index: 3340\n",
      "Completed up until index: 3360\n",
      "Completed up until index: 3380\n",
      "Completed up until index: 3400\n",
      "Completed up until index: 3420\n",
      "Completed up until index: 3440\n",
      "Completed up until index: 3460\n",
      "Completed up until index: 3480\n",
      "Completed up until index: 3500\n",
      "Completed up until index: 3520\n",
      "Completed up until index: 3540\n",
      "Completed up until index: 3560\n",
      "Completed up until index: 3580\n",
      "Completed up until index: 3600\n",
      "Completed up until index: 3620\n",
      "Completed up until index: 3640\n",
      "Completed up until index: 3660\n",
      "Completed up until index: 3680\n",
      "Completed up until index: 3700\n",
      "Completed up until index: 3720\n",
      "Completed up until index: 3740\n",
      "Completed up until index: 3760\n",
      "Completed up until index: 3780\n",
      "Completed up until index: 3800\n",
      "Completed up until index: 3820\n",
      "Completed up until index: 3840\n",
      "Completed up until index: 3860\n",
      "Completed up until index: 3880\n",
      "Completed up until index: 3900\n",
      "Completed up until index: 3920\n",
      "Completed up until index: 3940\n",
      "Completed up until index: 3960\n",
      "Completed up until index: 3980\n",
      "Completed up until index: 4000\n",
      "Completed up until index: 4020\n",
      "Completed up until index: 4040\n",
      "Completed up until index: 4060\n",
      "Completed up until index: 4080\n",
      "Completed up until index: 4100\n",
      "Completed up until index: 4120\n",
      "Completed up until index: 4140\n",
      "Completed up until index: 4160\n",
      "Completed up until index: 4180\n",
      "Completed up until index: 4200\n",
      "Completed up until index: 4220\n",
      "Completed up until index: 4240\n",
      "Completed up until index: 4260\n",
      "Completed up until index: 4280\n",
      "Completed up until index: 4300\n",
      "Completed up until index: 4320\n",
      "Completed up until index: 4340\n",
      "Completed up until index: 4360\n",
      "Completed up until index: 4380\n",
      "Completed up until index: 4400\n",
      "Completed up until index: 4420\n",
      "Completed up until index: 4440\n",
      "Completed up until index: 4460\n",
      "Completed up until index: 4480\n",
      "Completed up until index: 4500\n",
      "Completed up until index: 4520\n",
      "Completed up until index: 4540\n",
      "Completed up until index: 4560\n",
      "Completed up until index: 4580\n",
      "Completed up until index: 4600\n",
      "Completed up until index: 4620\n",
      "Completed up until index: 4640\n",
      "Completed up until index: 4660\n",
      "Completed up until index: 4680\n",
      "Completed up until index: 4700\n",
      "Completed up until index: 4720\n",
      "Completed up until index: 4740\n",
      "Completed up until index: 4760\n",
      "Completed up until index: 4780\n",
      "Completed up until index: 4800\n",
      "Completed up until index: 4820\n",
      "Completed up until index: 4840\n",
      "Completed up until index: 4860\n",
      "Completed up until index: 4880\n",
      "Completed up until index: 4900\n",
      "Completed up until index: 4920\n",
      "Completed up until index: 4940\n",
      "Completed up until index: 4960\n",
      "Completed up until index: 4980\n",
      "Completed up until index: 5000\n",
      "Completed up until index: 5020\n",
      "Completed up until index: 5040\n",
      "Completed up until index: 5060\n",
      "Completed up until index: 5080\n",
      "Completed up until index: 5100\n",
      "Completed up until index: 5120\n",
      "Completed up until index: 5140\n",
      "Completed up until index: 5160\n",
      "Completed up until index: 5180\n",
      "Completed up until index: 5200\n",
      "Completed up until index: 5220\n",
      "Completed up until index: 5240\n",
      "Completed up until index: 5260\n",
      "Completed up until index: 5280\n",
      "Completed up until index: 5300\n",
      "Completed up until index: 5320\n",
      "Completed up until index: 5340\n",
      "Completed up until index: 5360\n",
      "Completed up until index: 5380\n",
      "Completed up until index: 5400\n",
      "Completed up until index: 5420\n",
      "Completed up until index: 5440\n",
      "Completed up until index: 5460\n",
      "Completed up until index: 5480\n",
      "Completed up until index: 5500\n",
      "Completed up until index: 5520\n",
      "Completed up until index: 5540\n",
      "Completed up until index: 5560\n",
      "Completed up until index: 5580\n",
      "Completed up until index: 5600\n",
      "Completed up until index: 5620\n",
      "Completed up until index: 5640\n",
      "Completed up until index: 5660\n",
      "Completed up until index: 5680\n",
      "Completed up until index: 5700\n",
      "Completed up until index: 5720\n",
      "Completed up until index: 5740\n",
      "Completed up until index: 5760\n",
      "Completed up until index: 5780\n",
      "Completed up until index: 5800\n",
      "Completed up until index: 5820\n",
      "Completed up until index: 5840\n",
      "Completed up until index: 5860\n",
      "Completed up until index: 5880\n",
      "Completed up until index: 5900\n",
      "Completed up until index: 5920\n",
      "Completed up until index: 5940\n",
      "Completed up until index: 5960\n",
      "Completed up until index: 5980\n",
      "Completed up until index: 6000\n",
      "Completed up until index: 6020\n",
      "Completed up until index: 6040\n",
      "Completed up until index: 6060\n",
      "Completed up until index: 6080\n",
      "Completed up until index: 6100\n",
      "Completed up until index: 6120\n",
      "Completed up until index: 6140\n",
      "Completed up until index: 6160\n",
      "Completed up until index: 6180\n",
      "Completed up until index: 6200\n",
      "Completed up until index: 6220\n",
      "Completed up until index: 6240\n",
      "Completed up until index: 6260\n",
      "Completed up until index: 6280\n",
      "Completed up until index: 6300\n",
      "Completed up until index: 6320\n",
      "Completed up until index: 6340\n",
      "Completed up until index: 6360\n",
      "Completed up until index: 6380\n",
      "Completed up until index: 6400\n",
      "Completed up until index: 6420\n",
      "Completed up until index: 6440\n",
      "Completed up until index: 6460\n",
      "Completed up until index: 6480\n",
      "Completed up until index: 6500\n",
      "Completed up until index: 6520\n",
      "Completed up until index: 6540\n",
      "Completed up until index: 6560\n",
      "Completed up until index: 6580\n",
      "Completed up until index: 6600\n",
      "Completed up until index: 6620\n",
      "Completed up until index: 6640\n",
      "Completed up until index: 6660\n",
      "Completed up until index: 6680\n",
      "Completed up until index: 6700\n",
      "Completed up until index: 6720\n",
      "Completed up until index: 6740\n",
      "Completed up until index: 6760\n",
      "Completed up until index: 6780\n",
      "Completed up until index: 6800\n",
      "Completed up until index: 6820\n",
      "Completed up until index: 6840\n",
      "Completed up until index: 6860\n",
      "Completed up until index: 6880\n",
      "Completed up until index: 6900\n",
      "Completed up until index: 6920\n",
      "Completed up until index: 6940\n",
      "Completed up until index: 6960\n",
      "Completed up until index: 6980\n",
      "Completed up until index: 7000\n",
      "Completed up until index: 7020\n",
      "Completed up until index: 7040\n",
      "Completed up until index: 7060\n",
      "Completed up until index: 7080\n",
      "Completed up until index: 7100\n",
      "Completed up until index: 7120\n",
      "Completed up until index: 7140\n",
      "Completed up until index: 7160\n",
      "Completed up until index: 7180\n",
      "Completed up until index: 7200\n",
      "Completed up until index: 7220\n",
      "Completed up until index: 7240\n",
      "Completed up until index: 7260\n",
      "Completed up until index: 7280\n",
      "Completed up until index: 7300\n",
      "Completed up until index: 7320\n",
      "Completed up until index: 7340\n",
      "Completed up until index: 7360\n",
      "Completed up until index: 7380\n",
      "Completed up until index: 7400\n",
      "Completed up until index: 7420\n",
      "Completed up until index: 7440\n",
      "Completed up until index: 7460\n",
      "Completed up until index: 7480\n",
      "Completed up until index: 7500\n",
      "Completed up until index: 7520\n",
      "Completed up until index: 7540\n",
      "Completed up until index: 7560\n",
      "Completed up until index: 7580\n",
      "Completed up until index: 7600\n",
      "Completed up until index: 7620\n",
      "Completed up until index: 7640\n",
      "Completed up until index: 7660\n",
      "Completed up until index: 7680\n",
      "Completed up until index: 7700\n",
      "Completed up until index: 7720\n",
      "Completed up until index: 7740\n",
      "Completed up until index: 7760\n",
      "Completed up until index: 7780\n",
      "Completed up until index: 7800\n",
      "Completed up until index: 7820\n",
      "Completed up until index: 7840\n",
      "Completed up until index: 7860\n",
      "Completed up until index: 7880\n"
     ]
    }
   ],
   "source": [
    "table_name = \"open_aq_locations\"\n",
    "\n",
    "## URI too large to insert more than about 20 rows at once, have to do in small sets\n",
    "kwargs = {\n",
    "    \"data_df\":locations,\n",
    "    \"batch_size\":20,\n",
    "    \"target_table_name\":table_name,\n",
    "    \"cols_and_types\":cols_and_types_locations,\n",
    "    \"cols_with_apostrophes\":[\"city\", \"location\", \"sourceName\"]\n",
    "}\n",
    "\n",
    "update_in_batches(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List OpenAQ locations that we've previously acknowledged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>firstupdated</th>\n",
       "      <th>iso3</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>sourcename</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40RL01 - ROESELARE</th>\n",
       "      <td>Flanders</td>\n",
       "      <td>2016-11-17T00:00:00Z</td>\n",
       "      <td>BEL</td>\n",
       "      <td>50.953180</td>\n",
       "      <td>3.121155</td>\n",
       "      <td>EEA Belgium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40SZ01 - STEENOKKERZ</th>\n",
       "      <td>Flanders</td>\n",
       "      <td>2016-11-17T00:00:00Z</td>\n",
       "      <td>BEL</td>\n",
       "      <td>50.914577</td>\n",
       "      <td>4.504183</td>\n",
       "      <td>EEA Belgium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40SZ02 - STEENOKKERZ</th>\n",
       "      <td>Flanders</td>\n",
       "      <td>2016-11-17T00:00:00Z</td>\n",
       "      <td>BEL</td>\n",
       "      <td>50.913020</td>\n",
       "      <td>4.512184</td>\n",
       "      <td>EEA Belgium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40TS21 - TESSENDERLO</th>\n",
       "      <td>Flanders</td>\n",
       "      <td>2016-11-17T00:00:00Z</td>\n",
       "      <td>BEL</td>\n",
       "      <td>51.065710</td>\n",
       "      <td>5.107536</td>\n",
       "      <td>EEA Belgium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40WZ02 - MOL</th>\n",
       "      <td>Flanders</td>\n",
       "      <td>2016-11-17T00:00:00Z</td>\n",
       "      <td>BEL</td>\n",
       "      <td>51.192800</td>\n",
       "      <td>5.221534</td>\n",
       "      <td>EEA Belgium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          city          firstupdated iso3   latitude  \\\n",
       "location                                                               \n",
       "40RL01 - ROESELARE    Flanders  2016-11-17T00:00:00Z  BEL  50.953180   \n",
       "40SZ01 - STEENOKKERZ  Flanders  2016-11-17T00:00:00Z  BEL  50.914577   \n",
       "40SZ02 - STEENOKKERZ  Flanders  2016-11-17T00:00:00Z  BEL  50.913020   \n",
       "40TS21 - TESSENDERLO  Flanders  2016-11-17T00:00:00Z  BEL  51.065710   \n",
       "40WZ02 - MOL          Flanders  2016-11-17T00:00:00Z  BEL  51.192800   \n",
       "\n",
       "                      longitude   sourcename  \n",
       "location                                      \n",
       "40RL01 - ROESELARE     3.121155  EEA Belgium  \n",
       "40SZ01 - STEENOKKERZ   4.504183  EEA Belgium  \n",
       "40SZ02 - STEENOKKERZ   4.512184  EEA Belgium  \n",
       "40TS21 - TESSENDERLO   5.107536  EEA Belgium  \n",
       "40WZ02 - MOL           5.221534  EEA Belgium  "
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_name = \"open_aq_locations\"\n",
    "select_all_sql = \"\"\"\n",
    "SELECT * FROM {table_name}\n",
    "\"\"\".format(table_name=table_name)\n",
    "\n",
    "res = sql_api(select_all_sql)\n",
    "locations = pd.DataFrame(res[\"rows\"])\n",
    "locations = locations.set_index(\"location\")\n",
    "locations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve latest data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = \"https://api.openaq.org/v1/latest\"\n",
    "\n",
    "params = {\n",
    "    \"limit\":10000\n",
    "}\n",
    "\n",
    "res = req.get(url, params=params)\n",
    "data = res.json()[\"results\"]\n",
    "\n",
    "latest_data = pd.io.json.json_normalize(data, ['measurements'],[['coordinates', 'latitude'], ['coordinates', 'longitude'],'location', 'city', 'country'],  \n",
    "                                          errors='ignore')\n",
    "\n",
    "##\n",
    "## Potential error - if no observed points have an averagingPeriod during an update, this can fail\n",
    "##\n",
    "\n",
    "#latest_data.columns = [\"averagingPeriod\", \"lastUpdated\", \"parameter\", \"sourceName\", \"unit\", \"value\", \"latitude\", \"longitude\", \"location\",\"city\", \"country\"]\n",
    "#latest_data[\"iso3\"] = iso2s.loc[latest_data[\"country\"], \"iso3\"].values\n",
    "latest_data = latest_data.set_index(\"location\")\n",
    "\n",
    "## May need to develop function for adding iso3 that is more flexible for a range of spellings...\n",
    "# Have a check whether anything was not successfully coded. Determine whether to add this new spelling\n",
    "# to running list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>averagingPeriod</th>\n",
       "      <th>lastUpdated</th>\n",
       "      <th>parameter</th>\n",
       "      <th>sourceName</th>\n",
       "      <th>unit</th>\n",
       "      <th>value</th>\n",
       "      <th>coordinates.latitude</th>\n",
       "      <th>coordinates.longitude</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100 ail</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-12-12T19:00:00.000Z</td>\n",
       "      <td>no2</td>\n",
       "      <td>Agaar.mn</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>26.0</td>\n",
       "      <td>47.932907</td>\n",
       "      <td>106.92139</td>\n",
       "      <td>Ulaanbaatar</td>\n",
       "      <td>MN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100 ail</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-12-12T19:00:00.000Z</td>\n",
       "      <td>o3</td>\n",
       "      <td>Agaar.mn</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>20.0</td>\n",
       "      <td>47.932907</td>\n",
       "      <td>106.92139</td>\n",
       "      <td>Ulaanbaatar</td>\n",
       "      <td>MN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100 ail</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-12-12T19:00:00.000Z</td>\n",
       "      <td>so2</td>\n",
       "      <td>Agaar.mn</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>28.0</td>\n",
       "      <td>47.932907</td>\n",
       "      <td>106.92139</td>\n",
       "      <td>Ulaanbaatar</td>\n",
       "      <td>MN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100 ail</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-12-12T19:00:00.000Z</td>\n",
       "      <td>pm10</td>\n",
       "      <td>Agaar.mn</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>177.0</td>\n",
       "      <td>47.932907</td>\n",
       "      <td>106.92139</td>\n",
       "      <td>Ulaanbaatar</td>\n",
       "      <td>MN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100 ail</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-12-12T19:00:00.000Z</td>\n",
       "      <td>co</td>\n",
       "      <td>Agaar.mn</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>1158.0</td>\n",
       "      <td>47.932907</td>\n",
       "      <td>106.92139</td>\n",
       "      <td>Ulaanbaatar</td>\n",
       "      <td>MN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         averagingPeriod               lastUpdated parameter sourceName  \\\n",
       "location                                                                  \n",
       "100 ail              NaN  2017-12-12T19:00:00.000Z       no2   Agaar.mn   \n",
       "100 ail              NaN  2017-12-12T19:00:00.000Z        o3   Agaar.mn   \n",
       "100 ail              NaN  2017-12-12T19:00:00.000Z       so2   Agaar.mn   \n",
       "100 ail              NaN  2017-12-12T19:00:00.000Z      pm10   Agaar.mn   \n",
       "100 ail              NaN  2017-12-12T19:00:00.000Z        co   Agaar.mn   \n",
       "\n",
       "           unit   value  coordinates.latitude  coordinates.longitude  \\\n",
       "location                                                               \n",
       "100 ail   µg/m³    26.0             47.932907              106.92139   \n",
       "100 ail   µg/m³    20.0             47.932907              106.92139   \n",
       "100 ail   µg/m³    28.0             47.932907              106.92139   \n",
       "100 ail   µg/m³   177.0             47.932907              106.92139   \n",
       "100 ail   µg/m³  1158.0             47.932907              106.92139   \n",
       "\n",
       "                 city country  \n",
       "location                       \n",
       "100 ail   Ulaanbaatar      MN  \n",
       "100 ail   Ulaanbaatar      MN  \n",
       "100 ail   Ulaanbaatar      MN  \n",
       "100 ail   Ulaanbaatar      MN  \n",
       "100 ail   Ulaanbaatar      MN  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check to see that new data all has a corresponding location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['100 ail', '16th and Whitmore', '1NL Navajo Lake', '21 de mayo',\n",
      "       '22nd Street & Craycr', '24th & O', '2912 Coffey', '2LL Los Lunas',\n",
      "       '40AB01 - ANTWERPEN', '40AB02 - BERENDRECHT',\n",
      "       ...\n",
      "       'תחנה:איינשטין', 'תחנה:אריאל', 'תחנה:גבעת המורה', 'תחנה:גליל מערבי',\n",
      "       'תחנה:גן שמואל', 'תחנה:חיפה', 'תחנה:כביש 1 מוצא', 'תחנה:ניידת1',\n",
      "       'תחנה:קיסריה', 'ฺBan-Tai, Kanchanaburi'],\n",
      "      dtype='object', name='location', length=240)\n",
      "\n",
      "Total number of unique places in latest data: 8055\n",
      "Previously unseen places in latest data: 240\n"
     ]
    }
   ],
   "source": [
    "unique_places_in_latest_data = latest_data.index.unique()\n",
    "new_places_ix = [place not in locations.index for place in unique_places_in_latest_data]\n",
    "new_places = unique_places_in_latest_data[new_places_ix]\n",
    "print(new_places)\n",
    "\n",
    "### Replaced apostrophes, this could be a problem\n",
    "# Also dropped non-georeferenced\n",
    "# Follow up on both of these and see if there are still any unaccounted for\n",
    "\n",
    "print(\"\\nTotal number of unique places in latest data:\", len(unique_places_in_latest_data))\n",
    "print(\"Previously unseen places in latest data:\", len(new_places))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add any \"new places\" to the open_aq_locations table\n",
    "* Note: firstUpdated will be set to the earliest \"lastUpdated\" field for that sensor in the new data\n",
    "* This will likely not be correct... will need to verify this with OpenAQ partners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>firstUpdated</th>\n",
       "      <th>sourceName</th>\n",
       "      <th>city</th>\n",
       "      <th>iso3</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [firstUpdated, sourceName, city, iso3, latitude, longitude]\n",
       "Index: []"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location_table_columns =[\"location\",\"firstUpdated\",\"sourceName\",\"city\",\"iso3\",\"latitude\",\"longitude\"]\n",
    "new_places_df = pd.DataFrame(columns=location_table_columns).set_index(\"location\")\n",
    "new_places_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>averagingPeriod</th>\n",
       "      <th>lastUpdated</th>\n",
       "      <th>parameter</th>\n",
       "      <th>sourceName</th>\n",
       "      <th>unit</th>\n",
       "      <th>value</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>iso3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100 ail</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-12-08T10:45:00.000Z</td>\n",
       "      <td>o3</td>\n",
       "      <td>Agaar.mn</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.932907</td>\n",
       "      <td>106.92139</td>\n",
       "      <td>Ulaanbaatar</td>\n",
       "      <td>MN</td>\n",
       "      <td>MNG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100 ail</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-12-08T10:45:00.000Z</td>\n",
       "      <td>pm10</td>\n",
       "      <td>Agaar.mn</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>203.0</td>\n",
       "      <td>47.932907</td>\n",
       "      <td>106.92139</td>\n",
       "      <td>Ulaanbaatar</td>\n",
       "      <td>MN</td>\n",
       "      <td>MNG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100 ail</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-12-08T10:45:00.000Z</td>\n",
       "      <td>so2</td>\n",
       "      <td>Agaar.mn</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>41.0</td>\n",
       "      <td>47.932907</td>\n",
       "      <td>106.92139</td>\n",
       "      <td>Ulaanbaatar</td>\n",
       "      <td>MN</td>\n",
       "      <td>MNG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100 ail</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-12-08T10:45:00.000Z</td>\n",
       "      <td>co</td>\n",
       "      <td>Agaar.mn</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>3771.0</td>\n",
       "      <td>47.932907</td>\n",
       "      <td>106.92139</td>\n",
       "      <td>Ulaanbaatar</td>\n",
       "      <td>MN</td>\n",
       "      <td>MNG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100 ail</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-12-08T10:45:00.000Z</td>\n",
       "      <td>no2</td>\n",
       "      <td>Agaar.mn</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>86.0</td>\n",
       "      <td>47.932907</td>\n",
       "      <td>106.92139</td>\n",
       "      <td>Ulaanbaatar</td>\n",
       "      <td>MN</td>\n",
       "      <td>MNG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         averagingPeriod               lastUpdated parameter sourceName  \\\n",
       "location                                                                  \n",
       "100 ail              NaN  2017-12-08T10:45:00.000Z        o3   Agaar.mn   \n",
       "100 ail              NaN  2017-12-08T10:45:00.000Z      pm10   Agaar.mn   \n",
       "100 ail              NaN  2017-12-08T10:45:00.000Z       so2   Agaar.mn   \n",
       "100 ail              NaN  2017-12-08T10:45:00.000Z        co   Agaar.mn   \n",
       "100 ail              NaN  2017-12-08T10:45:00.000Z       no2   Agaar.mn   \n",
       "\n",
       "           unit   value   latitude  longitude         city country iso3  \n",
       "location                                                                 \n",
       "100 ail   µg/m³     0.0  47.932907  106.92139  Ulaanbaatar      MN  MNG  \n",
       "100 ail   µg/m³   203.0  47.932907  106.92139  Ulaanbaatar      MN  MNG  \n",
       "100 ail   µg/m³    41.0  47.932907  106.92139  Ulaanbaatar      MN  MNG  \n",
       "100 ail   µg/m³  3771.0  47.932907  106.92139  Ulaanbaatar      MN  MNG  \n",
       "100 ail   µg/m³    86.0  47.932907  106.92139  Ulaanbaatar      MN  MNG  "
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest_data.loc[new_places[0], ]\n",
    "\n",
    "locations.reset_index().set_index(\"city\").loc[\"Ulaanbaatar\"]\n",
    "latest_data.reset_index().set_index(\"city\").loc[\"Ulaanbaatar\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load files to experiment with de-duping\n",
    "\n",
    "# Set above: OPENAQ_DATA_FOLDER = \"/Users/nathansuberi/Desktop/RW_Data/OpenAQ/\"\n",
    "sample1_file = \"open_aq_latest_2017-12-07_09-19-10.csv\"\n",
    "sample2_file = \"open_aq_latest_2017-12-08_09-41-36.csv\"\n",
    "\n",
    "df1 = pd.read_csv(OPENAQ_DATA_FOLDER+sample1_file, index_col=[0])\n",
    "df2 = pd.read_csv(OPENAQ_DATA_FOLDER+sample2_file, index_col=[0])\n",
    "\n",
    "df1.set_index([\"latitude\", \"longitude\"], inplace=True)\n",
    "df2.set_index([\"latitude\", \"longitude\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Float64Index([-158.088592529,  -157.96913147,  -157.87109375, -157.858093262,\n",
       "              -156.492416382, -156.446105957, -156.370346069, -155.913299561,\n",
       "              -155.778137207, -155.468902588,\n",
       "              ...\n",
       "               153.028106689,  153.029998779,  153.032104492,  153.035003662,\n",
       "               153.087203979,  153.103805542,  153.135894775,  153.149505615,\n",
       "               153.152694702,  153.158096313],\n",
       "             dtype='float64', name='longitude', length=6183)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine if there are any overlaps\n",
    "df1.index.levels[0]\n",
    "df1.index.levels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Insert original data into Carto table\n",
    "# Insert value sql\n",
    "\n",
    "df = pd.read_csv(\"open_aq_latest_2017-12-08 09/21/31.219395.csv\")\n",
    "\n",
    "table_name = \"open_aq_history\"\n",
    "\n",
    "columns = str(tuple(df.columns)).replace(\"'\",\"\")\n",
    "values = \", \".join(list(df.apply(lambda row: dump_row_contents(row, cols_and_types_history), axis=1)))\n",
    "\n",
    "insert_value_sql = \"\"\"\n",
    "INSERT INTO {table_name} {columns} VALUES {values}\n",
    "\"\"\".format(table_name=table_name, columns=columns, values=values)\n",
    "\n",
    "print(insert_value_sql)\n",
    "\n",
    "res = sql_api(insert_value_sql)\n",
    "print(res.text)\n",
    "\n",
    "\n",
    "# Extract data from Carto table to run the de-duping method\n",
    "\n",
    "# Select all from a table in a certain time range\n",
    "\n",
    "## TO DO: Format this for the UTC format the Carto table will use\n",
    "look_back = \"1 day\"\n",
    "select_all_in_time_range_sql = \"\"\"\n",
    "SELECT * FROM {table_name} WHERE lastUpdated \n",
    "\"\"\".format(table_name=table_name)\n",
    "\n",
    "res = sql_api(select_all_in_time_range_sql)\n",
    "print(res.text)\n",
    "\n",
    "# Add in the de-duped data as an extension to the original Carto table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save latest data \n",
    "* Put on S3\n",
    "* Add into open_aq_history table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nathansuberi/Desktop/RW_Data/open_aq/open_aq_latest_2017-12-08_09-48-38.csv\n"
     ]
    }
   ],
   "source": [
    "# Current datetime, in desired format for naming convention\n",
    "cur_datetime = str(datetime.now())\n",
    "cur_datetime = cur_datetime.split(\".\")[0]\n",
    "cur_datetime = cur_datetime.replace(\":\", \"-\")\n",
    "cur_datetime = cur_datetime.replace(\" \", \"_\")\n",
    "\n",
    "folder = \"/Users/nathansuberi/Desktop/RW_Data/open_aq/\"\n",
    "file_name = \"open_aq_latest_{datetime}.csv\".format(datetime=cur_datetime)\n",
    "current_file_name = folder + file_name\\\n",
    "print(current_file_name)\n",
    "\n",
    "#df.to_csv(current_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['bc', 'co', 'no2', 'o3', 'pm10', 'pm25', 'so2'],\n",
       "       dtype='<U4'), array([   17,  3453, 24056,  6837,  4493,  2953,  4665]))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## All of this made unnecessary by magic of json_normalize, but list flattening is a nice trick\n",
    "\n",
    "# # Extract measurements\n",
    "\n",
    "# # All possible measurements:\n",
    "# # Flattening nested lists: https://stackoverflow.com/questions/952914/making-a-flat-list-out-of-list-of-lists-in-python\n",
    "# parameters = [obs[\"parameter\"] for msr in df['measurements'] for obs in msr]\n",
    "# parameters = np.unique(parameters, return_counts=True)\n",
    "# #(array(['bc', 'co', 'no2', 'o3', 'pm10', 'pm25', 'so2'],\n",
    "# #       dtype='<U4'), array([   17,  3453, 24056,  6837,  4493,  2953,  4665]))\n",
    "\n",
    "# # Sometimes has an averaging period, other times not\n",
    "# fields = [\"averagingPeriod\", \"lastUpdated\", \"parameter\", \"sourceName\", \"unit\", \"value\"]\n",
    "\n",
    "# parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-12-08 14:19:57.581782\n",
      "2017-12-08 09:19:57.582269\n",
      "1 day, 0:00:00\n",
      "2017-12-07 09:19:57.582608\n"
     ]
    }
   ],
   "source": [
    "# Exploring Python's datetime library\n",
    "# Docs: https://docs.python.org/3/library/datetime.html\n",
    "\n",
    "# This is UTC time, from Greenwich mean time\n",
    "print(datetime.utcnow())\n",
    "# This takes my current timezone\n",
    "print(datetime.now())\n",
    "# This makes a 1 day timedelta\n",
    "print(timedelta(days=1))\n",
    "print(datetime.now() - timedelta(days=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These two dfs are equal: True\n"
     ]
    }
   ],
   "source": [
    "# Experiment with breaking apart data structure\n",
    "x = np.random.rand(107)\n",
    "x = pd.DataFrame(x)\n",
    "#print(x)\n",
    "\n",
    "pieces = int(len(x) / piece_len)\n",
    "rg = range(pieces+1)\n",
    "y = pd.DataFrame([])\n",
    "\n",
    "for r in rg:\n",
    "    #print(r*piece_len)\n",
    "    #print(r*piece_len+piece_len)\n",
    "    y = y.append(x.iloc[r*piece_len:r*piece_len+piece_len], ignore_index=True)\n",
    "#y = np.append(y,x[pieces*piece_len:])\n",
    "\n",
    "print(\"These two dfs are equal:\",x.equals(y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
