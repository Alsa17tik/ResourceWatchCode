{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import logging\n",
    "import sys\n",
    "LOG_LEVEL = logging.INFO\n",
    "logging.basicConfig(stream=sys.stderr, level=LOG_LEVEL)\n",
    "\n",
    "from functools import reduce\n",
    "from sklearn import linear_model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 100\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA_FOLDER = \"/Users/nathansuberi/Desktop/RW_Data/com_009 Material Flows/\"\n",
    "os.listdir(DATA_FOLDER)\n",
    "\n",
    "# 13 categories mapped to 4 main categories\n",
    "MFA_13 = 'MFA13.csv'\n",
    "\n",
    "# Region codes\n",
    "REGIONS = 'Regions.csv'\n",
    "\n",
    "# Flow type table: Flow.name, Unit, Axis.label\n",
    "FLOW = 'Flow.csv'\n",
    "\n",
    "# 11 sectors (product group) and their names\n",
    "PRODUCT_GROUP = 'ProductGroup.csv'\n",
    "\n",
    "# Detailed item codes w/ names, aggregate 3 letter codes\n",
    "MATERIAL = 'Material.csv'\n",
    "\n",
    "# Country info - ISO, Name, Region, ISONum3, ALPHANUMISO\n",
    "COUNTRY = 'Country.csv'\n",
    "\n",
    "# Names for 4 main categories\n",
    "MFA_4 = 'MFA4.csv'\n",
    "\n",
    "\n",
    "####\n",
    "## Country / Regional data sets\n",
    "####\n",
    "\n",
    "\n",
    "# Country Data: Flow category, MFA13 code, MFA4 code, Time, Value\n",
    "FLOW_MFA = 'FlowMFA.csv'\n",
    "\n",
    "# Country data: by CCC_Code, Time, Value\n",
    "FLOW_CCC = 'FlowCCC.csv'\n",
    "\n",
    "# Country & Regional Data: ISO or Region (but not both), Flow type, Time, Value \n",
    "INDEX_DATA = 'IndexData.csv'\n",
    "\n",
    "# Flow Data: Year, Source.Region, Consumer.Region, Material.Category, Final.Product, Value\n",
    "FLOW_DETAILED = 'FlowDetailed.csv'\n",
    "\n",
    "all_data = [FLOW_MFA, FLOW_CCC, INDEX_DATA, FLOW_DETAILED]\n",
    "all_lookups = [MFA_13, REGIONS, FLOW, PRODUCT_GROUP,  \n",
    "           COUNTRY, MATERIAL, MFA_4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_df(df):\n",
    "    path = DATA_FOLDER + df\n",
    "    return pd.read_csv(path, sep=';')\n",
    "\n",
    "# https://stackoverflow.com/questions/35979620/get-the-last-10000-lines-of-a-csv-file\n",
    "# Read only the tail... better this way than running pd.read_csv().tail(num)\n",
    "def read_last_100_rows(df):\n",
    "    path = DATA_FOLDER + df\n",
    "    size = sum(1 for l in open(path))\n",
    "    return pd.read_csv(path, skiprows=range(100, size - 100), sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_to_dict(agg, df):\n",
    "    print(df)\n",
    "    agg[df] = read_df(df)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = reduce(add_to_dict, all_data, {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lookups = reduce(add_to_dict, all_lookups, {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data[FLOW_MFA].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data[FLOW_CCC].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data[INDEX_DATA].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data[FLOW_DETAILED].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lookups[MFA_13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking into the FLOW_MFA dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data[FLOW_MFA].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data[FLOW_MFA]['ISOAlpha3'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data[FLOW_MFA]['Flow'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data[FLOW_MFA]['MFA13'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data[FLOW_MFA]['MFA4'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data[FLOW_MFA]['Time'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running a linear model against sections of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_unique(df, col):\n",
    "    return df[col].unique()\n",
    "\n",
    "def run_linear_regressions(data, year, \n",
    "                           prod_col, flow_col,\n",
    "                           year_col, val_col, \n",
    "                           country_col):\n",
    "    '''\n",
    "    Inputs: Data, and\n",
    "    Outputs: square matrix of regression coefficients for each indicator\n",
    "    '''\n",
    "    data = data.copy()\n",
    "    \n",
    "    # Only look at comparisons of traded products\n",
    "    data = data[pd.notnull(data[prod_col])]\n",
    "        \n",
    "    # Create lists of countries, products, and flows to loop over\n",
    "    all_countries, all_products, all_flows = [extract_unique(data, col) for col in [country_col, prod_col, flow_col]]\n",
    "    logging.debug('all_countries: {}'.format(all_countries))\n",
    "    logging.debug('all_products: {}'.format(all_products))\n",
    "    logging.debug('all_flows: {}'.format(all_flows))\n",
    "    \n",
    "    # Result will be an upper right triangular square matrix in 4 dimensions\n",
    "    results = {}\n",
    "    \n",
    "    for ix_prod_x, prod_x in enumerate(all_products):\n",
    "        for ix_prod_y, prod_y in enumerate(all_products[:ix_prod_x+1]):\n",
    "            for ix_flow_x, flow_x in enumerate(all_flows):\n",
    "                for ix_flow_y, flow_y in enumerate(all_flows[:ix_flow_x+1]):\n",
    "                    # Extract data\n",
    "                    # TO DO: allow for year ranges\n",
    "\n",
    "                    logging.debug('flow x: {}'.format(flow_x))\n",
    "                    logging.debug('prod x: {}'.format(prod_x))\n",
    "                    logging.debug('flow y: {}'.format(flow_y))\n",
    "                    logging.debug('prod y: {}'.format(prod_y))\n",
    "                    \n",
    "                    msg = \"regressing {flow_x} of {prod_x} against {flow_y} of {prod_y}\"\n",
    "                    msg = msg.format(flow_x = flow_x,\n",
    "                              flow_y = flow_y,\n",
    "                               prod_x = prod_x,\n",
    "                               prod_y = prod_y)\n",
    "                    \n",
    "                    logging.info(msg)\n",
    "                    \n",
    "                    data_x = data.loc[(data[prod_col]==prod_x) & (data[year_col]==year) & (data[flow_col]==flow_x)]\n",
    "                    data_y = data.loc[(data[prod_col]==prod_y) & (data[year_col]==year) & (data[flow_col]==flow_y)]\n",
    "\n",
    "                    # Throw away all but intersection of countries\n",
    "                    keep_countries = set(data_x[country_col]) & set(data_y[country_col])\n",
    "                    skipped_countries = [country for country in all_countries if country not in keep_countries]\n",
    "                    \n",
    "                    data_x = data_x.set_index(country_col).loc[keep_countries, val_col]\n",
    "                    data_y = data_y.set_index(country_col).loc[keep_countries, val_col]\n",
    "                    \n",
    "                    # Reshape for regression\n",
    "                    data_x = data_x.values.reshape(-1, 1)\n",
    "                    data_y = data_y.values.reshape(-1, 1)\n",
    "\n",
    "                    r_squared = -1\n",
    "                    if data_x.shape[0] > 0:\n",
    "                        # Run regression\n",
    "                        lm = linear_model.LinearRegression() \n",
    "                        lm.fit(data_x, data_y)\n",
    "\n",
    "                        # Extract coefficient of determination (r^2)\n",
    "                        r_squared = lm.score(data_x, data_y)\n",
    "\n",
    "                    # Store results\n",
    "                    results[(flow_x, prod_x, flow_y, prod_y)] = {\n",
    "                        'r_squared': r_squared,\n",
    "                        'skipped_countries': skipped_countries\n",
    "                    }\n",
    "\n",
    "    return results\n",
    "\n",
    "def pretty_print_results(data_tuple, df_prod_names, df_flow_names):\n",
    "    \n",
    "    flow_x, prod_x, flow_y, prod_y = data_tuple[0]\n",
    "    \n",
    "    ## ALERT TO MATERIAL FLOWS!!!! DATA DOESNT USE SHORTHAND FOR EXPORT AND IMPORT\n",
    "    prod_x_name = df_prod_names.loc[prod_x, 'V2']\n",
    "    prod_y_name = df_prod_names.loc[prod_y, 'V2']\n",
    "    try:\n",
    "        flow_x_name = df_flow_names.loc[flow_x, 'Flow.name']\n",
    "    except:\n",
    "        flow_x_name = flow_x\n",
    "\n",
    "    try:\n",
    "        flow_y_name = df_flow_names.loc[flow_y, 'Flow.name']\n",
    "    except:\n",
    "        flow_y_name = flow_y\n",
    "    \n",
    "    new_tuple = ((flow_x_name, prod_x_name, flow_y_name, prod_y_name), data_tuple[1])\n",
    "    \n",
    "    return new_tuple\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kwargs = {\n",
    "    'data': data[FLOW_MFA],\n",
    "    'year': 2015,\n",
    "    'country_col': 'ISOAlpha3',\n",
    "    'prod_col': 'MFA13',\n",
    "    'flow_col':'Flow',\n",
    "    'year_col': 'Time',\n",
    "    'val_col': 'Value'\n",
    "}\n",
    "regression_results = run_linear_regressions(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lookups[FLOW]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lookups[MFA_13]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examining results of the regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logging.info('Number of regressions attempted: {}'.format(len(regression_results))\n",
    "logging.info('Results: {}'.format(regression_results))\n",
    "\n",
    "sorted_results = sorted(regression_results.items(), \n",
    "                        key=lambda res: res[1]['r_squared'], \n",
    "                        reverse=True)\n",
    "             \n",
    "# Only keep non-perfect correlations, \n",
    "# and ones for which no more than 10 countries are skipped\n",
    "filterd_sorted_results = [res for res in sorted_results if \n",
    "                  (res[1]['r_squared'] < 1) and \n",
    "                  (len(res[1]['skipped_countries']) < 10) ]\n",
    "\n",
    "df_prod_names = lookups[MFA_13].copy().set_index('V1') \n",
    "df_flow_names = lookups[FLOW].copy().set_index('Flow')\n",
    "\n",
    "readable_results = list(map(lambda tup: pretty_print_results(tup, df_prod_names, df_flow_names), \n",
    "                            filterd_sorted_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('com_009_material_flow_linear_regression_results.csv', 'w') as f:\n",
    "    f.write(json.dumps(readable_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('com_009_material_flow_linear_regression_results.csv', 'r') as f:\n",
    "    readable_results = json.loads(f.read())\n",
    "readable_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
