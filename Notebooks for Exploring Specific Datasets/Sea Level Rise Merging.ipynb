{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import rasterio as rio\n",
    "import numpy as np\n",
    "import logging\n",
    "import sys\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:{'driver': 'GTiff', 'dtype': 'uint8', 'nodata': 0.0, 'width': 432360, 'height': 140517, 'count': 1, 'crs': CRS({'init': 'epsg:4326'}), 'transform': Affine(0.000832639467111, 0.0, -180.0,\n",
      "       0.0, -0.000832639467111, 61.0), 'blockxsize': 256, 'blockysize': 256, 'compress': 'lzw', 'interleave': 'band', 'tiled': True}\n",
      "INFO:root:Processing row:0\n",
      "INFO:root:Processing row:1\n",
      "INFO:root:Processing row:2\n",
      "INFO:root:Processing row:3\n",
      "INFO:root:Processing row:4\n",
      "INFO:root:Processing row:5\n",
      "INFO:root:Processing row:6\n",
      "INFO:root:Processing row:7\n",
      "INFO:root:Processing row:8\n",
      "INFO:root:Processing row:9\n",
      "INFO:root:Processing row:10\n",
      "INFO:root:Processing row:11\n",
      "INFO:root:Processing row:12\n",
      "INFO:root:Processing row:13\n",
      "INFO:root:Processing row:14\n",
      "INFO:root:Processing row:15\n",
      "INFO:root:Processing row:16\n",
      "INFO:root:Processing row:17\n",
      "INFO:root:Processing row:18\n",
      "INFO:root:Processing row:19\n",
      "INFO:root:Processing row:20\n",
      "INFO:root:Processing row:21\n",
      "INFO:root:Processing row:22\n",
      "INFO:root:Processing row:23\n",
      "INFO:root:Processing row:24\n",
      "INFO:root:Processing row:25\n",
      "INFO:root:Processing row:26\n",
      "INFO:root:Processing row:27\n",
      "INFO:root:Processing row:28\n",
      "INFO:root:Processing row:29\n",
      "INFO:root:Processing row:30\n",
      "INFO:root:Processing row:31\n",
      "INFO:root:Processing row:32\n",
      "INFO:root:Processing row:33\n",
      "INFO:root:Processing row:34\n",
      "INFO:root:Processing row:35\n",
      "INFO:root:Processing row:36\n",
      "INFO:root:Processing row:37\n",
      "INFO:root:Processing row:38\n",
      "INFO:root:Processing row:39\n",
      "INFO:root:Processing row:40\n",
      "INFO:root:Processing row:41\n",
      "INFO:root:Processing row:42\n",
      "INFO:root:Processing row:43\n",
      "INFO:root:Processing row:44\n",
      "INFO:root:Processing row:45\n",
      "INFO:root:Processing row:46\n",
      "INFO:root:Processing row:47\n",
      "INFO:root:Processing row:48\n",
      "INFO:root:Processing row:49\n",
      "INFO:root:Processing row:50\n",
      "INFO:root:Processing row:51\n",
      "INFO:root:Processing row:52\n",
      "INFO:root:Processing row:53\n",
      "INFO:root:Processing row:54\n",
      "INFO:root:Processing row:55\n",
      "INFO:root:Processing row:56\n",
      "INFO:root:Processing row:57\n",
      "INFO:root:Processing row:58\n",
      "INFO:root:Processing row:59\n",
      "INFO:root:Processing row:60\n",
      "INFO:root:Processing row:61\n",
      "INFO:root:Processing row:62\n",
      "INFO:root:Processing row:63\n",
      "INFO:root:Processing row:64\n",
      "INFO:root:Processing row:65\n",
      "INFO:root:Processing row:66\n",
      "INFO:root:Processing row:67\n",
      "INFO:root:Processing row:68\n",
      "INFO:root:Processing row:69\n",
      "INFO:root:Processing row:70\n",
      "INFO:root:Processing row:71\n",
      "INFO:root:Processing row:72\n",
      "INFO:root:Processing row:73\n",
      "INFO:root:Processing row:74\n",
      "INFO:root:Processing row:75\n",
      "INFO:root:Processing row:76\n",
      "INFO:root:Processing row:77\n",
      "INFO:root:Processing row:78\n",
      "INFO:root:Processing row:79\n",
      "INFO:root:Processing row:80\n",
      "INFO:root:Processing row:81\n",
      "INFO:root:Processing row:82\n",
      "INFO:root:Processing row:83\n",
      "INFO:root:Processing row:84\n",
      "INFO:root:Processing row:85\n",
      "INFO:root:Processing row:86\n",
      "INFO:root:Processing row:87\n",
      "INFO:root:Processing row:88\n",
      "INFO:root:Processing row:89\n",
      "INFO:root:Processing row:90\n",
      "INFO:root:Processing row:91\n",
      "INFO:root:Processing row:92\n",
      "INFO:root:Processing row:93\n",
      "INFO:root:Processing row:94\n",
      "INFO:root:Processing row:95\n",
      "INFO:root:Processing row:96\n",
      "INFO:root:Processing row:97\n",
      "INFO:root:Processing row:98\n",
      "INFO:root:Processing row:99\n",
      "INFO:root:Processing row:100\n",
      "INFO:root:Processing row:101\n",
      "INFO:root:Processing row:102\n",
      "INFO:root:Processing row:103\n",
      "INFO:root:Processing row:104\n",
      "INFO:root:Processing row:105\n",
      "INFO:root:Processing row:106\n",
      "INFO:root:Processing row:107\n",
      "INFO:root:Processing row:108\n",
      "INFO:root:Processing row:109\n",
      "INFO:root:Processing row:110\n",
      "INFO:root:Processing row:111\n",
      "INFO:root:Processing row:112\n",
      "INFO:root:Processing row:113\n",
      "INFO:root:Processing row:114\n",
      "INFO:root:Processing row:115\n",
      "INFO:root:Processing row:116\n",
      "INFO:root:Processing row:117\n",
      "INFO:root:Processing row:118\n",
      "INFO:root:Processing row:119\n",
      "INFO:root:Processing row:120\n",
      "INFO:root:Processing row:121\n",
      "INFO:root:Processing row:122\n",
      "INFO:root:Processing row:123\n",
      "INFO:root:Processing row:124\n",
      "INFO:root:Processing row:125\n",
      "INFO:root:Processing row:126\n",
      "INFO:root:Processing row:127\n",
      "INFO:root:Processing row:128\n",
      "INFO:root:Processing row:129\n",
      "INFO:root:Processing row:130\n",
      "INFO:root:Processing row:131\n",
      "INFO:root:Processing row:132\n",
      "INFO:root:Processing row:133\n",
      "INFO:root:Processing row:134\n",
      "INFO:root:Processing row:135\n",
      "INFO:root:Processing row:136\n",
      "INFO:root:Processing row:137\n",
      "INFO:root:Processing row:138\n",
      "INFO:root:Processing row:139\n",
      "INFO:root:Processing row:140\n",
      "INFO:root:Processing row:141\n",
      "INFO:root:Processing row:142\n",
      "INFO:root:Processing row:143\n",
      "INFO:root:Processing row:144\n",
      "INFO:root:Processing row:145\n",
      "INFO:root:Processing row:146\n",
      "INFO:root:Processing row:147\n",
      "INFO:root:Processing row:148\n",
      "INFO:root:Processing row:149\n",
      "INFO:root:Processing row:150\n",
      "INFO:root:Processing row:151\n",
      "INFO:root:Processing row:152\n",
      "INFO:root:Processing row:153\n",
      "INFO:root:Processing row:154\n",
      "INFO:root:Processing row:155\n",
      "INFO:root:Processing row:156\n",
      "INFO:root:Processing row:157\n",
      "INFO:root:Processing row:158\n",
      "INFO:root:Processing row:159\n",
      "INFO:root:Processing row:160\n",
      "INFO:root:Processing row:161\n",
      "INFO:root:Processing row:162\n",
      "INFO:root:Processing row:163\n",
      "INFO:root:Processing row:164\n",
      "INFO:root:Processing row:165\n",
      "INFO:root:Processing row:166\n",
      "INFO:root:Processing row:167\n",
      "INFO:root:Processing row:168\n",
      "INFO:root:Processing row:169\n",
      "INFO:root:Processing row:170\n",
      "INFO:root:Processing row:171\n",
      "INFO:root:Processing row:172\n",
      "INFO:root:Processing row:173\n",
      "INFO:root:Processing row:174\n",
      "INFO:root:Processing row:175\n",
      "INFO:root:Processing row:176\n",
      "INFO:root:Processing row:177\n",
      "INFO:root:Processing row:178\n",
      "INFO:root:Processing row:179\n",
      "INFO:root:Processing row:180\n",
      "INFO:root:Processing row:181\n",
      "INFO:root:Processing row:182\n",
      "INFO:root:Processing row:183\n",
      "INFO:root:Processing row:184\n",
      "INFO:root:Processing row:185\n",
      "INFO:root:Processing row:186\n",
      "INFO:root:Processing row:187\n",
      "INFO:root:Processing row:188\n",
      "INFO:root:Processing row:189\n",
      "INFO:root:Processing row:190\n",
      "INFO:root:Processing row:191\n",
      "INFO:root:Processing row:192\n",
      "INFO:root:Processing row:193\n",
      "INFO:root:Processing row:194\n",
      "INFO:root:Processing row:195\n",
      "INFO:root:Processing row:196\n",
      "INFO:root:Processing row:197\n",
      "INFO:root:Processing row:198\n",
      "INFO:root:Processing row:199\n",
      "INFO:root:Processing row:200\n",
      "INFO:root:Processing row:201\n",
      "INFO:root:Processing row:202\n",
      "INFO:root:Processing row:203\n",
      "INFO:root:Processing row:204\n",
      "INFO:root:Processing row:205\n",
      "INFO:root:Processing row:206\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-c3e929ca6736>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Processing row:\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_row\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Investigate if it worked\n",
    "\n",
    "logging.basicConfig(stream=sys.stderr, level=logging.INFO)\n",
    "\n",
    "merged_cc_data = \"merged_cc_data.tif\"\n",
    "with rio.open(merged_cc_data, \"r\") as src:\n",
    "    profile = src.profile\n",
    "    logging.info(profile)\n",
    "    \n",
    "    windows = src.block_windows()\n",
    "    \n",
    "    curr_row = None\n",
    "    \n",
    "    for win_ix, window in windows:\n",
    "        data = src.read(indexes=1, window=window)\n",
    "        \n",
    "        if(curr_row != win_ix[0]):\n",
    "            curr_row = win_ix[0]\n",
    "            logging.info(\"Processing row:\" + str(curr_row))\n",
    "                \n",
    "        if np.sum(data) > 0:\n",
    "            logging.info(np.sum(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:{'driver': 'GTiff', 'dtype': 'uint8', 'nodata': 0.0, 'width': 432360, 'height': 140517, 'count': 10, 'crs': CRS({'init': 'epsg:4326'}), 'transform': Affine(0.000832639467111, 0.0, -180.0,\n",
      "       0.0, -0.000832639467111, 61.0), 'blockxsize': 256, 'blockysize': 256, 'tiled': True, 'compress': 'lzw', 'interleave': 'pixel'}\n",
      "INFO:root:num_rows: 548\n",
      "INFO:root:num_cols: 1688\n",
      "INFO:root:Processing Row: 0\n",
      "INFO:root:Time for row: 0:00:00.000018\n",
      "INFO:root:Total time elapsed: 0:00:00.000027\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5ad72ebebfc8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbnd\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_bands\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbnd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m                 \u001b[0mmerged_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbnd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import rasterio as rio\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(stream=sys.stderr, level=logging.INFO)\n",
    "# If true, this function will print out the sum of the values being input into merged_cc_data\n",
    "VERBOSE=False\n",
    "\n",
    "merged_cc_data = \"merged_cc_data_ft.tif\"\n",
    "\n",
    "with rio.open(\"https://wri-public-data.s3.amazonaws.com/resourcewatch/raster/cli_024_sea_level_rise/cli_024_sea_level_rise_ft.tif\", \"r\") as src:\n",
    "    profile = src.profile\n",
    "    logging.info(profile)\n",
    "    \n",
    "profile[\"count\"] = 1\n",
    "\n",
    "with rio.open(merged_cc_data, \"w\", **profile) as dst:\n",
    "    # Iterate over the input data, updating the merged file as we go\n",
    "    # Do this for every block in the larger block_windows\n",
    "    \n",
    "    with rio.open(\"https://wri-public-data.s3.amazonaws.com/resourcewatch/raster/cli_024_sea_level_rise/cli_024_sea_level_rise_ft.tif\", \"r\") as src:\n",
    "        profile = src.profile\n",
    "        \n",
    "        num_bands = profile[\"count\"]\n",
    "        blockx = profile[\"blockxsize\"]\n",
    "        blocky = profile[\"blockysize\"]\n",
    "        \n",
    "        height = profile[\"height\"]\n",
    "        width = profile[\"width\"]\n",
    "        \n",
    "        num_rows = int(height/blocky)\n",
    "        num_cols = int(width/blockx)\n",
    "        \n",
    "        logging.info(\"num_rows: \" + str(num_rows))\n",
    "        logging.info(\"num_cols: \" + str(num_cols))\n",
    "        \n",
    "        dtype = profile[\"dtype\"]\n",
    "        \n",
    "        windows = src.block_windows()\n",
    "        \n",
    "        curr_row = None\n",
    "        start_time = datetime.now()\n",
    "        time_step = datetime.now()\n",
    "        \n",
    "        for win_ix, window in windows:\n",
    "            \n",
    "            if(curr_row != win_ix[0]):\n",
    "                curr_row = win_ix[0]\n",
    "                curr_time = datetime.now()\n",
    "                logging.info(\"Processing Row: \" + str(curr_row))\n",
    "                logging.info(\"Time for row: \" + str(curr_time-time_step))\n",
    "                logging.info(\"Total time elapsed: \" + str(curr_time-start_time))\n",
    "                time_step = curr_time\n",
    "    \n",
    "            x = window[0][1] - window[0][0]\n",
    "            y = window[1][1] - window[1][0]\n",
    "            merged_data = np.zeros((x,y), dtype=dtype)\n",
    "            \n",
    "            for bnd in range(num_bands, 0, -1):\n",
    "                data = src.read(indexes=bnd, window=window)\n",
    "                merged_data[data==1] = bnd\n",
    "            \n",
    "            sum_data = np.sum(merged_data)\n",
    "            \n",
    "            if (sum_data > 0) & VERBOSE:\n",
    "                logging.info(\"Sum of merged_data: \" + str(sum_data))\n",
    "            dst.write(merged_data, indexes=1, window=window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import rasterio as rio\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(stream=sys.stderr, level=logging.INFO)\n",
    "\n",
    "merged_cc_data = \"merged_cc_data_meters.tif\"\n",
    "\n",
    "conversions_of_band_to_meters = {\n",
    "    1:.5,\n",
    "    2:1.,\n",
    "    3:1.5,\n",
    "    4:2.,\n",
    "    5:2.5,\n",
    "    6:3.,\n",
    "    7:5.,\n",
    "    8:10.,\n",
    "    9:20.,\n",
    "    10:30.\n",
    "}\n",
    "\n",
    "with rio.open(\"https://wri-public-data.s3.amazonaws.com/resourcewatch/raster/cli_024_sea_level_rise/cli_024_sea_level_rise_m.tif\", \"r\") as src:\n",
    "    profile = src.profile\n",
    "    print(profile)\n",
    "    \n",
    "profile[\"count\"] = 1\n",
    "\n",
    "with rio.open(merged_cc_data, \"w\", **profile) as dst:\n",
    "    # Iterate over the input data, updating the merged file as we go\n",
    "    # Do this for every block in the larger block_windows\n",
    "    \n",
    "    with rio.open(\"https://wri-public-data.s3.amazonaws.com/resourcewatch/raster/cli_024_sea_level_rise/cli_024_sea_level_rise_m.tif\", \"r\") as src:\n",
    "        profile = src.profile\n",
    "        \n",
    "        num_bands = profile[\"count\"]\n",
    "        blockx = profile[\"blockxsize\"]\n",
    "        blocky = profile[\"blockysize\"]\n",
    "        \n",
    "        height = profile[\"height\"]\n",
    "        width = profile[\"width\"]\n",
    "        \n",
    "        num_rows = int(height/blocky)\n",
    "        num_cols = int(width/blockx)\n",
    "        \n",
    "        logging.info(\"num_rows: \" + str(num_rows))\n",
    "        logging.info(\"num_cols: \" + str(num_cols))\n",
    "        \n",
    "        dtype = profile[\"dtype\"]\n",
    "        \n",
    "        windows = src.block_windows()\n",
    "        \n",
    "        curr_row = None\n",
    "        start_time = datetime.now()\n",
    "        time_step = datetime.now()\n",
    "        \n",
    "        for win_ix, window in windows:\n",
    "            \n",
    "            if(curr_row != win_ix[0]):\n",
    "                curr_row = win_ix[0]\n",
    "                curr_time = datetime.now()\n",
    "                logging.info(\"Processing Row: \" + str(curr_row))\n",
    "                logging.info(\"Time for row: \" + str(curr_time-time_step))\n",
    "                logging.info(\"Total time elapsed: \" + str(curr_time-start_time))\n",
    "                time_step = curr_time\n",
    "    \n",
    "            x = window[0][1] - window[0][0]\n",
    "            y = window[1][1] - window[1][0]\n",
    "            merged_data = np.zeros((x,y), dtype=dtype)\n",
    "            \n",
    "            for bnd in range(num_bands, 0, -1):\n",
    "                data = src.read(indexes=bnd, window=window)\n",
    "                merged_data[data==1] = conversions_of_band_to_meters[bnd]\n",
    "\n",
    "            dst.write(merged_data, indexes=1, window=window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing band 1\n",
      "Writing band 2\n",
      "Writing band 3\n",
      "Writing band 4\n",
      "Writing band 5\n",
      "Writing band 6\n",
      "Writing band 7\n",
      "Writing band 8\n",
      "Writing band 9\n",
      "Writing band 10\n"
     ]
    }
   ],
   "source": [
    "from rasterio.crs import CRS\n",
    "from affine import Affine\n",
    "\n",
    "sample_tif = \"climate_central_merge_sample.tif\"\n",
    "profile = {\n",
    "    'driver': 'GTiff', \n",
    "   'dtype': 'uint8', \n",
    "   'nodata': 0.0, \n",
    "   'width': 256, \n",
    "   'height': 256, \n",
    "   'count': 10, \n",
    "   'crs': CRS({'init': 'epsg:4326'}), \n",
    "   'transform': Affine(0.000832639467111, 0.0, -180.0,\n",
    "0.0, -0.000832639467111, 61.0), \n",
    "   'blockxsize': 256, \n",
    "   'blockysize': 256, \n",
    "   'tiled': True, \n",
    "   'compress': 'lzw', \n",
    "   'interleave': 'pixel'\n",
    "}\n",
    "\n",
    "num_bands = profile[\"count\"]\n",
    "\n",
    "with rio.open(sample_tif, \"w\", **profile) as dst:\n",
    "    # Make data that conforms to the CC style... \n",
    "    # i.e. if an earlier band has a 1 in a cell, the later ones do too\n",
    "    \n",
    "    new_data = np.zeros((256, 256), dtype=\"uint8\")\n",
    "    \n",
    "    for bnd in range(1,num_bands+1):\n",
    "        print(\"Writing band\", bnd)\n",
    "        \n",
    "        # How to randomly select in shape of 2d array:\n",
    "        # https://www.reddit.com/r/learnpython/comments/2ol1n4/taking_random_sample_from_a_2d_numpy_array/\n",
    "        new_ones = np.random.choice([True,False], new_data.shape)\n",
    "        new_data[new_ones] = 1\n",
    "        dst.write(new_data, indexes=bnd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying data from band 10\n",
      "Copying data from band 9\n",
      "Copying data from band 8\n",
      "Copying data from band 7\n",
      "Copying data from band 6\n",
      "Copying data from band 5\n",
      "Copying data from band 4\n",
      "Copying data from band 3\n",
      "Copying data from band 2\n",
      "Copying data from band 1\n"
     ]
    }
   ],
   "source": [
    "with rio.open(sample_tif, \"r\") as src:\n",
    "        profile = src.profile\n",
    "        num_bands = profile[\"count\"]\n",
    "        for bnd in range(num_bands, 0, -1):\n",
    "            print(\"Copying data from band\", bnd)\n",
    "            data = src.read(indexes=bnd)\n",
    "            merged_data[data==1] = bnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying data from band 10\n",
      "Copying data from band 9\n",
      "Copying data from band 8\n",
      "Copying data from band 7\n",
      "Copying data from band 6\n",
      "Copying data from band 5\n",
      "Copying data from band 4\n",
      "Copying data from band 3\n",
      "Copying data from band 2\n",
      "Copying data from band 1\n",
      "(256, 256)\n",
      "[[5 1 1 ..., 5 4 3]\n",
      " [1 1 5 ..., 4 5 1]\n",
      " [1 1 4 ..., 3 5 1]\n",
      " ..., \n",
      " [1 1 5 ..., 3 3 1]\n",
      " [9 1 3 ..., 2 2 1]\n",
      " [2 6 3 ..., 3 1 1]]\n"
     ]
    }
   ],
   "source": [
    "sample_merged_tif = \"climate_central_merged_sample.tif\"\n",
    "profile = {\n",
    "    'driver': 'GTiff', \n",
    "   'dtype': 'uint8', \n",
    "   'nodata': 0.0, \n",
    "   'width': 256, \n",
    "   'height': 256, \n",
    "   'count': 1, \n",
    "   'crs': CRS({'init': 'epsg:4326'}), \n",
    "   'transform': Affine(0.000832639467111, 0.0, -180.0,\n",
    "0.0, -0.000832639467111, 61.0), \n",
    "   'blockxsize': 256, \n",
    "   'blockysize': 256, \n",
    "   'tiled': True, \n",
    "   'compress': 'lzw', \n",
    "   'interleave': 'pixel'\n",
    "}\n",
    "\n",
    "# Open the file to contain the merged data\n",
    "with rio.open(sample_merged_tif, \"w\", **profile) as dst:\n",
    "    # Iterate over the input data, updating the merged file as we go\n",
    "    # Would do this for every block in the larger block_windows\n",
    "    \n",
    "    merged_data = np.zeros((256,256), dtype=\"uint8\")\n",
    "    \n",
    "    with rio.open(sample_tif, \"r\") as src:\n",
    "        profile = src.profile\n",
    "        num_bands = profile[\"count\"]\n",
    "        for bnd in range(num_bands, 0, -1):\n",
    "            print(\"Copying data from band\", bnd)\n",
    "            data = src.read(indexes=bnd)\n",
    "            merged_data[data==1] = bnd\n",
    "    \n",
    "    print(merged_data.shape)\n",
    "    print(merged_data)\n",
    "    dst.write(merged_data, indexes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'driver': 'GTiff', 'dtype': 'uint8', 'nodata': 0.0, 'width': 256, 'height': 256, 'count': 1, 'crs': CRS({'init': 'epsg:4326'}), 'transform': Affine(0.000832639467111, 0.0, -180.0,\n",
      "       0.0, -0.000832639467111, 61.0), 'blockxsize': '256', 'blockysize': '256', 'compress': 'lzw', 'interleave': 'band', 'tiled': False}\n",
      "[[5 1 1 ..., 5 4 3]\n",
      " [1 1 5 ..., 4 5 1]\n",
      " [1 1 4 ..., 3 5 1]\n",
      " ..., \n",
      " [1 1 5 ..., 3 3 1]\n",
      " [9 1 3 ..., 2 2 1]\n",
      " [2 6 3 ..., 3 1 1]]\n"
     ]
    }
   ],
   "source": [
    "with rio.open(sample_merged_tif, \"r\", **profile) as src:\n",
    "    merged_profile = src.profile\n",
    "    print(merged_profile)\n",
    "    data = src.read(indexes=1)\n",
    "    \n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment with multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Concurrency with rasterio - couldn't figure out how to get this to work\n",
    "# https://mapbox.github.io/rasterio/topics/concurrency.html\n",
    "# The compute function mentioned here: https://github.com/mapbox/rasterio/blob/master/rasterio/_example.pyx\n",
    "# ThreadPoolExecutor: https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.ThreadPoolExecutor\n",
    "\n",
    "import rasterio as rio\n",
    "import numpy as np\n",
    "from rasterio._example import compute\n",
    "\n",
    "import concurrent.futures\n",
    "import multiprocessing\n",
    "import time\n",
    "max_works = multiprocessing.cpu_count()\n",
    "\n",
    "merged_cc_data = \"merged_cc_data.tif\"\n",
    "\n",
    "with rio.open(\"https://wri-public-data.s3.amazonaws.com/resourcewatch/raster/cli_024_sea_level_rise/cli_024_sea_level_rise_ft.tif\", \"r\") as src:\n",
    "    profile = src.profile\n",
    "    print(profile)\n",
    "    \n",
    "profile[\"count\"] = 1\n",
    "\n",
    "with rio.open(merged_cc_data, \"w\", **profile) as dst:\n",
    "    # Iterate over the input data, updating the merged file as we go\n",
    "    # Do this for every block in the larger block_windows\n",
    "    \n",
    "    with rio.open(\"https://wri-public-data.s3.amazonaws.com/resourcewatch/raster/cli_024_sea_level_rise/cli_024_sea_level_rise_ft.tif\", \"r\") as src:\n",
    "        profile = src.profile\n",
    "        \n",
    "        num_bands = profile[\"count\"]\n",
    "        blockx = profile[\"blockxsize\"]\n",
    "        blocky = profile[\"blockysize\"]\n",
    "        \n",
    "        height = profile[\"height\"]\n",
    "        width = profile[\"width\"]\n",
    "        \n",
    "        num_rows = int(height/blocky)\n",
    "        num_cols = int(width/blockx)\n",
    "        \n",
    "        print(\"num_rows:\", num_rows)\n",
    "        print(\"num_cols:\", num_cols)\n",
    "        \n",
    "        dtype = profile[\"dtype\"]\n",
    "        \n",
    "        def jobs():\n",
    "            for ij, window in dst.block_windows():\n",
    "                x = window[0][1] - window[0][0]\n",
    "                y = window[1][1] - window[1][0]\n",
    "                merged_data = np.zeros((x,y), dtype=dtype)\n",
    "\n",
    "                for bnd in range(num_bands, 0, -1):\n",
    "                    data = src.read(indexes=bnd, window=window)\n",
    "                    merged_data[data==1] = bnd\n",
    "\n",
    "                res = np.zeros((x,y), dtype=dtype)\n",
    "                yield merged_data, res, window, ij\n",
    "        \n",
    "        # Submit the jobs to the thread pool executor.\n",
    "        with concurrent.futures.ThreadPoolExecutor(\n",
    "                max_workers=multiprocessing.cpu_count()) as executor:\n",
    "\n",
    "            # Map the futures returned from executor.submit()\n",
    "            # to their destination windows.\n",
    "            #\n",
    "            # The _example.compute function modifies no Python\n",
    "            # objects and releases the GIL. It can execute\n",
    "            # concurrently.\n",
    "            future_to_window = {\n",
    "                executor.submit(compute, data, res): (data, res, window, ij)\n",
    "                for data, res, window, ij in jobs()}\n",
    "\n",
    "            # As the processing jobs are completed, get the\n",
    "            # results and write the data to the appropriate\n",
    "            # destination window.\n",
    "            for future in concurrent.futures.as_completed(\n",
    "                    future_to_window):\n",
    "\n",
    "                data, result, window, ij = future_to_window[future]\n",
    "\n",
    "                print(\"Computing for index:\", ij)\n",
    "                \n",
    "                dst.write(result, indexes=1, window=window)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
